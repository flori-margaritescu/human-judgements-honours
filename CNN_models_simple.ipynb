{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Importing Drive Datasets </h1>"
      ],
      "metadata": {
        "id": "In1wlSGFIdVB"
      },
      "id": "In1wlSGFIdVB"
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/flori-margaritescu/human-judgements-honours.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fk-k5K5aJtaB",
        "outputId": "b36b2b1e-7b6b-4b75-aa61-1489b5e1d1c5"
      },
      "id": "Fk-k5K5aJtaB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'human-judgements-honours'...\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects:  11% (1/9)\u001b[K\rremote: Counting objects:  22% (2/9)\u001b[K\rremote: Counting objects:  33% (3/9)\u001b[K\rremote: Counting objects:  44% (4/9)\u001b[K\rremote: Counting objects:  55% (5/9)\u001b[K\rremote: Counting objects:  66% (6/9)\u001b[K\rremote: Counting objects:  77% (7/9)\u001b[K\rremote: Counting objects:  88% (8/9)\u001b[K\rremote: Counting objects: 100% (9/9)\u001b[K\rremote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects:  14% (1/7)\u001b[K\rremote: Compressing objects:  28% (2/7)\u001b[K\rremote: Compressing objects:  42% (3/7)\u001b[K\rremote: Compressing objects:  57% (4/7)\u001b[K\rremote: Compressing objects:  71% (5/7)\u001b[K\rremote: Compressing objects:  85% (6/7)\u001b[K\rremote: Compressing objects: 100% (7/7)\u001b[K\rremote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 9 (delta 2), reused 7 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects:  11% (1/9)\rUnpacking objects:  22% (2/9)\rUnpacking objects:  33% (3/9)\rUnpacking objects:  44% (4/9)\rUnpacking objects:  55% (5/9)\rUnpacking objects:  66% (6/9)\rUnpacking objects:  77% (7/9)\rUnpacking objects:  88% (8/9)\rUnpacking objects: 100% (9/9)\rUnpacking objects: 100% (9/9), 4.34 KiB | 2.17 MiB/s, done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmOC1OCdIcy7",
        "outputId": "8605842d-c767-4151-c8c5-719c77c20ee4"
      },
      "id": "YmOC1OCdIcy7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -uq \"/content/drive/MyDrive/Colab Notebooks/distortion_triplets.zip\" -d \"/content/datasets/distortions\"\n",
        "!unzip -uq \"/content/drive/MyDrive/Colab Notebooks/hsj_triplets.zip\" -d \"/content/datasets/hsj\"\n",
        "!unzip -uq \"/content/drive/MyDrive/Colab Notebooks/birds_dataset_triplets.zip\" -d \"/content/datasets/birds-16\""
      ],
      "metadata": {
        "id": "LlfBBzehJFc-"
      },
      "id": "LlfBBzehJFc-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "9065aff9",
      "metadata": {
        "id": "9065aff9"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install img2vec-pytorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zD9whTxmMTN-",
        "outputId": "77650191-5560-47f4-9696-42f6af4b5d72"
      },
      "id": "zD9whTxmMTN-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting img2vec-pytorch\n",
            "  Downloading img2vec_pytorch-1.0.1-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from img2vec-pytorch) (1.22.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from img2vec-pytorch) (1.13.1+cu116)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from img2vec-pytorch) (0.14.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->img2vec-pytorch) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision->img2vec-pytorch) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->img2vec-pytorch) (8.4.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->img2vec-pytorch) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->img2vec-pytorch) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->img2vec-pytorch) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->img2vec-pytorch) (2022.12.7)\n",
            "Installing collected packages: img2vec-pytorch\n",
            "Successfully installed img2vec-pytorch-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5158285a",
      "metadata": {
        "id": "5158285a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "from img2vec_pytorch import Img2Vec"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fc372be2",
      "metadata": {
        "id": "fc372be2"
      },
      "source": [
        "### Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: AlexNet and ResNet-18 take in completely different Tensor formats!\n",
        "\n",
        "<h2> Note: the below package does the feature extraction for us aparently - careful with how you use it - better start from scratch for consistency of results!</h2>"
      ],
      "metadata": {
        "id": "FvunBJEsNP77"
      },
      "id": "FvunBJEsNP77"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fd5b2f0c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fd5b2f0c",
        "outputId": "022700a6-d559-45df-865d-e5f98b5a40a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 4096])\n",
            "torch.Size([1, 512, 1, 1])\n"
          ]
        }
      ],
      "source": [
        "# Initialize Img2Vec with GPU\n",
        "img2vec_alexnet = Img2Vec(cuda=False, model=\"alexnet\")  # default model resnet\n",
        "\n",
        "# Read in an image (rgb format)\n",
        "img = Image.open('test.png').convert('RGB')\n",
        "\n",
        "# Get a vector from img2vec, returned as a torch FloatTensor\n",
        "vec = img2vec_alexnet.get_vec(img, tensor=True)\n",
        "\n",
        "print(vec.size())\n",
        "\n",
        "# Initialize Img2Vec with GPU\n",
        "img2vec_18 = Img2Vec(cuda=False, model=\"resnet-18\")  # default model resnet\n",
        "\n",
        "# Read in an image (rgb format)\n",
        "img = Image.open('test.png').convert('RGB')\n",
        "# Get a vector from img2vec, returned as a torch FloatTensor\n",
        "vec = img2vec_18.get_vec(img, tensor=True)  \n",
        "\n",
        "print(vec.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a6a4db4c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "a6a4db4c",
        "outputId": "50d1209f-eabc-444b-9a22-87ca876c739d"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-940622e41615>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ref.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mref_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'p0.png'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mp0_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg2vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'img2vec' is not defined"
          ]
        }
      ],
      "source": [
        "ref = Image.open('ref.png').convert('RGB')\n",
        "ref_vec = img2vec.get_vec(ref, tensor=True)\n",
        "\n",
        "p0 = Image.open('p0.png').convert('RGB')\n",
        "p0_vec = img2vec.get_vec(p0, tensor=True)\n",
        "\n",
        "p1 = Image.open('p1.png').convert('RGB')\n",
        "p1_vec = img2vec.get_vec(p1, tensor=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "93cf0baa",
      "metadata": {
        "id": "93cf0baa",
        "outputId": "13dd189d-8464-43f2-d48c-d28cb4d7729c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cosine similarity: tensor([0.4113])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Using PyTorch Cosine Similarity\n",
        "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "cos_sim = cos(ref_vec,\n",
        "              p0_vec)\n",
        "print('\\nCosine similarity: {0}\\n'.format(cos_sim))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "314ba326",
      "metadata": {
        "scrolled": true,
        "id": "314ba326",
        "outputId": "70eaf33a-388b-4b5f-eab0-5b3a961ba893"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Cosine similarity: tensor([0.3291])\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Using PyTorch Cosine Similarity\n",
        "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "cos_sim = cos(ref_vec,\n",
        "              p1_vec)\n",
        "print('\\nCosine similarity: {0}\\n'.format(cos_sim))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5f1e953e",
      "metadata": {
        "id": "5f1e953e"
      },
      "source": [
        "### Common functions for loading dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aade6f16",
      "metadata": {
        "id": "aade6f16"
      },
      "outputs": [],
      "source": [
        "def format_image_number(number):\n",
        "    img_no_str = str(number)\n",
        "    \n",
        "    if len(img_no_str) == 1:\n",
        "        im_no_name = \"00000\"\n",
        "    elif len(img_no_str) == 2:\n",
        "        im_no_name = \"0000\"\n",
        "    elif len(img_no_str) == 3:\n",
        "        im_no_name = \"000\"\n",
        "    elif len(img_no_str) == 4:\n",
        "        im_no_name = \"00\"\n",
        "    elif len(img_no_str) == 5:\n",
        "        im_no_name = \"0\"\n",
        "    elif len(img_no_str) == 6:\n",
        "        im_no_name = \"\"\n",
        "        \n",
        "    return im_no_name + img_no_str\n",
        "    \n",
        "\n",
        "def get_images_vector(path, number_of_images):  # returns a list of tensors\n",
        "    # path of form: traditional/ref/\n",
        "    feature_tensor_list = []\n",
        "    \n",
        "    for image_no in range(number_of_images):\n",
        "        image_no_str = str(image_no)\n",
        "        \n",
        "        im_no_name = format_image_number(image_no_str) + \".png\"\n",
        "        \n",
        "        path_to_image = path + im_no_name\n",
        "\n",
        "        feature_vector_image = Image.open(path_to_image).convert('RGB')\n",
        "        feature_vec = img2vec.get_vec(feature_vector_image, tensor=True)\n",
        "        feature_tensor_list.append(feature_vec)\n",
        "        \n",
        "    return feature_tensor_list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d7d1a43",
      "metadata": {
        "id": "2d7d1a43"
      },
      "outputs": [],
      "source": [
        "def obtain_cosine_similarity_model_predictions(number_of_images, refs_vec_list, p0s_rec_list, p1s_rec_list):\n",
        "    cosine_similarity_ref_and_p0 = []\n",
        "    cosine_similarity_ref_and_p1 = []\n",
        "\n",
        "    # list of predictions\n",
        "    cosine_similarity_predictions = []\n",
        "    \n",
        "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "    # cos_sim = cos(query_vector.unsqueeze(0), ref2_vector.unsqueeze(0))\n",
        "\n",
        "    for image_no in range(number_of_images): \n",
        "        reshaped_ref = torch.reshape(refs_vec_list[image_no], (1,512))\n",
        "        reshaped_p0 = torch.reshape(p0s_rec_list[image_no], (1,512))\n",
        "        reshaped_p1 = torch.reshape(p1s_rec_list[image_no], (1,512))\n",
        "        \n",
        "        cosine_similarity_ref_and_p0.append(cos(reshaped_ref, reshaped_p0))\n",
        "        cosine_similarity_ref_and_p1.append(cos(reshaped_ref, reshaped_p1))\n",
        "\n",
        "        if cosine_similarity_ref_and_p0[image_no] >= cosine_similarity_ref_and_p1[image_no]:\n",
        "            cosine_similarity_predictions.append(0)\n",
        "        else:\n",
        "            cosine_similarity_predictions.append(1)   \n",
        "            \n",
        "    return cosine_similarity_predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66ee8ae1",
      "metadata": {
        "id": "66ee8ae1"
      },
      "outputs": [],
      "source": [
        "def obtain_prediction_accuracy(number_of_images, path_to_decision, actual_predictions):\n",
        "    expected_decision_outputs = []\n",
        "\n",
        "    for image_no in range(number_of_images):\n",
        "            image_no_str = str(image_no)\n",
        "\n",
        "            im_no_name = format_image_number(image_no_str) + \".npy\"\n",
        "            path_to_image = path_to_decision + im_no_name\n",
        "\n",
        "            decision = np.load(path_to_image)\n",
        "\n",
        "            if decision[0] <= 0.5: \n",
        "                expected_decision_outputs.append(0)\n",
        "            else: \n",
        "                expected_decision_outputs.append(1)\n",
        "                \n",
        "    number_wrong_predictions = 0\n",
        "\n",
        "    for image_no in range(number_of_images):\n",
        "        if actual_predictions[image_no] != expected_decision_outputs[image_no]:\n",
        "            number_wrong_predictions += 1\n",
        "\n",
        "    accuracy = (number_of_images - number_wrong_predictions)/(number_of_images)\n",
        "    \n",
        "    return accuracy\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "68c2d02d",
      "metadata": {
        "id": "68c2d02d"
      },
      "outputs": [],
      "source": [
        "def reshape_tensor_list(dim, tensor_list):\n",
        "    reshaped_list = []\n",
        "    for t in tensor_list:\n",
        "        reshaped_t = torch.reshape(t, (1,dim))\n",
        "        reshaped_list.append(t)\n",
        "    return reshaped_list"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49678780",
      "metadata": {
        "id": "49678780"
      },
      "source": [
        "### 1. Resnet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73f39e4e",
      "metadata": {
        "id": "73f39e4e"
      },
      "outputs": [],
      "source": [
        "img2vec_res = Img2Vec(cuda=False, model=\"resnet-18\")  # default model resnet"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "22520bf3",
      "metadata": {
        "id": "22520bf3"
      },
      "source": [
        "#### 1.1 Traditional"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "27073e7e",
      "metadata": {
        "id": "27073e7e"
      },
      "outputs": [],
      "source": [
        "traditional_refs = get_images_vector(\"val/traditional/ref/\", 4720)\n",
        "traditional_p0s = get_images_vector(\"val/traditional/p0/\", 4720)\n",
        "traditional_p1s = get_images_vector(\"val/traditional/p1/\", 4720)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0a2a3043",
      "metadata": {
        "id": "0a2a3043",
        "outputId": "57984062-bb0c-4a12-962c-3d6f15db82c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4720\n",
            "4720\n",
            "4720\n"
          ]
        }
      ],
      "source": [
        "print(len(traditional_refs))\n",
        "print(len(traditional_p0s))\n",
        "print(len(traditional_p1s))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46a90a85",
      "metadata": {
        "id": "46a90a85"
      },
      "outputs": [],
      "source": [
        "actual_model_predictions = obtain_cosine_similarity_model_predictions(4720, traditional_refs, traditional_p0s, traditional_p1s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09b82c5f",
      "metadata": {
        "id": "09b82c5f"
      },
      "outputs": [],
      "source": [
        "prediction_accuracy = obtain_prediction_accuracy(4720, \"val/traditional/judge/\", actual_model_predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8ca7cef",
      "metadata": {
        "id": "d8ca7cef",
        "outputId": "c17e67e3-3f3e-4ae4-81aa-463eaf143853"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8048728813559322"
            ]
          },
          "execution_count": 79,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e07c6190",
      "metadata": {
        "id": "e07c6190"
      },
      "source": [
        "Prediction accuracy for Resnet-18 for traditional distortions: 0.8048728813559322"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "077a16c9",
      "metadata": {
        "id": "077a16c9"
      },
      "source": [
        "#### 1.2 CNN-based"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d95c1374",
      "metadata": {
        "id": "d95c1374"
      },
      "outputs": [],
      "source": [
        "cnn_refs = get_images_vector(\"val/cnn/ref/\", 4720)\n",
        "cnn_p0s = get_images_vector(\"val/cnn/p0/\", 4720)\n",
        "cnn_p1s = get_images_vector(\"val/cnn/p1/\", 4720)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d2e7f2d",
      "metadata": {
        "id": "7d2e7f2d",
        "outputId": "eddb6768-5e79-4bca-b6a1-d9f996a8f39f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4720\n",
            "4720\n",
            "4720\n"
          ]
        }
      ],
      "source": [
        "print(len(cnn_refs))\n",
        "print(len(cnn_p0s))\n",
        "print(len(cnn_p1s))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "131aa574",
      "metadata": {
        "id": "131aa574"
      },
      "outputs": [],
      "source": [
        "actual_model_predictions_cnn_distortion = obtain_cosine_similarity_model_predictions(4720, cnn_refs, cnn_p0s, cnn_p1s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d427a1f8",
      "metadata": {
        "id": "d427a1f8"
      },
      "outputs": [],
      "source": [
        "prediction_accuracy_cnn_distortion = obtain_prediction_accuracy(4720, \"val/cnn/judge/\", actual_model_predictions_cnn_distortion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7534f0a4",
      "metadata": {
        "id": "7534f0a4",
        "outputId": "8030cb62-a4a4-43a3-f062-d1cad56f5574"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8442796610169492"
            ]
          },
          "execution_count": 88,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction_accuracy_cnn_distortion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93478b18",
      "metadata": {
        "id": "93478b18"
      },
      "source": [
        "Prediction accuracy for Resnet-18 for CNN-based distortions: 0.8442796610169492"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95b8f83f",
      "metadata": {
        "id": "95b8f83f"
      },
      "source": [
        "#### 1.3 Colorization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eca880a7",
      "metadata": {
        "id": "eca880a7"
      },
      "outputs": [],
      "source": [
        "color_refs = get_images_vector(\"val/color/ref/\", 4720)\n",
        "color_p0s = get_images_vector(\"val/color/p0/\", 4720)\n",
        "color_p1s = get_images_vector(\"val/color/p1/\", 4720)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e90d57d",
      "metadata": {
        "id": "1e90d57d",
        "outputId": "84d5d237-6a45-4d71-be67-7a8de491d041"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4720\n",
            "4720\n",
            "4720\n"
          ]
        }
      ],
      "source": [
        "print(len(color_refs))\n",
        "print(len(color_p0s))\n",
        "print(len(color_p1s))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d3829085",
      "metadata": {
        "id": "d3829085"
      },
      "outputs": [],
      "source": [
        "actual_model_predictions_color_distortion = obtain_cosine_similarity_model_predictions(4720, color_refs, color_p0s, color_p1s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8dcd0778",
      "metadata": {
        "id": "8dcd0778"
      },
      "outputs": [],
      "source": [
        "prediction_accuracy_color_distortion = obtain_prediction_accuracy(4720, \"val/color/judge/\", actual_model_predictions_color_distortion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2fe4ff36",
      "metadata": {
        "id": "2fe4ff36",
        "outputId": "954388b2-ceb4-470d-d7c4-0328c8b9d54b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6533898305084745"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction_accuracy_color_distortion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0c68ea4",
      "metadata": {
        "id": "d0c68ea4"
      },
      "source": [
        "Prediction accuracy for Resnet-18 for colorizaton distortions: 0.6533898305084745"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7687f12b",
      "metadata": {
        "id": "7687f12b"
      },
      "source": [
        "#### 1.4 Deblurring --- IGNORE FOR NOW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "190dcbb3",
      "metadata": {
        "id": "190dcbb3"
      },
      "outputs": [],
      "source": [
        "deb_refs = get_images_vector(\"val/deblur/ref/\", 9440)\n",
        "deb_p0s = get_images_vector(\"val/deblur/p0/\", 9440)\n",
        "deb_p1s = get_images_vector(\"val/deblur/p1/\", 9440)\n",
        "\n",
        "fi_refs = get_images_vector(\"val/frameinterp/ref/\", 1888)\n",
        "fi_p0s = get_images_vector(\"val/frameinterp/p0/\", 1888)\n",
        "fi_p1s = get_images_vector(\"val/frameinterp/p1/\", 1888)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e570fb8a",
      "metadata": {
        "id": "e570fb8a",
        "outputId": "4dd1ca95-e2ae-4ead-f6e9-87b7bf117443"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4720\n",
            "4720\n",
            "4720\n"
          ]
        }
      ],
      "source": [
        "print(len(deb_refs))\n",
        "print(len(deb_p0s))\n",
        "print(len(deb_p1s))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25912505",
      "metadata": {
        "id": "25912505"
      },
      "outputs": [],
      "source": [
        "actual_model_predictions_deb_distortion = obtain_cosine_similarity_model_predictions(4720, deb_refs, deb_p0s, deb_p1s)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b696dd69",
      "metadata": {
        "id": "b696dd69"
      },
      "outputs": [],
      "source": [
        "prediction_accuracy_deb_distortion = obtain_prediction_accuracy(4720, \"val/deblur/judge/\", actual_model_predictions_deb_distortion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24fe912d",
      "metadata": {
        "id": "24fe912d",
        "outputId": "61bd0650-3f54-44c4-a02e-adeb73c55076"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.6016949152542372"
            ]
          },
          "execution_count": 99,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prediction_accuracy_deb_distortion"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dd7e700",
      "metadata": {
        "id": "6dd7e700"
      },
      "source": [
        "Prediction accuracy for Resnet-18 for deblurring distortions: 0.6016949152542372"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73f340a2",
      "metadata": {
        "id": "73f340a2"
      },
      "source": [
        "#### 1.4, 1.5 and 1.6 Deblurring, frame interpolation and super resolution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40b99584",
      "metadata": {
        "id": "40b99584",
        "outputId": "fca9b8f2-0ebe-43ca-d9b7-de866672149d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deblurring is complete\n",
            "FI is complete\n",
            "Spr is complete\n"
          ]
        }
      ],
      "source": [
        "deblur_refs = get_images_vector(\"val/deblur/ref/\", 9440)\n",
        "deblur_p0s = get_images_vector(\"val/deblur/p0/\", 9440)\n",
        "deblur_p1s = get_images_vector(\"val/deblur/p1/\", 9440)\n",
        "print(\"Deblurring is complete\")\n",
        "\n",
        "fi_refs = get_images_vector(\"val/frameinterp/ref/\", 1888)\n",
        "fi_p0s = get_images_vector(\"val/frameinterp/p0/\", 1888)\n",
        "fi_p1s = get_images_vector(\"val/frameinterp/p1/\", 1888)\n",
        "print(\"FI is complete\")\n",
        "\n",
        "spr_refs = get_images_vector(\"val/superres/ref/\", 10856)\n",
        "spr_p0s = get_images_vector(\"val/superres/p0/\", 10856)\n",
        "spr_p1s = get_images_vector(\"val/superres/p1/\", 10856)\n",
        "print(\"Spr is complete\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10596319",
      "metadata": {
        "id": "10596319",
        "outputId": "23d60384-bb5d-4f2b-c600-41b252b4b548"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deblur: \n",
            "0.6113347457627119\n",
            "----------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "actual_model_predictions_blur_distortion = obtain_cosine_similarity_model_predictions(9440, deblur_refs, deblur_p0s, deblur_p1s)\n",
        "prediction_accuracy_blur_distortion = obtain_prediction_accuracy(9440, \"val/deblur/judge/\", actual_model_predictions_blur_distortion)\n",
        "print(\"Deblur: \")\n",
        "print(prediction_accuracy_blur_distortion)\n",
        "print(\"----------------\")\n",
        "print(\"\")\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5e767016",
      "metadata": {
        "id": "5e767016",
        "outputId": "bea9373e-0be1-40a2-9f20-17a820ae6c2e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fi: \n",
            "0.6604872881355932\n",
            "----------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "actual_model_predictions_frame = obtain_cosine_similarity_model_predictions(1888, fi_refs, fi_p0s, fi_p1s)\n",
        "prediction_accuracy_frame = obtain_prediction_accuracy(1888, \"val/frameinterp/judge/\", actual_model_predictions_frame)\n",
        "print(\"Fi: \")\n",
        "print(prediction_accuracy_frame)\n",
        "print(\"----------------\")\n",
        "print(\"\")\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b85a9750",
      "metadata": {
        "id": "b85a9750",
        "outputId": "4a0e4ee8-087d-4ac7-aaaf-b859068cae73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Spr: \n",
            "0.7198784082535004\n",
            "----------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "actual_model_predictions_cnn_distortion_super = obtain_cosine_similarity_model_predictions(10856, spr_refs, spr_p0s, spr_p1s)\n",
        "prediction_accuracy_cnn_distortion_super = obtain_prediction_accuracy(10856, \"val/superres/judge/\", actual_model_predictions_cnn_distortion_super)\n",
        "print(\"Spr: \")\n",
        "print(prediction_accuracy_cnn_distortion_super)\n",
        "print(\"----------------\")\n",
        "print(\"\")\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "45c4672a",
      "metadata": {
        "id": "45c4672a"
      },
      "source": [
        "Prediction accuracy for Resnet-18 for deblurring distortions: 0.6113347457627119\n",
        "\n",
        "Prediction accuracy for Resnet-18 for frame interpolation distortions: 0.6604872881355932\n",
        "\n",
        "Prediction accuracy for Resnet-18 for super resolution distortions: 0.7198784082535004"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8eb9f1bc",
      "metadata": {
        "id": "8eb9f1bc"
      },
      "source": [
        "### 2. AlexNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3cad9bf9",
      "metadata": {
        "id": "3cad9bf9",
        "outputId": "9c48d905-9cfe-4132-9fd8-a05da2fb3c5a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Alexnet results:\n",
            "Deblurring is complete\n",
            "FI is complete\n",
            "Spr is complete\n",
            "Traditional: \n",
            "0.8108050847457627\n",
            "----------------\n",
            "\n",
            "\n",
            "CNN: \n",
            "0.8544491525423729\n",
            "----------------\n",
            "\n",
            "\n",
            "Colorization: \n",
            "0.6720338983050848\n",
            "----------------\n",
            "\n",
            "\n",
            "Deblur: \n",
            "0.639406779661017\n",
            "----------------\n",
            "\n",
            "\n",
            "Fi: \n",
            "0.666843220338983\n",
            "----------------\n",
            "\n",
            "\n",
            "Spr: \n",
            "0.7424465733235077\n",
            "----------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "from img2vec_pytorch import Img2Vec\n",
        "\n",
        "def format_image_number(number):\n",
        "    img_no_str = str(number)\n",
        "    \n",
        "    if len(img_no_str) == 1:\n",
        "        im_no_name = \"00000\"\n",
        "    elif len(img_no_str) == 2:\n",
        "        im_no_name = \"0000\"\n",
        "    elif len(img_no_str) == 3:\n",
        "        im_no_name = \"000\"\n",
        "    elif len(img_no_str) == 4:\n",
        "        im_no_name = \"00\"\n",
        "    elif len(img_no_str) == 5:\n",
        "        im_no_name = \"0\"\n",
        "    elif len(img_no_str) == 6:\n",
        "        im_no_name = \"\"\n",
        "        \n",
        "    return im_no_name + img_no_str\n",
        "    \n",
        "img2vec = Img2Vec(cuda=False, model=\"alexnet\")  # default model resnet\n",
        "\n",
        "def get_images_vector(path, number_of_images):  # returns a list of tensors\n",
        "    # path of form: traditional/ref/\n",
        "    feature_tensor_list = []\n",
        "    \n",
        "    for image_no in range(number_of_images):\n",
        "        image_no_str = str(image_no)\n",
        "        \n",
        "        im_no_name = format_image_number(image_no_str) + \".png\"\n",
        "        \n",
        "        path_to_image = path + im_no_name\n",
        "\n",
        "        feature_vector_image = Image.open(path_to_image).convert('RGB')\n",
        "        feature_vec = img2vec.get_vec(feature_vector_image, tensor=True)\n",
        "        feature_tensor_list.append(feature_vec)\n",
        "        \n",
        "    return feature_tensor_list\n",
        "\n",
        "def obtain_cosine_similarity_model_predictions(number_of_images, refs_vec_list, p0s_rec_list, p1s_rec_list):\n",
        "    cosine_similarity_ref_and_p0 = []\n",
        "    cosine_similarity_ref_and_p1 = []\n",
        "\n",
        "    # list of predictions\n",
        "    cosine_similarity_predictions = []\n",
        "    \n",
        "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "    # cos_sim = cos(query_vector.unsqueeze(0), ref2_vector.unsqueeze(0))\n",
        "\n",
        "    for image_no in range(number_of_images): \n",
        "        reshaped_ref = refs_vec_list[image_no]\n",
        "        reshaped_p0 = p0s_rec_list[image_no]\n",
        "        reshaped_p1 = p1s_rec_list[image_no]\n",
        "        \n",
        "        cosine_similarity_ref_and_p0.append(cos(reshaped_ref, reshaped_p0))\n",
        "        cosine_similarity_ref_and_p1.append(cos(reshaped_ref, reshaped_p1))\n",
        "\n",
        "        if cosine_similarity_ref_and_p0[image_no] >= cosine_similarity_ref_and_p1[image_no]:\n",
        "            cosine_similarity_predictions.append(0)\n",
        "        else:\n",
        "            cosine_similarity_predictions.append(1)   \n",
        "            \n",
        "    return cosine_similarity_predictions\n",
        "\n",
        "def obtain_prediction_accuracy(number_of_images, path_to_decision, actual_predictions):\n",
        "    expected_decision_outputs = []\n",
        "\n",
        "    for image_no in range(number_of_images):\n",
        "            image_no_str = str(image_no)\n",
        "\n",
        "            im_no_name = format_image_number(image_no_str) + \".npy\"\n",
        "            path_to_image = path_to_decision + im_no_name\n",
        "\n",
        "            decision = np.load(path_to_image)\n",
        "\n",
        "            if decision[0] <= 0.5: \n",
        "                expected_decision_outputs.append(0)\n",
        "            else: \n",
        "                expected_decision_outputs.append(1)\n",
        "                \n",
        "    number_wrong_predictions = 0\n",
        "\n",
        "    for image_no in range(number_of_images):\n",
        "        if actual_predictions[image_no] != expected_decision_outputs[image_no]:\n",
        "            number_wrong_predictions += 1\n",
        "\n",
        "    accuracy = (number_of_images - number_wrong_predictions)/(number_of_images)\n",
        "    \n",
        "    return accuracy\n",
        "\n",
        "\n",
        "def reshape_tensor_list(dim, tensor_list):\n",
        "    reshaped_list = []\n",
        "    for t in tensor_list:\n",
        "        reshaped_t = torch.reshape(t, (1,dim))\n",
        "        reshaped_list.append(t)\n",
        "    return reshaped_list\n",
        "\n",
        "\n",
        "\n",
        "print(\"Alexnet results:\")\n",
        "\n",
        "img2vec_res = Img2Vec(cuda=False, model=\"alexnet\")  # default model resnet\n",
        "\n",
        "traditional_refs = get_images_vector(\"val/traditional/ref/\", 4720)\n",
        "traditional_p0s = get_images_vector(\"val/traditional/p0/\", 4720)\n",
        "traditional_p1s = get_images_vector(\"val/traditional/p1/\", 4720)\n",
        "\n",
        "cnn_refs = get_images_vector(\"val/cnn/ref/\", 4720)\n",
        "cnn_p0s = get_images_vector(\"val/cnn/p0/\", 4720)\n",
        "cnn_p1s = get_images_vector(\"val/cnn/p1/\", 4720)\n",
        "\n",
        "color_refs = get_images_vector(\"val/color/ref/\", 4720)\n",
        "color_p0s = get_images_vector(\"val/color/p0/\", 4720)\n",
        "color_p1s = get_images_vector(\"val/color/p1/\", 4720)\n",
        "\n",
        "deblur_refs = get_images_vector(\"val/deblur/ref/\", 9440)\n",
        "deblur_p0s = get_images_vector(\"val/deblur/p0/\", 9440)\n",
        "deblur_p1s = get_images_vector(\"val/deblur/p1/\", 9440)\n",
        "print(\"Deblurring is complete\")\n",
        "\n",
        "fi_refs = get_images_vector(\"val/frameinterp/ref/\", 1888)\n",
        "fi_p0s = get_images_vector(\"val/frameinterp/p0/\", 1888)\n",
        "fi_p1s = get_images_vector(\"val/frameinterp/p1/\", 1888)\n",
        "print(\"FI is complete\")\n",
        "\n",
        "spr_refs = get_images_vector(\"val/superres/ref/\", 10856)\n",
        "spr_p0s = get_images_vector(\"val/superres/p0/\", 10856)\n",
        "spr_p1s = get_images_vector(\"val/superres/p1/\", 10856)\n",
        "print(\"Spr is complete\")\n",
        "\n",
        "\n",
        "actual_model_predictions = obtain_cosine_similarity_model_predictions(4720, traditional_refs, traditional_p0s, traditional_p1s)\n",
        "prediction_accuracy = obtain_prediction_accuracy(4720, \"val/traditional/judge/\", actual_model_predictions)\n",
        "print(\"Traditional: \")\n",
        "print(prediction_accuracy)\n",
        "print(\"----------------\")\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "actual_model_predictions_cnn_distortion = obtain_cosine_similarity_model_predictions(4720, cnn_refs, cnn_p0s, cnn_p1s)\n",
        "prediction_accuracy_cnn_distortion = obtain_prediction_accuracy(4720, \"val/cnn/judge/\", actual_model_predictions_cnn_distortion)\n",
        "print(\"CNN: \")\n",
        "print(prediction_accuracy_cnn_distortion)\n",
        "print(\"----------------\")\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "actual_model_predictions_color_distortion = obtain_cosine_similarity_model_predictions(4720, color_refs, color_p0s, color_p1s)\n",
        "prediction_accuracy_color_distortion = obtain_prediction_accuracy(4720, \"val/color/judge/\", actual_model_predictions_color_distortion)\n",
        "print(\"Colorization: \")\n",
        "print(prediction_accuracy_color_distortion)\n",
        "print(\"----------------\")\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "actual_model_predictions_blur_distortion = obtain_cosine_similarity_model_predictions(9440, deblur_refs, deblur_p0s, deblur_p1s)\n",
        "prediction_accuracy_blur_distortion = obtain_prediction_accuracy(9440, \"val/deblur/judge/\", actual_model_predictions_blur_distortion)\n",
        "print(\"Deblur: \")\n",
        "print(prediction_accuracy_blur_distortion)\n",
        "print(\"----------------\")\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "\n",
        "actual_model_predictions_frame = obtain_cosine_similarity_model_predictions(1888, fi_refs, fi_p0s, fi_p1s)\n",
        "prediction_accuracy_frame = obtain_prediction_accuracy(1888, \"val/frameinterp/judge/\", actual_model_predictions_frame)\n",
        "print(\"Fi: \")\n",
        "print(prediction_accuracy_frame)\n",
        "print(\"----------------\")\n",
        "print(\"\")\n",
        "print(\"\")\n",
        "\n",
        "actual_model_predictions_cnn_distortion_super = obtain_cosine_similarity_model_predictions(10856, spr_refs, spr_p0s, spr_p1s)\n",
        "prediction_accuracy_cnn_distortion_super = obtain_prediction_accuracy(10856, \"val/superres/judge/\", actual_model_predictions_cnn_distortion_super)\n",
        "print(\"Spr: \")\n",
        "print(prediction_accuracy_cnn_distortion_super)\n",
        "print(\"----------------\")\n",
        "print(\"\")\n",
        "print(\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d1abe4f",
      "metadata": {
        "id": "7d1abe4f"
      },
      "source": [
        "AlexNet: \n",
        "    \n",
        "Traditional: \n",
        "0.8108050847457627\n",
        "\n",
        "\n",
        "CNN: \n",
        "0.8544491525423729\n",
        "\n",
        "\n",
        "\n",
        "Colorization: \n",
        "0.6720338983050848\n",
        "\n",
        "\n",
        "\n",
        "Deblur: \n",
        "0.639406779661017\n",
        "\n",
        "\n",
        "\n",
        "Fi: \n",
        "0.666843220338983\n",
        "\n",
        "\n",
        "\n",
        "Spr: \n",
        "0.7424465733235077"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> NEW START HERE </h1>\n",
        "\n",
        "Link: https://becominghuman.ai/extract-a-feature-vector-for-any-image-with-pytorch-9717561d1d4c\n",
        " + modify to adhere to current PyTorch updates"
      ],
      "metadata": {
        "id": "Mq-M8hr-PPD3"
      },
      "id": "Mq-M8hr-PPD3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "*What we have done here is created a reference to the layer we want to extract from. Deciding on which layer to extract from is a bit of a science, but something to keep in mind is that early layers in the network are usually learning high-level features such as ‘image contains fur’ or ‘image contains round object’, while lower-level features are more specific to the training data. The ‘avgpool’ layer selected here is at the end of ResNet-18, but if you plan to use images that are very different from ImageNet, you may benefit in using an ealier layer or fine-tuning the model.*\n",
        "\n",
        "Conclusion for me: because later layers are more specific to training data THEN I am expecting all models to perform much better on HSJ and the worst on Distortions.\n",
        "\n",
        "\n",
        "**But if you plan to use images that are very different from ImageNet, you may benefit in using an ealier layer or fine-tuning the model.**"
      ],
      "metadata": {
        "id": "Q04PUL8MP15O"
      },
      "id": "Q04PUL8MP15O"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from PIL import Image"
      ],
      "metadata": {
        "id": "HB2oe9hIPOqW"
      },
      "id": "HB2oe9hIPOqW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretrained model\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.cuda()\n",
        "# Use the model object to select the desired layer\n",
        "layer = model._modules.get('avgpool')\n",
        "# Set model to evaluation mode\n",
        "model.eval()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBVpBNLPPbdI",
        "outputId": "7e897c3d-bffd-4ba7-a885-52e1c7fcfd78"
      },
      "id": "rBVpBNLPPbdI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zeDECMcrY0dz"
      },
      "id": "zeDECMcrY0dz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set model to evaluation mode\n",
        "model.eval()"
      ],
      "metadata": {
        "id": "VX14Yl0tPgou"
      },
      "id": "VX14Yl0tPgou",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = transforms.Resize((224, 224))\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "to_tensor = transforms.ToTensor()   # used to convert the PIL image to a PyTorch tensor (multidimensional array)"
      ],
      "metadata": {
        "id": "B-hulT0xQa5z"
      },
      "id": "B-hulT0xQa5z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vector(image_name):\n",
        "    \n",
        "#     # Load the pretrained model\n",
        "#     model = models.resnet18(pretrained=True)\n",
        "#     # Use the model object to select the desired layer\n",
        "#     layer = model._modules.get('avgpool')\n",
        "    \n",
        "    # 1. Load the image with Pillow library\n",
        "    img = Image.open(image_name).convert('RGB')\n",
        "    # 2. Create a PyTorch Variable with the transformed image\n",
        "    t_img = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0)).cuda()\n",
        "    # 3. Create a vector of zeros that will hold our feature vector\n",
        "    #    The 'avgpool' layer has an output size of 512\n",
        "    \n",
        "    # M1: my_embedding = torch.zeros(1, 512, 1, 1) and later my_embedding.copy_(o.data)\n",
        "    # M2: my_embedding = torch.zeros(512) and later my_embedding.copy_(o.data.reshape(o.data.size(1)))\n",
        "    my_embedding = torch.zeros(512).cuda()\n",
        "    \n",
        "    # 4. Define a function that will copy the output of a layer\n",
        "    def copy_data(m, i, o):\n",
        "        my_embedding.copy_(o.data.reshape(o.data.size(1)))\n",
        "    # 5. Attach that function to our selected layer\n",
        "    h = layer.register_forward_hook(copy_data)\n",
        "    # 6. Run the model on our transformed image\n",
        "    model(t_img)\n",
        "    # 7. Detach our copy function from the layer\n",
        "    h.remove()\n",
        "    # 8. Return the feature vector\n",
        "    return my_embedding"
      ],
      "metadata": {
        "id": "WVhuqcJzQvYq"
      },
      "id": "WVhuqcJzQvYq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "query_vector = get_vector(\"ref.png\")\n",
        "ref1_vector = get_vector(\"p0.png\")\n",
        "ref2_vector = get_vector(\"p1.png\")"
      ],
      "metadata": {
        "id": "7uzFV2c5Rn5_"
      },
      "id": "7uzFV2c5Rn5_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Using PyTorch Cosine Similarity\n",
        "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "cos_sim = cos(query_vector.unsqueeze(0),\n",
        "              ref1_vector.unsqueeze(0))\n",
        "print('\\nCosine similarity: {0}\\n'.format(cos_sim))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gaZmhKNnYZ3z",
        "outputId": "9729938c-1ff9-4ee0-fa92-0a57752b2c3f"
      },
      "id": "gaZmhKNnYZ3z",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cosine similarity: tensor([0.8143], device='cuda:0')\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Using PyTorch Cosine Similarity\n",
        "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "cos_sim = cos(query_vector.unsqueeze(0),\n",
        "              ref2_vector.unsqueeze(0))\n",
        "print('\\nCosine similarity: {0}\\n'.format(cos_sim))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FrMsaD6PYhpr",
        "outputId": "d27f9f43-d5a5-430d-8548-95b6e56d8ebd"
      },
      "id": "FrMsaD6PYhpr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cosine similarity: tensor([0.5251], device='cuda:0')\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_image_embeddings(path, image_type):  # returns a list of tensors\n",
        "    # path of form: traditional/ref/\n",
        "    feature_tensor_dict = dict()\n",
        "    feature_tensor_dict[\"ref\"] = []\n",
        "    feature_tensor_dict[\"p0\"] = []\n",
        "    feature_tensor_dict[\"p1\"] = []\n",
        "    feature_tensor_dict[\"decision\"] = []\n",
        "    \n",
        "    for image_no in range(1000):\n",
        "        im_no_name =  (6-len(str(image_no)))*\"0\" + str(image_no) + \".\" + image_type\n",
        "        \n",
        "        feature_tensor_dict[\"ref\"].append(get_vector(path+\"/ref/\" + im_no_name))\n",
        "        feature_tensor_dict[\"p0\"].append(get_vector(path+\"/p0/\" + im_no_name))\n",
        "        feature_tensor_dict[\"p1\"].append(get_vector(path+\"/p1/\" + im_no_name))\n",
        "\n",
        "        # now load decision\n",
        "        decision_no_name =  (6-len(str(image_no)))*\"0\" + str(image_no) + \".npy\"\n",
        "        decision = np.load(path+\"/judge/\"+decision_no_name)\n",
        "        if decision[0] <= 0.5: \n",
        "              feature_tensor_dict[\"decision\"].append(0)\n",
        "        else: \n",
        "              feature_tensor_dict[\"decision\"].append(1)\n",
        "        \n",
        "    return feature_tensor_dict"
      ],
      "metadata": {
        "id": "q3nySb9GaiUH"
      },
      "id": "q3nySb9GaiUH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eu9hP7FRc-Ln",
        "outputId": "9eb4ea8b-0827-46c5-c49c-5de07cd1afcf"
      },
      "id": "Eu9hP7FRc-Ln",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_18_embedddings = get_image_embeddings(\"datasets/distortions/distortion_triplets/traditional_triplets\", \"png\")"
      ],
      "metadata": {
        "id": "Cs_f5-mydPO9"
      },
      "id": "Cs_f5-mydPO9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_18_embedddings[\"decision\"]"
      ],
      "metadata": {
        "id": "DK7DPu2RnkQ2"
      },
      "id": "DK7DPu2RnkQ2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_predictions(embeddings):\n",
        "  cosine_similarity_dict = dict()\n",
        "  cosine_similarity_dict[\"ref_and_p0\"] = []\n",
        "  cosine_similarity_dict[\"ref_and_p1\"] = []\n",
        "  cosine_similarity_predictions = []\n",
        "\n",
        "  cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "  # cos_sim = cos(query_vector.unsqueeze(0), ref2_vector.unsqueeze(0))\n",
        "\n",
        "  for image_no in range(1000):\n",
        "      cosine_similarity_dict[\"ref_and_p0\"].append(cos(embeddings[\"ref\"][image_no].unsqueeze(0), embeddings[\"p0\"][image_no].unsqueeze(0)))\n",
        "      cosine_similarity_dict[\"ref_and_p1\"].append(cos(embeddings[\"ref\"][image_no].unsqueeze(0), embeddings[\"p1\"][image_no].unsqueeze(0)))\n",
        "      \n",
        "      if cosine_similarity_dict[\"ref_and_p0\"][image_no] >= cosine_similarity_dict[\"ref_and_p1\"][image_no]:\n",
        "          cosine_similarity_predictions.append(0)\n",
        "      else:\n",
        "          cosine_similarity_predictions.append(1)   \n",
        "  return cosine_similarity_predictions\n",
        "\n",
        "def get_accuracy(predictions,embeddings):\n",
        "  decisions = embeddings[\"decision\"]\n",
        "\n",
        "  number_wrong_predictions = 0\n",
        "\n",
        "  for image_no in range(1000):\n",
        "      if predictions[image_no] != decisions[image_no]:\n",
        "          number_wrong_predictions += 1\n",
        "      \n",
        "  accuracy = (1000 - number_wrong_predictions)/(1000)\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "V6S5kBKBjo-l"
      },
      "id": "V6S5kBKBjo-l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = get_predictions(resnet_18_embedddings)\n",
        "accuracy = get_accuracy(predictions, resnet_18_embedddings)"
      ],
      "metadata": {
        "id": "Wt9bjXlSmkIH"
      },
      "id": "Wt9bjXlSmkIH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcbOFa1EoGFD",
        "outputId": "9d2ff7d7-ac18-4895-c83d-6bb5db1fcc40"
      },
      "id": "KcbOFa1EoGFD",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.809"
            ]
          },
          "metadata": {},
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Loading dataset and drive </h1>"
      ],
      "metadata": {
        "id": "zIgDgfIQxc5h"
      },
      "id": "zIgDgfIQxc5h"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install img2vec-pytorch"
      ],
      "metadata": {
        "id": "2qDJIombxf-I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45fd392a-5673-4dc8-85e4-98affb13c735"
      },
      "id": "2qDJIombxf-I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting img2vec-pytorch\n",
            "  Downloading img2vec_pytorch-1.0.1-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from img2vec-pytorch) (0.14.1+cu116)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from img2vec-pytorch) (1.13.1+cu116)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from img2vec-pytorch) (1.22.4)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->img2vec-pytorch) (4.5.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision->img2vec-pytorch) (2.27.1)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->img2vec-pytorch) (8.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->img2vec-pytorch) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->img2vec-pytorch) (2.0.12)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->img2vec-pytorch) (1.26.15)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->img2vec-pytorch) (3.4)\n",
            "Installing collected packages: img2vec-pytorch\n",
            "Successfully installed img2vec-pytorch-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -uq \"/content/drive/MyDrive/Colab Notebooks/distortion_triplets.zip\" -d \"/content/datasets/distortions\"\n",
        "!unzip -uq \"/content/drive/MyDrive/Colab Notebooks/hsj_triplets.zip\" -d \"/content/datasets/hsj\"\n",
        "!unzip -uq \"/content/drive/MyDrive/Colab Notebooks/birds_dataset_triplets.zip\" -d \"/content/datasets/birds-16\""
      ],
      "metadata": {
        "id": "D5OMjLX7dxhD"
      },
      "id": "D5OMjLX7dxhD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Working framework start </h1>"
      ],
      "metadata": {
        "id": "M1x9m7iwoV6B"
      },
      "id": "M1x9m7iwoV6B"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "############################ REQUIRES MODIFICATION FOR EACH MODEL \n",
        "\n",
        "# scaler = transforms.Resize((224, 224))\n",
        "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "#                                  std=[0.229, 0.224, 0.225])\n",
        "to_tensor = transforms.ToTensor()   # used to convert the PIL image to a PyTorch tensor (multidimensional array)\n",
        "############################\n",
        "\n",
        "\n",
        "############################## HOW TO GET MODEL:\n",
        "# # Load the pretrained model\n",
        "# model = models.resnet18(pretrained=True)\n",
        "# model.cuda()\n",
        "# # Use the model object to select the desired layer\n",
        "# layer = model._modules.get('avgpool')\n",
        "# # Set model to evaluation mode\n",
        "# model.eval()\n",
        "\n",
        "##################################\n",
        "\n",
        "def get_vector(image_name, model, layer, scaler, normalize, feature_tensor_size):\n",
        "    \n",
        "#     # Load the pretrained model\n",
        "#     model = models.resnet18(pretrained=True)\n",
        "#     # Use the model object to select the desired layer\n",
        "#     layer = model._modules.get('avgpool')\n",
        "    \n",
        "    # 1. Load the image with Pillow library\n",
        "    img = Image.open(image_name).convert('RGB')\n",
        "    # 2. Create a PyTorch Variable with the transformed image\n",
        "    t_img = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0)).cuda()\n",
        "    # 3. Create a vector of zeros that will hold our feature vector\n",
        "    #    The 'avgpool' layer has an output size of 512\n",
        "    \n",
        "    # M1: my_embedding = torch.zeros(1, 512, 1, 1) and later my_embedding.copy_(o.data)\n",
        "    # M2: my_embedding = torch.zeros(512) and later my_embedding.copy_(o.data.reshape(o.data.size(1)))\n",
        "    my_embedding = torch.zeros(feature_tensor_size).cuda()\n",
        "    \n",
        "    # 4. Define a function that will copy the output of a layer\n",
        "    def copy_data(m, i, o):\n",
        "        my_embedding.copy_(o.data.reshape(o.data.size(1)))\n",
        "    # 5. Attach that function to our selected layer\n",
        "    h = layer.register_forward_hook(copy_data)\n",
        "    # 6. Run the model on our transformed image\n",
        "    model(t_img)\n",
        "    # 7. Detach our copy function from the layer\n",
        "    h.remove()\n",
        "    # 8. Return the feature vector\n",
        "    return my_embedding\n",
        "    \n",
        "\n",
        "############################ COSINE SIMILARITY\n",
        "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "\n",
        "\n",
        "########################### GET FEATURE VECTORS\n",
        "def get_image_embeddings(path, image_type, model, layer, scaler, normalize, isHSJOrBirds, feature_tensor_size):  # returns a list of tensors\n",
        "    # path of form: traditional/ref/\n",
        "    feature_tensor_dict = dict()\n",
        "    feature_tensor_dict[\"ref\"] = []\n",
        "    feature_tensor_dict[\"p0\"] = []\n",
        "    feature_tensor_dict[\"p1\"] = []\n",
        "    feature_tensor_dict[\"decision\"] = []\n",
        "    \n",
        "    for image_no in range(1000):\n",
        "        im_no_name =  (6-len(str(image_no)))*\"0\" + str(image_no) + \".\" + image_type\n",
        "        \n",
        "        feature_tensor_dict[\"ref\"].append(get_vector(path+\"/ref/\" + im_no_name, model, layer, scaler, normalize, feature_tensor_size))\n",
        "        feature_tensor_dict[\"p0\"].append(get_vector(path+\"/p0/\" + im_no_name, model, layer, scaler, normalize, feature_tensor_size))\n",
        "        feature_tensor_dict[\"p1\"].append(get_vector(path+\"/p1/\" + im_no_name, model, layer, scaler, normalize, feature_tensor_size))\n",
        "\n",
        "        # now load decision\n",
        "        if isHSJOrBirds:\n",
        "          feature_tensor_dict[\"decision\"].append(0)\n",
        "        else: \n",
        "          decision_no_name =  (6-len(str(image_no)))*\"0\" + str(image_no) + \".npy\"\n",
        "          decision = np.load(path+\"/judge/\"+decision_no_name)\n",
        "          if decision[0] <= 0.5: \n",
        "                feature_tensor_dict[\"decision\"].append(0)\n",
        "          else: \n",
        "                feature_tensor_dict[\"decision\"].append(1)\n",
        "        \n",
        "    return feature_tensor_dict\n",
        "\n",
        "\n",
        "########################## GET MODEL PREDICTIONS\n",
        "def get_predictions(embeddings):\n",
        "  cosine_similarity_dict = dict()\n",
        "  cosine_similarity_dict[\"ref_and_p0\"] = []\n",
        "  cosine_similarity_dict[\"ref_and_p1\"] = []\n",
        "  cosine_similarity_predictions = []\n",
        "\n",
        "  cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "  # cos_sim = cos(query_vector.unsqueeze(0), ref2_vector.unsqueeze(0))\n",
        "\n",
        "  for image_no in range(1000):\n",
        "      cosine_similarity_dict[\"ref_and_p0\"].append(cos(embeddings[\"ref\"][image_no].unsqueeze(0), embeddings[\"p0\"][image_no].unsqueeze(0)))\n",
        "      cosine_similarity_dict[\"ref_and_p1\"].append(cos(embeddings[\"ref\"][image_no].unsqueeze(0), embeddings[\"p1\"][image_no].unsqueeze(0)))\n",
        "      \n",
        "      if cosine_similarity_dict[\"ref_and_p0\"][image_no] >= cosine_similarity_dict[\"ref_and_p1\"][image_no]:\n",
        "          cosine_similarity_predictions.append(0)\n",
        "      else:\n",
        "          cosine_similarity_predictions.append(1)   \n",
        "  return cosine_similarity_predictions\n",
        "\n",
        "########################## GET MODEL ACCURACY\n",
        "def get_accuracy(predictions,embeddings):\n",
        "  decisions = embeddings[\"decision\"]\n",
        "\n",
        "  number_wrong_predictions = 0\n",
        "\n",
        "  for image_no in range(1000):\n",
        "      if predictions[image_no] != decisions[image_no]:\n",
        "          number_wrong_predictions += 1\n",
        "      \n",
        "  accuracy = (1000 - number_wrong_predictions)/(1000)\n",
        "  return accuracy\n",
        "\n",
        "\n",
        "def apply_framework(path, image_type, model, layer, scaler, normalize, isHSJOrBirds, feature_tensor_size):\n",
        "  embeddings = get_image_embeddings(path, \n",
        "                                    image_type,\n",
        "                                    model, layer, scaler, normalize, isHSJOrBirds, feature_tensor_size)\n",
        "  predictions= get_predictions(embeddings)\n",
        "  accuracy = get_accuracy(predictions, embeddings)\n",
        "  print(path + \": \" + str(accuracy))\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "7D9166cvobDh"
      },
      "id": "7D9166cvobDh",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "    # 1. Load the image with Pillow library\n",
        "img = Image.open(\"datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar/p0/000000.jpg\").convert('RGB')\n",
        "    # 2. Create a PyTorch Variable with the transformed image\n",
        "scaler = transforms.Resize((224, 224))\n",
        "t_img = scaler(img)\n",
        "t_img"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "PtspBYvyumJR",
        "outputId": "435e16a7-eb2b-42d3-8527-833c679dd024"
      },
      "id": "PtspBYvyumJR",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=RGB size=224x224 at 0x7F12235E32E0>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Resnet-18 + cosine similarity\n",
        "\n",
        "datasets/distortions/distortion_triplets/traditional_triplets: 0.809\n",
        "\n",
        "datasets/distortions/distortion_triplets/cnn_triplets: 0.848\n",
        "\n",
        "datasets/distortions/distortion_triplets/color_triplets: 0.623\n",
        "\n",
        "datasets/distortions/distortion_triplets/deblur_triplets: 0.603\n",
        "\n",
        "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.663\n",
        "\n",
        "datasets/distortions/distortion_triplets/superres_triplets: 0.723"
      ],
      "metadata": {
        "id": "-pJ_BUwHp5uU"
      },
      "id": "-pJ_BUwHp5uU"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretrained model\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.cuda()\n",
        "# Use the model object to select the desired layer\n",
        "layer = model._modules.get('avgpool')\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "scaler = transforms.Resize((224, 224))\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "print(\"# ----------------------------------------BAPPS 2AFC DIST RESNET-18------------------------#\")\n",
        "print(\"\")\n",
        "################### TRADITIONAL \n",
        "apply_framework(\"datasets/distortions/distortion_triplets/traditional_triplets\",\n",
        "                \"png\",\n",
        "                model, layer, scaler, normalize, False)\n",
        "\n",
        "################ CNN\n",
        "apply_framework(\"datasets/distortions/distortion_triplets/cnn_triplets\",\n",
        "                \"png\",\n",
        "                model, layer, scaler, normalize, False)\n",
        "\n",
        "############### COLOR\n",
        "apply_framework(\"datasets/distortions/distortion_triplets/color_triplets\",\n",
        "                \"png\",\n",
        "                model, layer, scaler, normalize, False)\n",
        "\n",
        "################ DEBLUR\n",
        "apply_framework(\"datasets/distortions/distortion_triplets/deblur_triplets\",\n",
        "                \"png\",\n",
        "                model, layer, scaler, normalize, False)\n",
        "\n",
        "############### FRAME INTERP\n",
        "apply_framework(\"datasets/distortions/distortion_triplets/frameinterp_triplets\",\n",
        "                \"png\",\n",
        "                model, layer, scaler, normalize, False)\n",
        "\n",
        "################ SUPER RES\n",
        "apply_framework(\"datasets/distortions/distortion_triplets/superres_triplets\",\n",
        "                \"png\",\n",
        "                model, layer, scaler, normalize, False)\n",
        "\n",
        "# datasets/distortions/distortion_triplets/traditional_triplets: 0.809\n",
        "# datasets/distortions/distortion_triplets/cnn_triplets: 0.848\n",
        "# datasets/distortions/distortion_triplets/color_triplets: 0.623\n",
        "# datasets/distortions/distortion_triplets/deblur_triplets: 0.603\n",
        "# datasets/distortions/distortion_triplets/frameinterp_triplets: 0.663\n",
        "# datasets/distortions/distortion_triplets/superres_triplets: 0.723"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "do-kyNnap4wa",
        "outputId": "a6f3923b-851b-4fff-e015-34cd393e5398"
      },
      "id": "do-kyNnap4wa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# ----------------------------------------BAPPS 2AFC DIST RESNET-18------------------------#\n",
            "\n",
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.809\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.848\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.623\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.603\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.663\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.723\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.723"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###BAPPS 2AFC DIST RESNET-18+Cosine Similarity\n",
        "\n",
        "datasets/distortions/distortion_triplets/traditional_triplets: 0.809\n",
        "\n",
        "datasets/distortions/distortion_triplets/cnn_triplets: 0.848\n",
        "\n",
        "datasets/distortions/distortion_triplets/color_triplets: 0.623\n",
        "\n",
        "datasets/distortions/distortion_triplets/deblur_triplets: 0.603\n",
        "\n",
        "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.663\n",
        "\n",
        "datasets/distortions/distortion_triplets/superres_triplets: 0.723\n",
        "\n",
        "\n",
        "----------------------------------------HSJ------------------------\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.695\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.597\n",
        "\n",
        "----------------------------------------Birds-16------------------------\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.791\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.599\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.786"
      ],
      "metadata": {
        "id": "_uDcYjVTeW1p"
      },
      "id": "_uDcYjVTeW1p"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretrained model\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.cuda()\n",
        "# Use the model object to select the desired layer\n",
        "layer = model._modules.get('avgpool')\n",
        "# Set model to evaluation mode\n",
        "model.eval()\n",
        "scaler = transforms.Resize((224, 224))\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "print(\"# ----------------------------------------HSJ------------------------#\")\n",
        "print(\"\")\n",
        "################### HSJ Rank 0 + Dissimilar \n",
        "apply_framework(\"datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar\",\n",
        "                \"jpg\",\n",
        "                model, layer, scaler, normalize, True)\n",
        "\n",
        "################ HSJ Rank 0 + Rank 1\n",
        "apply_framework(\"datasets/hsj/hsj_triplets/hsj_query_rank0_rank1\",\n",
        "                \"jpg\",\n",
        "                model, layer, scaler, normalize, True)\n",
        "\n",
        "print(\"# ----------------------------------------Birds-16------------------------#\")\n",
        "print(\"\")\n",
        "################### Birds-16 Rank 0 + Dissimilar \n",
        "apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar\",\n",
        "                \"jpg\",\n",
        "                model, layer, scaler, normalize, True)\n",
        "\n",
        "################### Birds-16 Rank 0 + Rank 1 \n",
        "apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1\",\n",
        "                \"jpg\",\n",
        "                model, layer, scaler, normalize, True)\n",
        "\n",
        "################### Birds-16 Rank 0 + Dissimilar 2rank1 test\n",
        "apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1\",\n",
        "                \"jpg\",\n",
        "                model, layer, scaler, normalize, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFKC2UV0togy",
        "outputId": "87a117cf-fc38-4b2f-ec03-ff9718e17008"
      },
      "id": "iFKC2UV0togy",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.695\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.597\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.791\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.599\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.786\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.786"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretrained model\n",
        "model2 = models.resnet34(pretrained=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156,
          "referenced_widgets": [
            "bca6d128c81c4b1596e23411c8939c43",
            "f3e1a8617cb748a39f282c11b9491e0a",
            "d3e31a9020364e64be5c1ee8950e48b3",
            "7548b65877f94225ae7889578eab5db2",
            "75708c28b4694cee90680050814f3aa4",
            "893c1dca55e44bcaa5e35d8c22fa8636",
            "5372c90c9580459ab96dc596ac1361d5",
            "0f7d3090a62545049b4ebc69e7fd5f21",
            "fdd5022ec0ab422db94c6392eb0202f1",
            "009229f9541b4e25b6aa5b8a9724865c",
            "71eaa211a3a9407083de38c547cc3305"
          ]
        },
        "id": "0mIL7Zw4j9T5",
        "outputId": "671418bd-f591-4cab-9ef0-8c5c71caf5fc"
      },
      "id": "0mIL7Zw4j9T5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/83.3M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bca6d128c81c4b1596e23411c8939c43"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Resnet-34\n",
        "\n",
        "----------------------------------------BAPPS 2AFC DIST RESNET-18------------------------\n",
        "\n",
        "datasets/distortions/distortion_triplets/traditional_triplets: 0.801\n",
        "\n",
        "datasets/distortions/distortion_triplets/cnn_triplets: 0.851\n",
        "\n",
        "\n",
        "datasets/distortions/distortion_triplets/color_triplets: 0.626\n",
        "\n",
        "datasets/distortions/distortion_triplets/deblur_triplets: 0.601\n",
        "\n",
        "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.652\n",
        "\n",
        "datasets/distortions/distortion_triplets/superres_triplets: 0.725\n",
        "\n",
        "----------------------------------------HSJ------------------------\n",
        "\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.691\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.574\n",
        "\n",
        " ----------------------------------------Birds-16------------------------\n",
        "\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.775\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.611\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.\n",
        "753"
      ],
      "metadata": {
        "id": "yoN4xJgekSIK"
      },
      "id": "yoN4xJgekSIK"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretrained model\n",
        "model2 = models.resnet34(pretrained=True)\n",
        "model2.cuda()\n",
        "# Use the model object to select the desired layer\n",
        "layer = model2._modules.get('avgpool')\n",
        "# Set model to evaluation mode\n",
        "model2.eval()\n",
        "scaler = transforms.Resize((224, 224))\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "print(\"\")\n",
        "print(\"# ----------------------------------------BAPPS 2AFC DIST-----------------------#\")\n",
        "print(\"\")\n",
        "################### TRADITIONAL \n",
        "apply_framework(\"datasets/distortions/distortion_triplets/traditional_triplets\",\n",
        "                \"png\",\n",
        "                model2, layer, scaler, normalize, False)\n",
        "\n",
        "################ CNN\n",
        "apply_framework(\"datasets/distortions/distortion_triplets/cnn_triplets\",\n",
        "                \"png\",\n",
        "                model2, layer, scaler, normalize, False)\n",
        "\n",
        "############### COLOR\n",
        "apply_framework(\"datasets/distortions/distortion_triplets/color_triplets\",\n",
        "                \"png\",\n",
        "                model2, layer, scaler, normalize, False)\n",
        "\n",
        "################ DEBLUR\n",
        "apply_framework(\"datasets/distortions/distortion_triplets/deblur_triplets\",\n",
        "                \"png\",\n",
        "                model2, layer, scaler, normalize, False)\n",
        "\n",
        "############### FRAME INTERP\n",
        "apply_framework(\"datasets/distortions/distortion_triplets/frameinterp_triplets\",\n",
        "                \"png\",\n",
        "                model2, layer, scaler, normalize, False)\n",
        "\n",
        "################ SUPER RES\n",
        "apply_framework(\"datasets/distortions/distortion_triplets/superres_triplets\",\n",
        "                \"png\",\n",
        "                model2, layer, scaler, normalize, False)\n",
        "\n",
        "print(\"\")\n",
        "print(\"# ----------------------------------------HSJ------------------------#\")\n",
        "print(\"\")\n",
        "################### HSJ Rank 0 + Dissimilar \n",
        "apply_framework(\"datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar\",\n",
        "                \"jpg\",\n",
        "                model2, layer, scaler, normalize, True)\n",
        "\n",
        "################ HSJ Rank 0 + Rank 1\n",
        "apply_framework(\"datasets/hsj/hsj_triplets/hsj_query_rank0_rank1\",\n",
        "                \"jpg\",\n",
        "                model2, layer, scaler, normalize, True)\n",
        "\n",
        "print(\"\")\n",
        "print(\"# ----------------------------------------Birds-16------------------------#\")\n",
        "print(\"\")\n",
        "################### Birds-16 Rank 0 + Dissimilar \n",
        "apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar\",\n",
        "                \"jpg\",\n",
        "                model2, layer, scaler, normalize, True)\n",
        "\n",
        "################### Birds-16 Rank 0 + Rank 1 \n",
        "apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1\",\n",
        "                \"jpg\",\n",
        "                model2, layer, scaler, normalize, True)\n",
        "\n",
        "################### Birds-16 Rank 0 + Dissimilar 2rank1 test\n",
        "apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1\",\n",
        "                \"jpg\",\n",
        "                model2, layer, scaler, normalize, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdD6QgFzi-vC",
        "outputId": "0a6b0292-1660-4871-d22d-f780fee1c0e7"
      },
      "id": "ZdD6QgFzi-vC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST RESNET-18------------------------#\n",
            "\n",
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.801\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.851\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.626\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.601\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.652\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.725\n",
            "\n",
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.691\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.574\n",
            "\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.775\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.611\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.753\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.753"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. ResNet 50\n",
        "\n",
        " ----------------------------------------BAPPS 2AFC DIST-----------------------\n",
        "\n",
        "\n",
        "datasets/distortions/distortion_triplets/traditional_triplets: 0.81\n",
        "\n",
        "datasets/distortions/distortion_triplets/cnn_triplets: 0.837\n",
        "\n",
        "datasets/distortions/distortion_triplets/color_triplets: 0.635\n",
        "\n",
        "datasets/distortions/distortion_triplets/deblur_triplets: 0.608\n",
        "\n",
        "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.653\n",
        "\n",
        "datasets/distortions/distortion_triplets/superres_triplets: 0.721\n",
        "\n",
        " ----------------------------------------HSJ------------------------\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.687\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.588\n",
        "\n",
        "\n",
        "----------------------------------------Birds-16------------------------\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.755\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.605\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.755\n"
      ],
      "metadata": {
        "id": "XtMXz0qZm6cv"
      },
      "id": "XtMXz0qZm6cv"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretrained model\n",
        "model3 = models.resnet50(pretrained=True)\n",
        "model3.cuda()\n",
        "# Use the model object to select the desired layer\n",
        "layer = model3._modules.get('avgpool')\n",
        "# Set model to evaluation mode\n",
        "model3.eval()\n",
        "scaler = transforms.Resize((224, 224))\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "print(\"\")\n",
        "print(\"# ----------------------------------------BAPPS 2AFC DIST-----------------------#\")\n",
        "print(\"\")\n",
        "################### TRADITIONAL \n",
        "apply_framework(\"datasets/distortions/distortion_triplets/traditional_triplets\",\n",
        "                \"png\",\n",
        "                model3, layer, scaler, normalize, False)\n",
        "\n",
        "################ CNN\n",
        "apply_framework(\"datasets/distortions/distortion_triplets/cnn_triplets\",\n",
        "                \"png\",\n",
        "                model3, layer, scaler, normalize, False)\n",
        "\n",
        "############### COLOR\n",
        "apply_framework(\"datasets/distortions/distortion_triplets/color_triplets\",\n",
        "                \"png\",\n",
        "                model3, layer, scaler, normalize, False)\n",
        "\n",
        "################ DEBLUR\n",
        "apply_framework(\"datasets/distortions/distortion_triplets/deblur_triplets\",\n",
        "                \"png\",\n",
        "                model3, layer, scaler, normalize, False)\n",
        "\n",
        "############### FRAME INTERP\n",
        "apply_framework(\"datasets/distortions/distortion_triplets/frameinterp_triplets\",\n",
        "                \"png\",\n",
        "                model3, layer, scaler, normalize, False)\n",
        "\n",
        "################ SUPER RES\n",
        "apply_framework(\"datasets/distortions/distortion_triplets/superres_triplets\",\n",
        "                \"png\",\n",
        "                model3, layer, scaler, normalize, False)\n",
        "\n",
        "print(\"\")\n",
        "print(\"# ----------------------------------------HSJ------------------------#\")\n",
        "print(\"\")\n",
        "################### HSJ Rank 0 + Dissimilar \n",
        "apply_framework(\"datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar\",\n",
        "                \"jpg\",\n",
        "                model3, layer, scaler, normalize, True)\n",
        "\n",
        "################ HSJ Rank 0 + Rank 1\n",
        "apply_framework(\"datasets/hsj/hsj_triplets/hsj_query_rank0_rank1\",\n",
        "                \"jpg\",\n",
        "                model3, layer, scaler, normalize, True)\n",
        "\n",
        "print(\"\")\n",
        "print(\"# ----------------------------------------Birds-16------------------------#\")\n",
        "print(\"\")\n",
        "################### Birds-16 Rank 0 + Dissimilar \n",
        "apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar\",\n",
        "                \"jpg\",\n",
        "                model3, layer, scaler, normalize, True)\n",
        "\n",
        "################### Birds-16 Rank 0 + Rank 1 \n",
        "apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1\",\n",
        "                \"jpg\",\n",
        "                model3, layer, scaler, normalize, True)\n",
        "\n",
        "################### Birds-16 Rank 0 + Dissimilar 2rank1 test\n",
        "apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1\",\n",
        "                \"jpg\",\n",
        "                model3, layer, scaler, normalize, True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clXURUNolyLI",
        "outputId": "9cad0835-a009-4ea2-9ae0-dff6d53fed9e"
      },
      "id": "clXURUNolyLI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n",
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.81\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.837\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.635\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.608\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.653\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.721\n",
            "\n",
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.687\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.588\n",
            "\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.755\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.605\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.755\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.755"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New - even less lines of code"
      ],
      "metadata": {
        "id": "4vd4hLtDpm8d"
      },
      "id": "4vd4hLtDpm8d"
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_framework_model(modelf):\n",
        "  modelf.cuda()\n",
        "  # Use the model object to select the desired layer\n",
        "  layer = modelf._modules.get('avgpool')\n",
        "  # Set model to evaluation mode\n",
        "  modelf.eval()\n",
        "  scaler = transforms.Resize((224, 224))\n",
        "  normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                  std=[0.229, 0.224, 0.225])\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"# ----------------------------------------BAPPS 2AFC DIST-----------------------#\")\n",
        "  print(\"\")\n",
        "  ################### TRADITIONAL \n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/traditional_triplets\",\n",
        "                  \"png\",\n",
        "                  modelf, layer, scaler, normalize, False)\n",
        "\n",
        "  ################ CNN\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/cnn_triplets\",\n",
        "                  \"png\",\n",
        "                  modelf, layer, scaler, normalize, False)\n",
        "\n",
        "  ############### COLOR\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/color_triplets\",\n",
        "                  \"png\",\n",
        "                  modelf, layer, scaler, normalize, False)\n",
        "\n",
        "  ################ DEBLUR\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/deblur_triplets\",\n",
        "                  \"png\",\n",
        "                  modelf, layer, scaler, normalize, False)\n",
        "\n",
        "  ############### FRAME INTERP\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/frameinterp_triplets\",\n",
        "                  \"png\",\n",
        "                  model3, layer, scaler, normalize, False)\n",
        "\n",
        "  ################ SUPER RES\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/superres_triplets\",\n",
        "                  \"png\",\n",
        "                  modelf, layer, scaler, normalize, False)\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"# ----------------------------------------HSJ------------------------#\")\n",
        "  print(\"\")\n",
        "  ################### HSJ Rank 0 + Dissimilar \n",
        "  apply_framework(\"datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar\",\n",
        "                  \"jpg\",\n",
        "                  modelf, layer, scaler, normalize, True)\n",
        "\n",
        "  ################ HSJ Rank 0 + Rank 1\n",
        "  apply_framework(\"datasets/hsj/hsj_triplets/hsj_query_rank0_rank1\",\n",
        "                  \"jpg\",\n",
        "                  modelf, layer, scaler, normalize, True)\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"# ----------------------------------------Birds-16------------------------#\")\n",
        "  print(\"\")\n",
        "  ################### Birds-16 Rank 0 + Dissimilar \n",
        "  apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar\",\n",
        "                  \"jpg\",\n",
        "                  modelf, layer, scaler, normalize, True)\n",
        "\n",
        "  ################### Birds-16 Rank 0 + Rank 1 \n",
        "  apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1\",\n",
        "                  \"jpg\",\n",
        "                  modelf, layer, scaler, normalize, True)\n",
        "\n",
        "  ################### Birds-16 Rank 0 + Dissimilar 2rank1 test\n",
        "  apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1\",\n",
        "                  \"jpg\",\n",
        "                  modelf, layer, scaler, normalize, True)"
      ],
      "metadata": {
        "id": "tWRB-LfBpmBO"
      },
      "id": "tWRB-LfBpmBO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet 101"
      ],
      "metadata": {
        "id": "45EDIZHyqGBG"
      },
      "id": "45EDIZHyqGBG"
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretrained model\n",
        "model5 = models.resnet101(pretrained=True)\n",
        "apply_framework_model(model5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468,
          "referenced_widgets": [
            "6678c3284bba4788bbe9d4e45414ffc8",
            "0bb4ca5b79eb47cba9040c4866621628",
            "0dca7d41c2c6492d94e48aa4ddac2b39",
            "cffc167a23f346938726878ea7968396",
            "ce4cd73fae2c4ca6ac365353239ad9fe",
            "ff89d302c7b447b7865767d11316ab95",
            "dec2a15e52af45b8aef578feec6d82c6",
            "0c88bfb26f94466f8ce31588b5e6faff",
            "e2e0448838f24045bb09baa6a82f7d60",
            "9c786b0d9c3a4f908b4bef29511cdf54",
            "229cdc96df7c40029253c5e17f6edf74"
          ]
        },
        "id": "8lJsSoKbpjzi",
        "outputId": "a45c142e-6da9-4885-cb36-3bcd902fe796"
      },
      "id": "8lJsSoKbpjzi",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet101-63fe2227.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-63fe2227.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/171M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6678c3284bba4788bbe9d4e45414ffc8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n",
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.808\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.839\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.647\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.594\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.464\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.736\n",
            "\n",
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.685\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.595\n",
            "\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.771\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.621\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.745\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the pretrained model\n",
        "model6 = models.resnet152(pretrained=True)\n",
        "apply_framework_model(model6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503,
          "referenced_widgets": [
            "29ec99b1c78842238a5f1e9a1f7bd471",
            "d1a3ed3a66f5412b908e14b58b920c67",
            "053f280125b1431aba72492658913b36",
            "4561cbe2c1214254a8d670b9f31caed1",
            "1dac5859a10945a1adadb28dfc93ea0e",
            "18f2ceb4c94c4ea091afc17ab882936f",
            "48d0319c81204308a655424e9d974f41",
            "917e6cbf826c4da399841399330f9dd9",
            "92a20835c1ab41af8eee379d345dc6e0",
            "d97d9fc3cfe04e60aebd1723a4cdf263",
            "516db9148baa45f485cbcca81248a1f1"
          ]
        },
        "id": "ipWjsF1EuDrT",
        "outputId": "9066d80c-db16-4500-d52a-8eba83bfd441"
      },
      "id": "ipWjsF1EuDrT",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet152_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet152_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet152-394f9c45.pth\" to /root/.cache/torch/hub/checkpoints/resnet152-394f9c45.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/230M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "29ec99b1c78842238a5f1e9a1f7bd471"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n",
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.815\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.845\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.637\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.624\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.464\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.713\n",
            "\n",
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.68\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.588\n",
            "\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.779\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.605\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.786\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Sampling different layers of ResNet - Editting Framework"
      ],
      "metadata": {
        "id": "nqOi5dAb0tiw"
      },
      "id": "nqOi5dAb0tiw"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "############################ REQUIRES MODIFICATION FOR EACH MODEL \n",
        "\n",
        "# scaler = transforms.Resize((224, 224))\n",
        "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "#                                  std=[0.229, 0.224, 0.225])\n",
        "to_tensor = transforms.ToTensor()   # used to convert the PIL image to a PyTorch tensor (multidimensional array)\n",
        "############################\n",
        "\n",
        "\n",
        "############################## HOW TO GET MODEL:\n",
        "# # Load the pretrained model\n",
        "# model = models.resnet18(pretrained=True)\n",
        "# model.cuda()\n",
        "# # Use the model object to select the desired layer\n",
        "# layer = model._modules.get('avgpool')\n",
        "# # Set model to evaluation mode\n",
        "# model.eval()\n",
        "\n",
        "##################################\n",
        "\n",
        "def get_vector(image_name, model, layer, scaler, normalize, feature_tensor_size):\n",
        "    \n",
        "#     # Load the pretrained model\n",
        "#     model = models.resnet18(pretrained=True)\n",
        "#     # Use the model object to select the desired layer\n",
        "#     layer = model._modules.get('avgpool')\n",
        "    \n",
        "    # 1. Load the image with Pillow library\n",
        "    img = Image.open(image_name).convert('RGB')\n",
        "    # 2. Create a PyTorch Variable with the transformed image\n",
        "    t_img = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0)).cuda()\n",
        "    # 3. Create a vector of zeros that will hold our feature vector\n",
        "    #    The 'avgpool' layer has an output size of 512\n",
        "    \n",
        "    # M1: my_embedding = torch.zeros(1, 512, 1, 1) and later my_embedding.copy_(o.data)\n",
        "    # M2: my_embedding = torch.zeros(512) and later my_embedding.copy_(o.data.reshape(o.data.size(1)))\n",
        "    my_embedding = torch.zeros(feature_tensor_size).cuda()\n",
        "    \n",
        "    # 4. Define a function that will copy the output of a layer\n",
        "    def copy_data(m, i, o):\n",
        "        my_embedding.copy_(o.data)\n",
        "    # 5. Attach that function to our selected layer\n",
        "    h = layer.register_forward_hook(copy_data)\n",
        "    # 6. Run the model on our transformed image\n",
        "    model(t_img)\n",
        "    # 7. Detach our copy function from the layer\n",
        "    h.remove()\n",
        "    # 8. Return the feature vector\n",
        "    return torch.flatten(my_embedding)\n",
        "\n",
        "############################ COSINE SIMILARITY\n",
        "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "\n",
        "\n",
        "########################### GET FEATURE VECTORS\n",
        "def get_image_embeddings(path, image_type, model, layer, scaler, normalize, isHSJOrBirds, feature_tensor_size):  # returns a list of tensors\n",
        "    # path of form: traditional/ref/\n",
        "    feature_tensor_dict = dict()\n",
        "    feature_tensor_dict[\"ref\"] = []\n",
        "    feature_tensor_dict[\"p0\"] = []\n",
        "    feature_tensor_dict[\"p1\"] = []\n",
        "    feature_tensor_dict[\"decision\"] = []\n",
        "    \n",
        "    for image_no in range(1000):\n",
        "        im_no_name =  (6-len(str(image_no)))*\"0\" + str(image_no) + \".\" + image_type\n",
        "        \n",
        "        feature_tensor_dict[\"ref\"].append(get_vector(path+\"/ref/\" + im_no_name, model, layer, scaler, normalize, feature_tensor_size))\n",
        "        feature_tensor_dict[\"p0\"].append(get_vector(path+\"/p0/\" + im_no_name, model, layer, scaler, normalize, feature_tensor_size))\n",
        "        feature_tensor_dict[\"p1\"].append(get_vector(path+\"/p1/\" + im_no_name, model, layer, scaler, normalize, feature_tensor_size))\n",
        "\n",
        "        # now load decision\n",
        "        if isHSJOrBirds:\n",
        "          feature_tensor_dict[\"decision\"].append(0)\n",
        "        else: \n",
        "          decision_no_name =  (6-len(str(image_no)))*\"0\" + str(image_no) + \".npy\"\n",
        "          decision = np.load(path+\"/judge/\"+decision_no_name)\n",
        "          if decision[0] <= 0.5: \n",
        "                feature_tensor_dict[\"decision\"].append(0)\n",
        "          else: \n",
        "                feature_tensor_dict[\"decision\"].append(1)\n",
        "        \n",
        "    return feature_tensor_dict\n",
        "\n",
        "\n",
        "########################## GET MODEL PREDICTIONS\n",
        "def get_predictions(embeddings):\n",
        "  cosine_similarity_dict = dict()\n",
        "  cosine_similarity_dict[\"ref_and_p0\"] = []\n",
        "  cosine_similarity_dict[\"ref_and_p1\"] = []\n",
        "  cosine_similarity_predictions = []\n",
        "\n",
        "  cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "  # cos_sim = cos(query_vector.unsqueeze(0), ref2_vector.unsqueeze(0))\n",
        "\n",
        "  for image_no in range(1000):\n",
        "      cosine_similarity_dict[\"ref_and_p0\"].append(cos(embeddings[\"ref\"][image_no].unsqueeze(0), embeddings[\"p0\"][image_no].unsqueeze(0)))\n",
        "      cosine_similarity_dict[\"ref_and_p1\"].append(cos(embeddings[\"ref\"][image_no].unsqueeze(0), embeddings[\"p1\"][image_no].unsqueeze(0)))\n",
        "      \n",
        "      if cosine_similarity_dict[\"ref_and_p0\"][image_no] >= cosine_similarity_dict[\"ref_and_p1\"][image_no]:\n",
        "          cosine_similarity_predictions.append(0)\n",
        "      else:\n",
        "          cosine_similarity_predictions.append(1)   \n",
        "  return cosine_similarity_predictions\n",
        "\n",
        "########################## GET MODEL ACCURACY\n",
        "def get_accuracy(predictions,embeddings):\n",
        "  decisions = embeddings[\"decision\"]\n",
        "\n",
        "  number_wrong_predictions = 0\n",
        "\n",
        "  for image_no in range(1000):\n",
        "      if predictions[image_no] != decisions[image_no]:\n",
        "          number_wrong_predictions += 1\n",
        "      \n",
        "  accuracy = (1000 - number_wrong_predictions)/(1000)\n",
        "  return accuracy\n",
        "\n",
        "\n",
        "def apply_framework(path, image_type, model, layer, scaler, normalize, isHSJOrBirds, feature_tensor_size):\n",
        "  embeddings = get_image_embeddings(path, \n",
        "                                    image_type,\n",
        "                                    model, layer, scaler, normalize, isHSJOrBirds, feature_tensor_size)\n",
        "  predictions= get_predictions(embeddings)\n",
        "  accuracy = get_accuracy(predictions, embeddings)\n",
        "  print(path + \": \" + str(accuracy))\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "1uJdDnzS0s7O"
      },
      "id": "1uJdDnzS0s7O",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_framework_model(modelf, layer, feature_tensor_size):\n",
        "  scaler = transforms.Resize((224, 224))\n",
        "  normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                  std=[0.229, 0.224, 0.225])\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"# ----------------------------------------BAPPS 2AFC DIST-----------------------#\")\n",
        "  print(\"\")\n",
        "  ################### TRADITIONAL \n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/traditional_triplets\",\n",
        "                  \"png\",\n",
        "                  modelf, layer, scaler, normalize, False, feature_tensor_size)\n",
        "\n",
        "  ################ CNN\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/cnn_triplets\",\n",
        "                  \"png\",\n",
        "                  modelf, layer, scaler, normalize, False, feature_tensor_size)\n",
        "\n",
        "  ############### COLOR\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/color_triplets\",\n",
        "                  \"png\",\n",
        "                  modelf, layer, scaler, normalize, False, feature_tensor_size)\n",
        "\n",
        "  ################ DEBLUR\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/deblur_triplets\",\n",
        "                  \"png\",\n",
        "                  modelf, layer, scaler, normalize, False, feature_tensor_size)\n",
        "\n",
        "  ############### FRAME INTERP\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/frameinterp_triplets\",\n",
        "                  \"png\",\n",
        "                  modelf, layer, scaler, normalize, False, feature_tensor_size)\n",
        "\n",
        "  ################ SUPER RES\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/superres_triplets\",\n",
        "                  \"png\",\n",
        "                  modelf, layer, scaler, normalize, False, feature_tensor_size)\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"# ----------------------------------------HSJ------------------------#\")\n",
        "  print(\"\")\n",
        "  ################### HSJ Rank 0 + Dissimilar \n",
        "  apply_framework(\"datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar\",\n",
        "                  \"jpg\",\n",
        "                  modelf, layer, scaler, normalize, True, feature_tensor_size)\n",
        "\n",
        "  ################ HSJ Rank 0 + Rank 1\n",
        "  apply_framework(\"datasets/hsj/hsj_triplets/hsj_query_rank0_rank1\",\n",
        "                  \"jpg\",\n",
        "                  modelf, layer, scaler, normalize, True, feature_tensor_size)\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"# ----------------------------------------Birds-16------------------------#\")\n",
        "  print(\"\")\n",
        "  ################### Birds-16 Rank 0 + Dissimilar \n",
        "  apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar\",\n",
        "                  \"jpg\",\n",
        "                  modelf, layer, scaler, normalize, True, feature_tensor_size)\n",
        "\n",
        "  ################### Birds-16 Rank 0 + Rank 1 \n",
        "  apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1\",\n",
        "                  \"jpg\",\n",
        "                  modelf, layer, scaler, normalize, True, feature_tensor_size)\n",
        "\n",
        "  ################### Birds-16 Rank 0 + Dissimilar 2rank1 test\n",
        "  apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1\",\n",
        "                  \"jpg\",\n",
        "                  modelf, layer, scaler, normalize, True, feature_tensor_size)"
      ],
      "metadata": {
        "id": "j3Bbhfqy1gJP"
      },
      "id": "j3Bbhfqy1gJP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#-------------------------------Resnet-18-------------------------------------#\n",
        "#-------------------------------Layer 2 - conv_3x#\n",
        "\n",
        "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
        "\n",
        "datasets/distortions/distortion_triplets/traditional_triplets: 0.629\n",
        "datasets/distortions/distortion_triplets/cnn_triplets: 0.828\n",
        "datasets/distortions/distortion_triplets/color_triplets: 0.525\n",
        "datasets/distortions/distortion_triplets/deblur_triplets: 0.608\n",
        "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.464\n",
        "datasets/distortions/distortion_triplets/superres_triplets: 0.682\n",
        "\n",
        "# ----------------------------------------HSJ------------------------#\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.634\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.567\n",
        "\n",
        "# ----------------------------------------Birds-16------------------------#\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.604\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.541\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.607\n",
        "#-------------------------------Layer 3 - conv_4x#\n",
        "\n",
        "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
        "\n",
        "datasets/distortions/distortion_triplets/traditional_triplets: 0.725\n",
        "datasets/distortions/distortion_triplets/cnn_triplets: 0.84\n",
        "datasets/distortions/distortion_triplets/color_triplets: 0.554\n",
        "datasets/distortions/distortion_triplets/deblur_triplets: 0.617\n",
        "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.464\n",
        "datasets/distortions/distortion_triplets/superres_triplets: 0.731\n",
        "\n",
        "# ----------------------------------------HSJ------------------------#\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.648\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.603\n",
        "\n",
        "# ----------------------------------------Birds-16------------------------#\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.592\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.56\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.643\n",
        "#-------------------------------Layer 4 - conv_5x#\n",
        "\n",
        "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
        "\n",
        "datasets/distortions/distortion_triplets/traditional_triplets: 0.803\n",
        "datasets/distortions/distortion_triplets/cnn_triplets: 0.854\n",
        "datasets/distortions/distortion_triplets/color_triplets: 0.607\n",
        "datasets/distortions/distortion_triplets/deblur_triplets: 0.613\n",
        "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.464\n",
        "datasets/distortions/distortion_triplets/superres_triplets: 0.727\n",
        "\n",
        "# ----------------------------------------HSJ------------------------#\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.664\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.593\n",
        "\n",
        "# ----------------------------------------Birds-16------------------------#\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.772\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.605\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.753\n",
        "\n",
        "#-------------------------------Resnet-34-------------------------------------#\n",
        "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
        "  warnings.warn(msg)\n",
        "#-------------------------------Layer 2 - conv_3x#\n",
        "\n",
        "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
        "\n",
        "datasets/distortions/distortion_triplets/traditional_triplets: 0.636\n",
        "datasets/distortions/distortion_triplets/cnn_triplets: 0.824\n",
        "datasets/distortions/distortion_triplets/color_triplets: 0.524\n",
        "datasets/distortions/distortion_triplets/deblur_triplets: 0.605\n",
        "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.464\n",
        "datasets/distortions/distortion_triplets/superres_triplets: 0.651\n",
        "\n",
        "# ----------------------------------------HSJ------------------------#\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.601\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.57\n",
        "\n",
        "# ----------------------------------------Birds-16------------------------#\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.59\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.552\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.583\n",
        "#-------------------------------Layer 3 - conv_4x#\n",
        "\n",
        "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
        "\n",
        "datasets/distortions/distortion_triplets/traditional_triplets: 0.712\n",
        "datasets/distortions/distortion_triplets/cnn_triplets: 0.841\n",
        "datasets/distortions/distortion_triplets/color_triplets: 0.552\n",
        "datasets/distortions/distortion_triplets/deblur_triplets: 0.629\n",
        "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.464\n",
        "datasets/distortions/distortion_triplets/superres_triplets: 0.74\n",
        "\n",
        "# ----------------------------------------HSJ------------------------#\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.626\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.589\n",
        "\n",
        "# ----------------------------------------Birds-16------------------------#\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.583\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.553\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.639\n",
        "#-------------------------------Layer 4 - conv_5x#\n",
        "\n",
        "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
        "\n",
        "datasets/distortions/distortion_triplets/traditional_triplets: 0.803\n",
        "datasets/distortions/distortion_triplets/cnn_triplets: 0.841\n",
        "datasets/distortions/distortion_triplets/color_triplets: 0.624\n",
        "datasets/distortions/distortion_triplets/deblur_triplets: 0.626\n",
        "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.464\n",
        "datasets/distortions/distortion_triplets/superres_triplets: 0.724\n",
        "\n",
        "# ----------------------------------------HSJ------------------------#\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.691\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.591\n",
        "\n",
        "# ----------------------------------------Birds-16------------------------#\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.764\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.607\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.748\n"
      ],
      "metadata": {
        "id": "a06RF_CqO8Qf"
      },
      "id": "a06RF_CqO8Qf"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"#-------------------------------Resnet-18-------------------------------------#\")\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "print(\"#-------------------------------Layer 2 - conv_3x#\")\n",
        "layer = model._modules.get(\"layer2\")\n",
        "apply_framework_model(model,layer,[1, 128, 28, 28])\n",
        "\n",
        "print(\"#-------------------------------Layer 3 - conv_4x#\")\n",
        "layer = model._modules.get(\"layer3\")\n",
        "apply_framework_model(model,layer,[1, 256, 14, 14])\n",
        "\n",
        "print(\"#-------------------------------Layer 4 - conv_5x#\")\n",
        "layer = model._modules.get(\"layer4\")\n",
        "apply_framework_model(model,layer,[1, 512, 7, 7])\n",
        "\n",
        "print(\"\")\n",
        "print(\"#-------------------------------Resnet-34-------------------------------------#\")\n",
        "model = models.resnet34(pretrained=True)\n",
        "print(\"#-------------------------------Layer 2 - conv_3x#\")\n",
        "layer = model._modules.get(\"layer2\")\n",
        "apply_framework_model(model,layer,[1, 128, 28, 28])\n",
        "\n",
        "print(\"#-------------------------------Layer 3 - conv_4x#\")\n",
        "layer = model._modules.get(\"layer3\")\n",
        "apply_framework_model(model,layer,[1, 256, 14, 14])\n",
        "\n",
        "print(\"#-------------------------------Layer 4 - conv_5x#\")\n",
        "layer = model._modules.get(\"layer4\")\n",
        "apply_framework_model(model,layer,[1, 512, 7, 7])\n",
        "\n",
        "print(\"\")\n",
        "print(\"#-------------------------------Resnet-50-------------------------------------#\")\n",
        "model = models.resnet50(pretrained=True)\n",
        "print(\"#-------------------------------Layer 2 - conv_3x#\")\n",
        "layer = model._modules.get(\"layer2\")\n",
        "apply_framework_model(model,layer,[1, 512, 28, 28])\n",
        "\n",
        "print(\"#-------------------------------Layer 3 - conv_4x#\")\n",
        "layer = model._modules.get(\"layer3\")\n",
        "apply_framework_model(model,layer,[1, 1024, 14, 14])\n",
        "\n",
        "print(\"#-------------------------------Layer 4 - conv_5x#\")\n",
        "layer = model._modules.get(\"layer4\")\n",
        "apply_framework_model(model,layer,[1, 2048, 7, 7])"
      ],
      "metadata": {
        "id": "WLFyG2D51kUr"
      },
      "id": "WLFyG2D51kUr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# alexnet\n",
        "print(\"alexnet\")\n",
        "model = models.alexnet(pretrained=True)\n",
        "model.cuda()\n",
        "layer = model._modules.get(\"avgpool\")\n",
        "model.eval()\n",
        "apply_framework_model(model,layer,[1, 256, 6, 6])\n",
        "\n",
        "\n",
        "# mobilenet\n",
        "print(\"mobilenet v 2\")\n",
        "model = models.mobilenet_v2(pretrained=True)\n",
        "model.cuda()\n",
        "layer = model._modules.get(\"features\")\n",
        "model.eval()\n",
        "apply_framework_model(model,layer,[1, 1280, 7, 7])\n",
        "\n",
        "print(\"mobilenet v 3\")\n",
        "\n",
        "model = models.mobilenet_v3_large(pretrained=True)\n",
        "model.cuda()\n",
        "layer = model._modules.get(\"features\")\n",
        "model.eval()\n",
        "apply_framework_model(model,layer,[1, 960, 7, 7])\n",
        "\n",
        "# # vgg\n",
        "\n",
        "# model = models.mobilenet_v2(pretrained=True)\n",
        "# model.cuda()\n",
        "# layer = model._modules.get(\"features\")\n",
        "# model.eval()\n",
        "# apply_framework_model(model,layer,[1, 1280, 7, 7])\n",
        "\n",
        "\n",
        "# ConvNext --> MOST RECENTLY INTRODUCED\n",
        "print(\"convnext\")\n",
        "model = models.convnext_base(pretrained=True)\n",
        "model.cuda()\n",
        "layer = model._modules.get(\"avgpool\")\n",
        "model.eval()\n",
        "apply_framework_model(model,layer,[1, 1024, 1, 1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJcgVogGLcue",
        "outputId": "5f0518cc-76d8-43b2-cb61-d214c9a4589c"
      },
      "id": "vJcgVogGLcue",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alexnet\n",
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n",
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.813\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.877\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.637\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.651\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.678\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.764\n",
            "\n",
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.728\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.603\n",
            "\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.72\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.606\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.704\n",
            "mobilenet v 2\n",
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.795\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.861\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.607\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.626\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.65\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.751\n",
            "\n",
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.661\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.581\n",
            "\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.745\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.58\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.743\n",
            "mobilenet v 3\n",
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V3_Large_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V3_Large_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.775\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.85\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.588\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.62\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.641\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.72\n",
            "\n",
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.621\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.561\n",
            "\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.704\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.602\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.707\n",
            "convnext\n",
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n",
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.782\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.851\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.625\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.612\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.649\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.695\n",
            "\n",
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.601\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.569\n",
            "\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.727\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.59\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.753\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ResNet 18-34:\n",
        "\n",
        "Layer2: ([1, 128, 28, 28])\n",
        "\n",
        "Layer3: ([1, 256, 14, 14])\n",
        "\n",
        "Layer4: ([1, 512, 7, 7])\n",
        "\n",
        "ResNet 50: \n",
        "\n",
        "Layer2: ([1, 512, 28, 28])\n",
        "\n",
        "Layer3: ([1, 1024, 14, 14])\n",
        "\n",
        "Layer4: ([1, 2048, 7, 7])"
      ],
      "metadata": {
        "id": "GF4H6PjZB9Kh"
      },
      "id": "GF4H6PjZB9Kh"
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Different Architectures </h1>"
      ],
      "metadata": {
        "id": "sy2BI9hPQbY6"
      },
      "id": "sy2BI9hPQbY6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. EfficientNet B0 [1, 1280, 1, 1]\n",
        "2. EfficientNet B1 [1, 1280, 1, 1]\n",
        "3. EfficientNet B2 [1, 1408, 1, 1]\n",
        "4. EfficientNet B3 [1, 1536, 1, 1]\n",
        "5. EfficientNet B4 [1, 1792, 1, 1]\n",
        "6. EfficientNet B5 [1, 2048, 1, 1]\n",
        "7. EfficientNet B6 [1, 2304, 1, 1]\n",
        "7. EfficientNet B7 [1, 2560, 1, 1]\n",
        "\n",
        "\n",
        "#-----------EfficientNet B0------------------------#\n",
        "\n",
        "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
        "\n",
        "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
        "  warnings.warn(\n",
        "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
        "  warnings.warn(msg)\n",
        "datasets/distortions/distortion_triplets/traditional_triplets: 0.785\n",
        "datasets/distortions/distortion_triplets/cnn_triplets: 0.83\n",
        "datasets/distortions/distortion_triplets/color_triplets: 0.624\n",
        "datasets/distortions/distortion_triplets/deblur_triplets: 0.622\n",
        "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.664\n",
        "datasets/distortions/distortion_triplets/superres_triplets: 0.704\n",
        "\n",
        "# ----------------------------------------HSJ------------------------#\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.583\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.542\n",
        "\n",
        "# ----------------------------------------Birds-16------------------------#\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.813\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.641\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.813\n",
        "#-----------EfficientNet B1------------------------#\n",
        "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B1_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B1_Weights.DEFAULT` to get the most up-to-date weights.\n",
        "  warnings.warn(msg)\n",
        "\n",
        "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
        "\n",
        "datasets/distortions/distortion_triplets/traditional_triplets: 0.801\n",
        "datasets/distortions/distortion_triplets/cnn_triplets: 0.849\n",
        "datasets/distortions/distortion_triplets/color_triplets: 0.622\n",
        "datasets/distortions/distortion_triplets/deblur_triplets: 0.631\n",
        "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.651\n",
        "datasets/distortions/distortion_triplets/superres_triplets: 0.713\n",
        "\n",
        "# ----------------------------------------HSJ------------------------#\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.577\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.541\n",
        "\n",
        "# ----------------------------------------Birds-16------------------------#\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.806\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.626\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.815\n",
        "#-----------EfficientNet B2------------------------#\n",
        "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B2_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B2_Weights.DEFAULT` to get the most up-to-date weights.\n",
        "  warnings.warn(msg)\n",
        "\n",
        "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
        "\n",
        "datasets/distortions/distortion_triplets/traditional_triplets: 0.787\n",
        "datasets/distortions/distortion_triplets/cnn_triplets: 0.836\n",
        "datasets/distortions/distortion_triplets/color_triplets: 0.615\n",
        "datasets/distortions/distortion_triplets/deblur_triplets: 0.601\n",
        "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.667\n",
        "datasets/distortions/distortion_triplets/superres_triplets: 0.701\n",
        "\n",
        "# ----------------------------------------HSJ------------------------#\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.568\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.574\n",
        "\n",
        "# ----------------------------------------Birds-16------------------------#\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.799\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.619\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.805\n",
        "#-----------EfficientNet B3------------------------#\n"
      ],
      "metadata": {
        "id": "sBvIEMcrQgM1"
      },
      "id": "sBvIEMcrQgM1"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"#-----------EfficientNet B0------------------------#\")\n",
        "model = models.efficientnet_b0(pretrained=True)\n",
        "layer = model._modules.get(\"avgpool\")\n",
        "apply_framework_model(model,layer,[1, 1280, 1, 1])\n",
        "\n",
        "print(\"#-----------EfficientNet B1------------------------#\")\n",
        "model = models.efficientnet_b1(pretrained=True)\n",
        "layer = model._modules.get(\"avgpool\")\n",
        "apply_framework_model(model,layer,[1, 1280, 1, 1])\n",
        "\n",
        "print(\"#-----------EfficientNet B2------------------------#\")\n",
        "model = models.efficientnet_b2(pretrained=True)\n",
        "layer = model._modules.get(\"avgpool\")\n",
        "apply_framework_model(model,layer,[1, 1408, 1, 1])"
      ],
      "metadata": {
        "id": "StWBa1TaQaM7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c3d84fa3-2cfd-4b69-b14f-ac33c89964d8"
      },
      "id": "StWBa1TaQaM7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#-----------EfficientNet B0------------------------#\n",
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.785\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.83\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.624\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.622\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.664\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.704\n",
            "\n",
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.583\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.542\n",
            "\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.813\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.641\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.813\n",
            "#-----------EfficientNet B1------------------------#\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B1_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B1_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n",
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.801\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.849\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.622\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.631\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.651\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.713\n",
            "\n",
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.577\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.541\n",
            "\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.806\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.626\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.815\n",
            "#-----------EfficientNet B2------------------------#\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B2_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B2_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n",
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.787\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.836\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.615\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.601\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.667\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.701\n",
            "\n",
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.568\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.574\n",
            "\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.799\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.619\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.805\n",
            "#-----------EfficientNet B3------------------------#\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n",
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.77\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-c0a9cdba86fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mefficientnet_b3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"avgpool\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mapply_framework_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1536\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#-----------EfficientNet B4------------------------#\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-a7d1a163575f>\u001b[0m in \u001b[0;36mapply_framework_model\u001b[0;34m(modelf, layer, feature_tensor_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m   \u001b[0;31m################ CNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m   apply_framework(\"datasets/distortions/distortion_triplets/cnn_triplets\",\n\u001b[0m\u001b[1;32m     20\u001b[0m                   \u001b[0;34m\"png\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                   modelf, layer, scaler, normalize, False, feature_tensor_size)\n",
            "\u001b[0;32m<ipython-input-19-d6c36dd30e7d>\u001b[0m in \u001b[0;36mapply_framework\u001b[0;34m(path, image_type, model, layer, scaler, normalize, isHSJOrBirds, feature_tensor_size)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply_framework\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misHSJOrBirds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_tensor_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m   embeddings = get_image_embeddings(path, \n\u001b[0m\u001b[1;32m    130\u001b[0m                                     \u001b[0mimage_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                                     model, layer, scaler, normalize, isHSJOrBirds, feature_tensor_size)\n",
            "\u001b[0;32m<ipython-input-19-d6c36dd30e7d>\u001b[0m in \u001b[0;36mget_image_embeddings\u001b[0;34m(path, image_type, model, layer, scaler, normalize, isHSJOrBirds, feature_tensor_size)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0mim_no_name\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m\"0\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_no\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m         \u001b[0mfeature_tensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ref\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/ref/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim_no_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_tensor_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0mfeature_tensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"p0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/p0/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim_no_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_tensor_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0mfeature_tensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"p1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/p1/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim_no_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_tensor_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-d6c36dd30e7d>\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(image_name, model, layer, scaler, normalize, feature_tensor_size)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# 6. Run the model on our transformed image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;31m# 7. Detach our copy function from the layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_res_connect\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic_depth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mbn_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m             \u001b[0mbn_training\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         r\"\"\"\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'_parameters'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1258\u001b[0;31m             \u001b[0m_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_parameters'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1259\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_parameters\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_parameters\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#-----------EfficientNet B3------------------------#\n",
        "\n",
        "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
        "\n",
        "datasets/distortions/distortion_triplets/traditional_triplets: 0.77\n",
        "datasets/distortions/distortion_triplets/cnn_triplets: 0.83\n",
        "datasets/distortions/distortion_triplets/color_triplets: 0.569\n",
        "datasets/distortions/distortion_triplets/deblur_triplets: 0.595\n",
        "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.659\n",
        "datasets/distortions/distortion_triplets/superres_triplets: 0.665\n",
        "\n",
        "# ----------------------------------------HSJ------------------------#\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.635\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.569\n",
        "\n",
        "# ----------------------------------------Birds-16------------------------#\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.796\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.635\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.816\n",
        "#-----------EfficientNet B4------------------------#\n",
        "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B4_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B4_Weights.DEFAULT` to get the most up-to-date weights.\n",
        "  warnings.warn(msg)\n",
        "\n",
        "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
        "\n",
        "datasets/distortions/distortion_triplets/traditional_triplets: 0.737\n",
        "datasets/distortions/distortion_triplets/cnn_triplets: 0.812\n",
        "datasets/distortions/distortion_triplets/color_triplets: 0.605\n",
        "datasets/distortions/distortion_triplets/deblur_triplets: 0.601\n",
        "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.632\n",
        "datasets/distortions/distortion_triplets/superres_triplets: 0.657\n",
        "\n",
        "# ----------------------------------------HSJ------------------------#\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.628\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.58\n",
        "\n",
        "# ----------------------------------------Birds-16------------------------#\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.77\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.61\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.779\n",
        "#-----------EfficientNet B5------------------------#\n",
        "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B5_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B5_Weights.DEFAULT` to get the most up-to-date weights.\n",
        "  warnings.warn(msg)\n",
        "\n",
        "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
        "\n",
        "datasets/distortions/distortion_triplets/traditional_triplets: 0.763\n",
        "datasets/distortions/distortion_triplets/cnn_triplets: 0.812\n",
        "datasets/distortions/distortion_triplets/color_triplets: 0.571\n",
        "datasets/distortions/distortion_triplets/deblur_triplets: 0.6\n",
        "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.624\n",
        "datasets/distortions/distortion_triplets/superres_triplets: 0.645\n",
        "\n",
        "# ----------------------------------------HSJ------------------------#\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.57\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.558\n",
        "\n",
        "# ----------------------------------------Birds-16------------------------#\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.786\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.608\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.797\n",
        "#-----------EfficientNet B6------------------------#\n",
        "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B6_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B6_Weights.DEFAULT` to get the most up-to-date weights.\n",
        "  warnings.warn(msg)\n",
        "\n",
        "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
        "\n",
        "datasets/distortions/distortion_triplets/traditional_triplets: 0.767\n",
        "datasets/distortions/distortion_triplets/cnn_triplets: 0.818\n",
        "datasets/distortions/distortion_triplets/color_triplets: 0.569\n",
        "datasets/distortions/distortion_triplets/deblur_triplets: 0.593\n",
        "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.637\n",
        "datasets/distortions/distortion_triplets/superres_triplets: 0.582\n",
        "\n",
        "# ----------------------------------------HSJ------------------------#\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.576\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.553\n",
        "\n",
        "# ----------------------------------------Birds-16------------------------#\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.772\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.615\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.798"
      ],
      "metadata": {
        "id": "POOzpdTpQeTj"
      },
      "id": "POOzpdTpQeTj"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"#-----------EfficientNet B3------------------------#\")\n",
        "model = models.efficientnet_b3(pretrained=True)\n",
        "model.cuda()\n",
        "layer = model._modules.get(\"avgpool\")\n",
        "  # Use the model object to select the desired layer\n",
        "  # Set model to evaluation mode\n",
        "model.eval()\n",
        "apply_framework_model(model,layer,[1, 1536, 1, 1])\n",
        "\n",
        "print(\"#-----------EfficientNet B4------------------------#\")\n",
        "model = models.efficientnet_b4(pretrained=True)\n",
        "model.cuda()\n",
        "layer = model._modules.get(\"avgpool\")\n",
        "  # Use the model object to select the desired layer\n",
        "  # Set model to evaluation mode\n",
        "model.eval()\n",
        "apply_framework_model(model,layer,[1, 1792, 1, 1])\n",
        "\n",
        "print(\"#-----------EfficientNet B5------------------------#\")\n",
        "model = models.efficientnet_b5(pretrained=True)\n",
        "model.cuda()\n",
        "layer = model._modules.get(\"avgpool\")\n",
        "  # Use the model object to select the desired layer\n",
        "  # Set model to evaluation mode\n",
        "model.eval()\n",
        "apply_framework_model(model,layer,[1, 2048, 1, 1])\n",
        "\n",
        "print(\"#-----------EfficientNet B6------------------------#\")\n",
        "model = models.efficientnet_b6(pretrained=True)\n",
        "model.cuda()\n",
        "layer = model._modules.get(\"avgpool\")\n",
        "  # Use the model object to select the desired layer\n",
        "  # Set model to evaluation mode\n",
        "model.eval()\n",
        "apply_framework_model(model,layer,[1, 2304, 1, 1])\n",
        "\n",
        "print(\"#-----------EfficientNet B7------------------------#\")\n",
        "model = models.efficientnet_b7(pretrained=True)\n",
        "model.cuda()\n",
        "layer = model._modules.get(\"avgpool\")\n",
        "  # Use the model object to select the desired layer\n",
        "  # Set model to evaluation mode\n",
        "model.eval()\n",
        "apply_framework_model(model,layer,[1, 2560, 1, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "6TbzvYUs6yVM",
        "outputId": "44674cd5-ffd8-4f35-f815-580e896e2ed1"
      },
      "id": "6TbzvYUs6yVM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#-----------EfficientNet B3------------------------#\n",
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n",
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.77\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.83\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.569\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.595\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.659\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.665\n",
            "\n",
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.635\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.569\n",
            "\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.796\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.635\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.816\n",
            "#-----------EfficientNet B4------------------------#\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B4_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B4_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n",
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.737\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.812\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.605\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.601\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.632\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.657\n",
            "\n",
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.628\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.58\n",
            "\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.77\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.61\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.779\n",
            "#-----------EfficientNet B5------------------------#\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B5_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B5_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n",
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.763\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.812\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.571\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.6\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.624\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.645\n",
            "\n",
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.57\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.558\n",
            "\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.786\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.608\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.797\n",
            "#-----------EfficientNet B6------------------------#\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B6_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B6_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n",
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.767\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.818\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.569\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.593\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.637\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.582\n",
            "\n",
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.576\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.553\n",
            "\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.772\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.615\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.798\n",
            "#-----------EfficientNet B7------------------------#\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B7_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B7_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-c830127eef6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m   \u001b[0;31m# Set model to evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mapply_framework_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2560\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-ef3ced21dcc3>\u001b[0m in \u001b[0;36mapply_framework_model\u001b[0;34m(modelf, layer, feature_tensor_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m################### TRADITIONAL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   apply_framework(\"datasets/distortions/distortion_triplets/traditional_triplets\",\n\u001b[0m\u001b[1;32m     11\u001b[0m                   \u001b[0;34m\"png\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                   modelf, layer, scaler, normalize, False, feature_tensor_size)\n",
            "\u001b[0;32m<ipython-input-19-d6c36dd30e7d>\u001b[0m in \u001b[0;36mapply_framework\u001b[0;34m(path, image_type, model, layer, scaler, normalize, isHSJOrBirds, feature_tensor_size)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply_framework\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misHSJOrBirds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_tensor_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m   embeddings = get_image_embeddings(path, \n\u001b[0m\u001b[1;32m    130\u001b[0m                                     \u001b[0mimage_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                                     model, layer, scaler, normalize, isHSJOrBirds, feature_tensor_size)\n",
            "\u001b[0;32m<ipython-input-19-d6c36dd30e7d>\u001b[0m in \u001b[0;36mget_image_embeddings\u001b[0;34m(path, image_type, model, layer, scaler, normalize, isHSJOrBirds, feature_tensor_size)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mfeature_tensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ref\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/ref/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim_no_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_tensor_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mfeature_tensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"p0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/p0/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim_no_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_tensor_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mfeature_tensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"p1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/p1/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim_no_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_tensor_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-d6c36dd30e7d>\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(image_name, model, layer, scaler, normalize, feature_tensor_size)\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# 6. Run the model on our transformed image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m     \u001b[0;31m# 7. Detach our copy function from the layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/efficientnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_res_connect\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstochastic_depth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/ops/misc.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscale\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/ops/misc.py\u001b[0m in \u001b[0;36m_scale\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_scale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mavgpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mscale\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    457\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 459\u001b[0;31m         return F.conv2d(input, weight, bias, self.stride,\n\u001b[0m\u001b[1;32m    460\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = models.vit_b_16(pretrained=True)\n",
        "model.cuda()\n",
        "model.eval()\n",
        "layer = model._modules.get(\"encoder_layer_11\")\n",
        "  # Use the model object to select the desired layer\n",
        "  # Set model to evaluation mode\n",
        "model.eval()\n",
        "apply_framework_model(model,layer,[1, 1536, 1, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "7zcCky3LOxHf",
        "outputId": "163dc86c-acf5-4211-e877-632bd5708fd9"
      },
      "id": "7zcCky3LOxHf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-36-506d0d8870d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0;31m# Set model to evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mapply_framework_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1536\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-ef3ced21dcc3>\u001b[0m in \u001b[0;36mapply_framework_model\u001b[0;34m(modelf, layer, feature_tensor_size)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m################### TRADITIONAL\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   apply_framework(\"datasets/distortions/distortion_triplets/traditional_triplets\",\n\u001b[0m\u001b[1;32m     11\u001b[0m                   \u001b[0;34m\"png\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                   modelf, layer, scaler, normalize, False, feature_tensor_size)\n",
            "\u001b[0;32m<ipython-input-28-4f9ec1a873c9>\u001b[0m in \u001b[0;36mapply_framework\u001b[0;34m(path, image_type, model, layer, scaler, normalize, isHSJOrBirds, feature_tensor_size)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply_framework\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misHSJOrBirds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_tensor_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m   embeddings = get_image_embeddings(path, \n\u001b[0m\u001b[1;32m    131\u001b[0m                                     \u001b[0mimage_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                                     model, layer, scaler, normalize, isHSJOrBirds, feature_tensor_size)\n",
            "\u001b[0;32m<ipython-input-28-4f9ec1a873c9>\u001b[0m in \u001b[0;36mget_image_embeddings\u001b[0;34m(path, image_type, model, layer, scaler, normalize, isHSJOrBirds, feature_tensor_size)\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0mim_no_name\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m\"0\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_no\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m         \u001b[0mfeature_tensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ref\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/ref/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim_no_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_tensor_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mfeature_tensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"p0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/p0/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim_no_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_tensor_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mfeature_tensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"p1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/p1/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim_no_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_tensor_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-28-4f9ec1a873c9>\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(image_name, model, layer, scaler, normalize, feature_tensor_size)\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mmy_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;31m# 5. Attach that function to our selected layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m     \u001b[0;31m# 6. Run the model on our transformed image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'register_forward_hook'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model._modules"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVN4caz6SJnL",
        "outputId": "38262bd8-d083-4598-c15d-c49bdfa5f3a9"
      },
      "id": "fVN4caz6SJnL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('conv_proj',\n",
              "              Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))),\n",
              "             ('encoder', Encoder(\n",
              "                (dropout): Dropout(p=0.0, inplace=False)\n",
              "                (layers): Sequential(\n",
              "                  (encoder_layer_0): EncoderBlock(\n",
              "                    (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (self_attention): MultiheadAttention(\n",
              "                      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "                    )\n",
              "                    (dropout): Dropout(p=0.0, inplace=False)\n",
              "                    (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (mlp): MLPBlock(\n",
              "                      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                      (1): GELU(approximate='none')\n",
              "                      (2): Dropout(p=0.0, inplace=False)\n",
              "                      (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                      (4): Dropout(p=0.0, inplace=False)\n",
              "                    )\n",
              "                  )\n",
              "                  (encoder_layer_1): EncoderBlock(\n",
              "                    (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (self_attention): MultiheadAttention(\n",
              "                      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "                    )\n",
              "                    (dropout): Dropout(p=0.0, inplace=False)\n",
              "                    (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (mlp): MLPBlock(\n",
              "                      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                      (1): GELU(approximate='none')\n",
              "                      (2): Dropout(p=0.0, inplace=False)\n",
              "                      (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                      (4): Dropout(p=0.0, inplace=False)\n",
              "                    )\n",
              "                  )\n",
              "                  (encoder_layer_2): EncoderBlock(\n",
              "                    (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (self_attention): MultiheadAttention(\n",
              "                      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "                    )\n",
              "                    (dropout): Dropout(p=0.0, inplace=False)\n",
              "                    (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (mlp): MLPBlock(\n",
              "                      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                      (1): GELU(approximate='none')\n",
              "                      (2): Dropout(p=0.0, inplace=False)\n",
              "                      (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                      (4): Dropout(p=0.0, inplace=False)\n",
              "                    )\n",
              "                  )\n",
              "                  (encoder_layer_3): EncoderBlock(\n",
              "                    (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (self_attention): MultiheadAttention(\n",
              "                      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "                    )\n",
              "                    (dropout): Dropout(p=0.0, inplace=False)\n",
              "                    (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (mlp): MLPBlock(\n",
              "                      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                      (1): GELU(approximate='none')\n",
              "                      (2): Dropout(p=0.0, inplace=False)\n",
              "                      (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                      (4): Dropout(p=0.0, inplace=False)\n",
              "                    )\n",
              "                  )\n",
              "                  (encoder_layer_4): EncoderBlock(\n",
              "                    (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (self_attention): MultiheadAttention(\n",
              "                      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "                    )\n",
              "                    (dropout): Dropout(p=0.0, inplace=False)\n",
              "                    (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (mlp): MLPBlock(\n",
              "                      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                      (1): GELU(approximate='none')\n",
              "                      (2): Dropout(p=0.0, inplace=False)\n",
              "                      (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                      (4): Dropout(p=0.0, inplace=False)\n",
              "                    )\n",
              "                  )\n",
              "                  (encoder_layer_5): EncoderBlock(\n",
              "                    (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (self_attention): MultiheadAttention(\n",
              "                      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "                    )\n",
              "                    (dropout): Dropout(p=0.0, inplace=False)\n",
              "                    (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (mlp): MLPBlock(\n",
              "                      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                      (1): GELU(approximate='none')\n",
              "                      (2): Dropout(p=0.0, inplace=False)\n",
              "                      (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                      (4): Dropout(p=0.0, inplace=False)\n",
              "                    )\n",
              "                  )\n",
              "                  (encoder_layer_6): EncoderBlock(\n",
              "                    (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (self_attention): MultiheadAttention(\n",
              "                      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "                    )\n",
              "                    (dropout): Dropout(p=0.0, inplace=False)\n",
              "                    (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (mlp): MLPBlock(\n",
              "                      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                      (1): GELU(approximate='none')\n",
              "                      (2): Dropout(p=0.0, inplace=False)\n",
              "                      (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                      (4): Dropout(p=0.0, inplace=False)\n",
              "                    )\n",
              "                  )\n",
              "                  (encoder_layer_7): EncoderBlock(\n",
              "                    (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (self_attention): MultiheadAttention(\n",
              "                      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "                    )\n",
              "                    (dropout): Dropout(p=0.0, inplace=False)\n",
              "                    (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (mlp): MLPBlock(\n",
              "                      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                      (1): GELU(approximate='none')\n",
              "                      (2): Dropout(p=0.0, inplace=False)\n",
              "                      (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                      (4): Dropout(p=0.0, inplace=False)\n",
              "                    )\n",
              "                  )\n",
              "                  (encoder_layer_8): EncoderBlock(\n",
              "                    (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (self_attention): MultiheadAttention(\n",
              "                      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "                    )\n",
              "                    (dropout): Dropout(p=0.0, inplace=False)\n",
              "                    (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (mlp): MLPBlock(\n",
              "                      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                      (1): GELU(approximate='none')\n",
              "                      (2): Dropout(p=0.0, inplace=False)\n",
              "                      (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                      (4): Dropout(p=0.0, inplace=False)\n",
              "                    )\n",
              "                  )\n",
              "                  (encoder_layer_9): EncoderBlock(\n",
              "                    (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (self_attention): MultiheadAttention(\n",
              "                      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "                    )\n",
              "                    (dropout): Dropout(p=0.0, inplace=False)\n",
              "                    (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (mlp): MLPBlock(\n",
              "                      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                      (1): GELU(approximate='none')\n",
              "                      (2): Dropout(p=0.0, inplace=False)\n",
              "                      (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                      (4): Dropout(p=0.0, inplace=False)\n",
              "                    )\n",
              "                  )\n",
              "                  (encoder_layer_10): EncoderBlock(\n",
              "                    (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (self_attention): MultiheadAttention(\n",
              "                      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "                    )\n",
              "                    (dropout): Dropout(p=0.0, inplace=False)\n",
              "                    (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (mlp): MLPBlock(\n",
              "                      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                      (1): GELU(approximate='none')\n",
              "                      (2): Dropout(p=0.0, inplace=False)\n",
              "                      (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                      (4): Dropout(p=0.0, inplace=False)\n",
              "                    )\n",
              "                  )\n",
              "                  (encoder_layer_11): EncoderBlock(\n",
              "                    (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (self_attention): MultiheadAttention(\n",
              "                      (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
              "                    )\n",
              "                    (dropout): Dropout(p=0.0, inplace=False)\n",
              "                    (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "                    (mlp): MLPBlock(\n",
              "                      (0): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                      (1): GELU(approximate='none')\n",
              "                      (2): Dropout(p=0.0, inplace=False)\n",
              "                      (3): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                      (4): Dropout(p=0.0, inplace=False)\n",
              "                    )\n",
              "                  )\n",
              "                )\n",
              "                (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
              "              )),\n",
              "             ('heads', Sequential(\n",
              "                (head): Linear(in_features=768, out_features=1000, bias=True)\n",
              "              ))])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_vector_dummy(image_name, model, layer, scaler, normalize, feature_tensor_size):\n",
        "    \n",
        "#     # Load the pretrained model\n",
        "#     model = models.resnet18(pretrained=True)\n",
        "#     # Use the model object to select the desired layer\n",
        "#     layer = model._modules.get('avgpool')\n",
        "    \n",
        "    # 1. Load the image with Pillow library\n",
        "    img = Image.open(image_name).convert('RGB')\n",
        "    # 2. Create a PyTorch Variable with the transformed image\n",
        "    t_img = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0)).cuda()\n",
        "    # 3. Create a vector of zeros that will hold our feature vector\n",
        "    #    The 'avgpool' layer has an output size of 512\n",
        "    \n",
        "    # M1: my_embedding = torch.zeros(1, 512, 1, 1) and later my_embedding.copy_(o.data)\n",
        "    # M2: my_embedding = torch.zeros(512) and later my_embedding.copy_(o.data.reshape(o.data.size(1)))\n",
        "    my_embedding = torch.zeros(feature_tensor_size).cuda()\n",
        "    \n",
        "    # 4. Define a function that will copy the output of a layer\n",
        "    def copy_data(m, i, o):\n",
        "        print(o.data.size())\n",
        "        # my_embedding.copy_(o.data.reshape(o.data.size(1)))\n",
        "        my_embedding.copy_(o.data)\n",
        "    # 5. Attach that function to our selected layer\n",
        "    h = layer.register_forward_hook(copy_data)\n",
        "    # 6. Run the model on our transformed image\n",
        "    model(t_img)\n",
        "    # 7. Detach our copy function from the layer\n",
        "    h.remove()\n",
        "    # 8. Return the feature vector\n",
        "    return torch.flatten(my_embedding)\n",
        "    "
      ],
      "metadata": {
        "id": "OIAIzSSe6B1o"
      },
      "id": "OIAIzSSe6B1o",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = transforms.Resize((224, 224))\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                 std=[0.229, 0.224, 0.225])\n",
        "\n",
        "model = models.resnet50(pretrained=True)\n",
        "model.cuda()\n",
        "model.eval()\n",
        "\n",
        "# layer = model._modules.get(\"avgpool\")\n",
        "\n",
        "# feature = get_vector_dummy(\"000039.jpg\", model, layer, scaler, normalize, 512)\n",
        "\n",
        "layer = model._modules.get(\"layer4\")\n",
        "\n",
        "feature = get_vector_dummy(\"000039.jpg\", model, layer, scaler, normalize, [1, 256, 14, 14])\n",
        "t = torch.zeros([1, 128, 1, 1])\n",
        "print(t.size())\n",
        "print(torch.flatten(t).size())\n",
        "print(torch.zeros(128).size())"
      ],
      "metadata": {
        "id": "rks04Dtl5vDt"
      },
      "id": "rks04Dtl5vDt",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zQHexWIaBRmZ",
        "outputId": "ba6b128d-d6f8-4bbf-ab9e-97858fa3a6c6"
      },
      "id": "zQHexWIaBRmZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([50176])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model._modules"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ODDK5Msd7Qfc",
        "outputId": "fd1245b9-24e9-44bf-a9f5-369ce8d15889"
      },
      "id": "ODDK5Msd7Qfc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('conv1',\n",
              "              Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)),\n",
              "             ('bn1',\n",
              "              BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)),\n",
              "             ('relu', ReLU(inplace=True)),\n",
              "             ('maxpool',\n",
              "              MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)),\n",
              "             ('layer1', Sequential(\n",
              "                (0): BasicBlock(\n",
              "                  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (relu): ReLU(inplace=True)\n",
              "                  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                )\n",
              "                (1): BasicBlock(\n",
              "                  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (relu): ReLU(inplace=True)\n",
              "                  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                )\n",
              "              )),\n",
              "             ('layer2', Sequential(\n",
              "                (0): BasicBlock(\n",
              "                  (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (relu): ReLU(inplace=True)\n",
              "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (downsample): Sequential(\n",
              "                    (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  )\n",
              "                )\n",
              "                (1): BasicBlock(\n",
              "                  (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (relu): ReLU(inplace=True)\n",
              "                  (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                )\n",
              "              )),\n",
              "             ('layer3', Sequential(\n",
              "                (0): BasicBlock(\n",
              "                  (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (relu): ReLU(inplace=True)\n",
              "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (downsample): Sequential(\n",
              "                    (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  )\n",
              "                )\n",
              "                (1): BasicBlock(\n",
              "                  (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (relu): ReLU(inplace=True)\n",
              "                  (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                )\n",
              "              )),\n",
              "             ('layer4', Sequential(\n",
              "                (0): BasicBlock(\n",
              "                  (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
              "                  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (relu): ReLU(inplace=True)\n",
              "                  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (downsample): Sequential(\n",
              "                    (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
              "                    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  )\n",
              "                )\n",
              "                (1): BasicBlock(\n",
              "                  (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                  (relu): ReLU(inplace=True)\n",
              "                  (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                  (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "                )\n",
              "              )),\n",
              "             ('avgpool', AdaptiveAvgPool2d(output_size=(1, 1))),\n",
              "             ('fc', Linear(in_features=512, out_features=1000, bias=True))])"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# diff layer\n",
        "layer = model._modules.get(\"layer3\")\n",
        "\n",
        "feature = get_vector_dummy(\"000039.jpg\", model, layer, scaler, normalize, 100352)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "4R-A4V7d7J0k",
        "outputId": "b4cef65b-4baf-486d-aaa5-e8e6a38b4a30"
      },
      "id": "4R-A4V7d7J0k",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 128, 28, 28])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-220ae3f16027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"layer3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_vector_dummy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"000039.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100352\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-49-1f889eeb7b2a>\u001b[0m in \u001b[0;36mget_vector_dummy\u001b[0;34m(image_name, model, layer, scaler, normalize, feature_tensor_size)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# 6. Run the model on our transformed image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;31m# 7. Detach our copy function from the layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m                 \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-e89a1959dc00>\u001b[0m in \u001b[0;36mcopy_data\u001b[0;34m(m, i, o)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcopy_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mmy_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m# 5. Attach that function to our selected layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[128]' is invalid for input of size 100352"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# diff layer\n",
        "layer = model._modules.get(\"layer3\")\n",
        "\n",
        "feature = get_vector_dummy(\"000039.jpg\", model, layer, scaler, normalize, 100352)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "L2TH9o3y8GNO",
        "outputId": "5d09f145-bd6d-4d30-8089-3e43086ff459"
      },
      "id": "L2TH9o3y8GNO",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 128, 28, 28])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-52-220ae3f16027>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"layer3\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfeature\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_vector_dummy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"000039.jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m100352\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-49-1f889eeb7b2a>\u001b[0m in \u001b[0;36mget_vector_dummy\u001b[0;34m(image_name, model, layer, scaler, normalize, feature_tensor_size)\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;31m# 6. Run the model on our transformed image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0;31m# 7. Detach our copy function from the layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 285\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    286\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torchvision/models/resnet.py\u001b[0m in \u001b[0;36m_forward_impl\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    272\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    275\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer4\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m                 \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-36-e89a1959dc00>\u001b[0m in \u001b[0;36mcopy_data\u001b[0;34m(m, i, o)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcopy_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0mmy_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0;31m# 5. Attach that function to our selected layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: shape '[128]' is invalid for input of size 100352"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Transformers - new framework </h1>"
      ],
      "metadata": {
        "id": "ZIg0GhlheEJ-"
      },
      "id": "ZIg0GhlheEJ-"
    },
    {
      "cell_type": "code",
      "source": [
        "# Tutorial: https://discuss.pytorch.org/t/feature-extraction-in-torchvision-models-vit-b-16/148029/4\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "\n",
        "scaler = transforms.Resize((224, 224))\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                  std=[0.229, 0.224, 0.225])\n",
        "  \n",
        "p0 = Variable(normalize(to_tensor(scaler(Image.open(\"p0.png\").convert('RGB')))).unsqueeze(0)).cuda()\n",
        "p1 = Variable(normalize(to_tensor(scaler(Image.open(\"p1.png\").convert('RGB')))).unsqueeze(0)).cuda()\n",
        "ref = Variable(normalize(to_tensor(scaler(Image.open(\"ref.png\").convert('RGB')))).unsqueeze(0)).cuda()\n",
        "\n",
        "model = torchvision.models.vit_b_16(pretrained=True)\n",
        "model.cuda()\n",
        "model.eval()\n",
        "feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
        "conv = feature_extractor[0]  \n",
        "encoder = feature_extractor[1]\n",
        "\n",
        "x_p0 = model._process_input(p0)\n",
        "x_p1 = model._process_input(p1)\n",
        "x_ref = model._process_input(ref)\n",
        "\n",
        "\n",
        "n = x_p0.shape[0]\n",
        "\n",
        "batch_class_token = model.class_token.expand(n, -1, -1)\n",
        "\n",
        "x_p0 = torch.cat([batch_class_token, x_p0], dim=1)\n",
        "x_p1 = torch.cat([batch_class_token, x_p1], dim=1)\n",
        "x_ref = torch.cat([batch_class_token, x_ref], dim=1)\n",
        "\n",
        "x_p0 = encoder(x_p0)\n",
        "x_p1 = encoder(x_p1)\n",
        "x_ref = encoder(x_ref)\n",
        "\n",
        "x_p0 = torch.flatten(x_p0[:,0])\n",
        "x_p1 = torch.flatten(x_p1[:,0])\n",
        "x_ref = torch.flatten(x_ref[:,0])\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        },
        "id": "WCrjWJXDTNqS",
        "outputId": "694e7353-3895-41be-b029-8d644ba92040"
      },
      "id": "WCrjWJXDTNqS",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-0c3f769044ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m                                   std=[0.229, 0.224, 0.225])\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mp0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"p0.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mp1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"p1.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ref.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2975\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2976\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'p0.png'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Memory issue fix: https://stackoverflow.com/questions/70885777/run-out-of-memory-trying-to-create-a-tensor-of-size-2191-512-with-pytorch-to"
      ],
      "metadata": {
        "id": "88U4gdz1sa1c"
      },
      "id": "88U4gdz1sa1c"
    },
    {
      "cell_type": "code",
      "source": [
        "# Tutorial: https://discuss.pytorch.org/t/feature-extraction-in-torchvision-models-vit-b-16/148029/4\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "model = torchvision.models.vit_b_16(pretrained=True)\n",
        "model.cuda()\n",
        "model.eval()\n",
        "feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
        "conv = feature_extractor[0]  \n",
        "encoder = feature_extractor[1]\n",
        "scaler = transforms.Resize((224, 224))\n",
        "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                    std=[0.229, 0.224, 0.225])\n",
        "to_tensor = transforms.ToTensor()\n",
        "    \n",
        "\n",
        "\n",
        "def get_vector(path):\n",
        "  with torch.no_grad():\n",
        "    p0 = Variable(normalize(to_tensor(scaler(Image.open(path).convert('RGB')))).unsqueeze(0)).cuda()\n",
        "\n",
        "    x_p0 = model._process_input(p0)\n",
        "\n",
        "    n = x_p0.shape[0]\n",
        "\n",
        "    batch_class_token = model.class_token.expand(n, -1, -1)\n",
        "\n",
        "    x_p0 = torch.cat([batch_class_token, x_p0], dim=1)\n",
        "\n",
        "    x_p0 = encoder(x_p0)\n",
        "\n",
        "    x_p0 = torch.flatten(x_p0[:,0])\n",
        "\n",
        "    return x_p0\n",
        "\n",
        "\n",
        "def get_image_embeddings(path, image_type, isHSJOrBirds):  # returns a list of tensors\n",
        "    # path of form: traditional/ref/\n",
        "    feature_tensor_dict = dict()\n",
        "    feature_tensor_dict[\"ref\"] = []\n",
        "    feature_tensor_dict[\"p0\"] = []\n",
        "    feature_tensor_dict[\"p1\"] = []\n",
        "    feature_tensor_dict[\"decision\"] = []\n",
        "    \n",
        "    for image_no in range(1000):\n",
        "        im_no_name =  (6-len(str(image_no)))*\"0\" + str(image_no) + \".\" + image_type\n",
        "        \n",
        "        feature_tensor_dict[\"ref\"].append(get_vector(path+\"/ref/\" + im_no_name))\n",
        "        feature_tensor_dict[\"p0\"].append(get_vector(path+\"/p0/\" + im_no_name))\n",
        "        feature_tensor_dict[\"p1\"].append(get_vector(path+\"/p1/\" + im_no_name))\n",
        "\n",
        "        # now load decision\n",
        "        if isHSJOrBirds:\n",
        "          feature_tensor_dict[\"decision\"].append(0)\n",
        "        else: \n",
        "          decision_no_name =  (6-len(str(image_no)))*\"0\" + str(image_no) + \".npy\"\n",
        "          decision = np.load(path+\"/judge/\"+decision_no_name)\n",
        "          if decision[0] <= 0.5: \n",
        "                feature_tensor_dict[\"decision\"].append(0)\n",
        "          else: \n",
        "                feature_tensor_dict[\"decision\"].append(1)\n",
        "        \n",
        "    return feature_tensor_dict\n",
        "\n",
        "########################## GET MODEL PREDICTIONS\n",
        "def get_predictions(embeddings):\n",
        "  cosine_similarity_dict = dict()\n",
        "  cosine_similarity_dict[\"ref_and_p0\"] = []\n",
        "  cosine_similarity_dict[\"ref_and_p1\"] = []\n",
        "  cosine_similarity_predictions = []\n",
        "\n",
        "  cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "  # cos_sim = cos(query_vector.unsqueeze(0), ref2_vector.unsqueeze(0))\n",
        "\n",
        "  for image_no in range(1000):\n",
        "      cosine_similarity_dict[\"ref_and_p0\"].append(cos(embeddings[\"ref\"][image_no].unsqueeze(0), embeddings[\"p0\"][image_no].unsqueeze(0)))\n",
        "      cosine_similarity_dict[\"ref_and_p1\"].append(cos(embeddings[\"ref\"][image_no].unsqueeze(0), embeddings[\"p1\"][image_no].unsqueeze(0)))\n",
        "      \n",
        "      if cosine_similarity_dict[\"ref_and_p0\"][image_no] >= cosine_similarity_dict[\"ref_and_p1\"][image_no]:\n",
        "          cosine_similarity_predictions.append(0)\n",
        "      else:\n",
        "          cosine_similarity_predictions.append(1)   \n",
        "  return cosine_similarity_predictions\n",
        "\n",
        "########################## GET MODEL ACCURACY\n",
        "def get_accuracy(predictions,embeddings):\n",
        "  decisions = embeddings[\"decision\"]\n",
        "\n",
        "  number_wrong_predictions = 0\n",
        "\n",
        "  for image_no in range(1000):\n",
        "      if predictions[image_no] != decisions[image_no]:\n",
        "          number_wrong_predictions += 1\n",
        "      \n",
        "  accuracy = (1000 - number_wrong_predictions)/(1000)\n",
        "  return accuracy\n",
        "\n",
        "def get_average_reference_similarty_for_dataset(predictions,embeddings):\n",
        "  similarities_p0_p1 = []\n",
        "  similarities_p0_ref = []\n",
        "  similarities_p1_ref = []\n",
        "  \n",
        "  cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "\n",
        "  for image_no in range(1000):\n",
        "      similarities_p0_p1.append(float(cos(embeddings[\"p0\"][image_no].unsqueeze(0), embeddings[\"p1\"][image_no].unsqueeze(0))))\n",
        "      similarities_p0_ref.append(float(cos(embeddings[\"ref\"][image_no].unsqueeze(0), embeddings[\"p0\"][image_no].unsqueeze(0))))\n",
        "      similarities_p1_ref.append(float(cos(embeddings[\"ref\"][image_no].unsqueeze(0), embeddings[\"p1\"][image_no].unsqueeze(0))))\n",
        "\n",
        "  similarity = np.average(similarities_p0_p1)/(float(np.average(similarities_p0_ref)+np.average(similarities_p1_ref)))\n",
        "\n",
        "  return similarity\n",
        "\n",
        "def apply_framework(path, image_type,isHSJOrBirds):\n",
        "  embeddings = get_image_embeddings(path, \n",
        "                                    image_type,\n",
        "                                    isHSJOrBirds)\n",
        "  predictions= get_predictions(embeddings)\n",
        "  accuracy = get_average_reference_similarty_for_dataset(predictions, embeddings)\n",
        "  print(path + \": \" + str(accuracy))\n",
        "  return accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDWHW3-ZkDhG",
        "outputId": "772c0029-23b4-4cfb-8d6a-8357ebc9380e"
      },
      "id": "pDWHW3-ZkDhG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ViT_B_16_Weights.IMAGENET1K_V1`. You can also use `weights=ViT_B_16_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_framework_model():\n",
        "  print(\"\")\n",
        "  print(\"# ----------------------------------------BAPPS 2AFC DIST-----------------------#\")\n",
        "  print(\"\")\n",
        "  ################### TRADITIONAL \n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/traditional_triplets\",\n",
        "                  \"png\",\n",
        "                  False)\n",
        "\n",
        "  ################ CNN\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/cnn_triplets\",\n",
        "                  \"png\",\n",
        "                  False)\n",
        "\n",
        "  ############### COLOR\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/color_triplets\",\n",
        "                  \"png\",\n",
        "                  False)\n",
        "\n",
        "  ################ DEBLUR\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/deblur_triplets\",\n",
        "                  \"png\",\n",
        "                  False)\n",
        "\n",
        "  ############### FRAME INTERP\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/frameinterp_triplets\",\n",
        "                  \"png\",\n",
        "                  False)\n",
        "\n",
        "  ################ SUPER RES\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/superres_triplets\",\n",
        "                  \"png\",\n",
        "                  False)\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"# ----------------------------------------HSJ------------------------#\")\n",
        "  print(\"\")\n",
        "  ################### HSJ Rank 0 + Dissimilar \n",
        "  apply_framework(\"datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar\",\n",
        "                  \"jpg\",\n",
        "                  True)\n",
        "\n",
        "  ################ HSJ Rank 0 + Rank 1\n",
        "  apply_framework(\"datasets/hsj/hsj_triplets/hsj_query_rank0_rank1\",\n",
        "                  \"jpg\",\n",
        "                  True)\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"# ----------------------------------------Birds-16------------------------#\")\n",
        "  print(\"\")\n",
        "  ################### Birds-16 Rank 0 + Dissimilar \n",
        "  apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar\",\n",
        "                  \"jpg\",\n",
        "                  True)\n",
        "\n",
        "  ################### Birds-16 Rank 0 + Rank 1 \n",
        "  apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1\",\n",
        "                  \"jpg\",\n",
        "                  True)\n",
        "\n",
        "  ################### Birds-16 Rank 0 + Dissimilar 2rank1 test\n",
        "  apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1\",\n",
        "                  \"jpg\",\n",
        "                  True)"
      ],
      "metadata": {
        "id": "9UznXre4s_wa"
      },
      "id": "9UznXre4s_wa",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apply_framework_model() # reference similarity now"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NJ6NCjaHeunb",
        "outputId": "266f0a23-33c2-4593-a14d-2e1549de530c"
      },
      "id": "NJ6NCjaHeunb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n",
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.44550060127941576\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.4440446430166139\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.579516591105198\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.5268853097386452\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.4992213435853494\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.5178743461653065\n",
            "\n",
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.18113079661114512\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.21535694448091444\n",
            "\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.401459205264333\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.4775735705237343\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.4011398050617586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "apply_framework_model() # reference similarity now"
      ],
      "metadata": {
        "id": "zIc6qlS8gUgx"
      },
      "id": "zIc6qlS8gUgx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "# print(cos(get_vector(\"p0.png\").unsqueeze(0),get_vector(\"ref.png\").unsqueeze(0)))\n",
        "# print(cos(get_vector(\"p1.png\").unsqueeze(0),get_vector(\"ref.png\").unsqueeze(0)))\n",
        "f_dict_new = get_image_embeddings(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar\", \"jpg\", True)"
      ],
      "metadata": {
        "id": "l6Qb-IAlThTf"
      },
      "id": "l6Qb-IAlThTf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(f_dict_new[\"ref\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H99zIM3HrUxN",
        "outputId": "be479080-2118-4285-bf80-87377330bee8"
      },
      "id": "H99zIM3HrUxN",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1000"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ViT_B_16 - ask chat to describe differences\n",
        "\n",
        " ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
        "\n",
        "datasets/distortions/distortion_triplets/traditional_triplets: 0.804\n",
        "\n",
        "datasets/distortions/distortion_triplets/cnn_triplets: 0.832\n",
        "\n",
        "datasets/distortions/distortion_triplets/color_triplets: 0.619\n",
        "\n",
        "datasets/distortions/distortion_triplets/deblur_triplets: 0.617\n",
        "\n",
        "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.658\n",
        "\n",
        "datasets/distortions/distortion_triplets/superres_triplets: 0.71\n",
        "\n",
        " ----------------------------------------HSJ------------------------#\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.566\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.532\n",
        "\n",
        "----------------------------------------Birds-16------------------------#\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.771\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.634\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.794\n",
        "\n"
      ],
      "metadata": {
        "id": "--r7GEafuw1i"
      },
      "id": "--r7GEafuw1i"
    },
    {
      "cell_type": "code",
      "source": [
        "apply_framework_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrx2Aekota5B",
        "outputId": "e4e710aa-b934-4737-e7ca-9262204da375"
      },
      "id": "qrx2Aekota5B",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n",
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.804\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.832\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.619\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.617\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.658\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.71\n",
            "\n",
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.566\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.532\n",
            "\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.771\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.634\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vit_b_32\n",
        "\n",
        "----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
        "\n",
        "datasets/distortions/distortion_triplets/traditional_triplets: 0.771\n",
        "\n",
        "datasets/distortions/distortion_triplets/cnn_triplets: 0.824\n",
        "\n",
        "datasets/distortions/distortion_triplets/color_triplets: 0.577\n",
        "\n",
        "datasets/distortions/distortion_triplets/deblur_triplets: 0.597\n",
        "\n",
        "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.674\n",
        "\n",
        "datasets/distortions/distortion_triplets/superres_triplets: 0.686\n",
        "\n",
        "----------------------------------------HSJ------------------------#\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.551\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.556\n",
        "\n",
        "----------------------------------------Birds-16------------------------#\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.787\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.636\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.794"
      ],
      "metadata": {
        "id": "vZsgssuSywV8"
      },
      "id": "vZsgssuSywV8"
    },
    {
      "cell_type": "code",
      "source": [
        "apply_framework_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC6F3P5-y0Lp",
        "outputId": "c00168ff-b218-4bd9-b773-7e95168b5351"
      },
      "id": "CC6F3P5-y0Lp",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n",
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.771\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.824\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.577\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.597\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.674\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.686\n",
            "\n",
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.551\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.556\n",
            "\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.787\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.636\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.794\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vit_l_16\n",
        "\n",
        "----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
        "\n",
        "datasets/distortions/distortion_triplets/traditional_triplets: 0.779\n",
        "\n",
        "datasets/distortions/distortion_triplets/cnn_triplets: 0.832\n",
        "\n",
        "datasets/distortions/distortion_triplets/color_triplets: 0.625\n",
        "\n",
        "datasets/distortions/distortion_triplets/deblur_triplets: 0.588\n",
        "\n",
        "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.66\n",
        "\n",
        "datasets/distortions/distortion_triplets/superres_triplets: 0.688\n",
        "\n",
        "----------------------------------------HSJ------------------------#\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.569\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.54\n",
        "\n",
        "----------------------------------------Birds-16------------------------#\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.791\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.622\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.825"
      ],
      "metadata": {
        "id": "ijS3i-Qt0dzv"
      },
      "id": "ijS3i-Qt0dzv"
    },
    {
      "cell_type": "code",
      "source": [
        "apply_framework_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2qyc35P90nO-",
        "outputId": "ae502b14-87c6-4b92-87d8-1225b8177211"
      },
      "id": "2qyc35P90nO-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n",
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.779\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.832\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.625\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.588\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.66\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.688\n",
            "\n",
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.569\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.54\n",
            "\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.791\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.622\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.825\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vit_l_32\n",
        "\n",
        "----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
        "\n",
        "datasets/distortions/distortion_triplets/traditional_triplets: 0.776\n",
        "\n",
        "datasets/distortions/distortion_triplets/cnn_triplets: 0.839\n",
        "\n",
        "datasets/distortions/distortion_triplets/color_triplets: 0.571\n",
        "\n",
        "datasets/distortions/distortion_triplets/deblur_triplets: 0.577\n",
        "\n",
        "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.657\n",
        "\n",
        "datasets/distortions/distortion_triplets/superres_triplets: 0.637\n",
        "\n",
        "----------------------------------------HSJ------------------------#\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.565\n",
        "\n",
        "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.552\n",
        "\n",
        "----------------------------------------Birds-16------------------------#\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.767\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.616\n",
        "\n",
        "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.76"
      ],
      "metadata": {
        "id": "zzTrwXML89tP"
      },
      "id": "zzTrwXML89tP"
    },
    {
      "cell_type": "code",
      "source": [
        "apply_framework_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWj7ZTRk9FAk",
        "outputId": "98a9951e-210a-402a-b06a-ad74c3d44756"
      },
      "id": "AWj7ZTRk9FAk",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n",
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.776\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.839\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.571\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.577\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.657\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.637\n",
            "\n",
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.565\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.552\n",
            "\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.767\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.616\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3> New framework: </h3>"
      ],
      "metadata": {
        "id": "XGFZIECefylI"
      },
      "id": "XGFZIECefylI"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install img2vec-pytorch\n",
        "!unzip -uq \"/content/drive/MyDrive/Colab Notebooks/distortion_triplets.zip\" -d \"/content/datasets/distortions\"\n",
        "!unzip -uq \"/content/drive/MyDrive/Colab Notebooks/hsj_triplets.zip\" -d \"/content/datasets/hsj\"\n",
        "!unzip -uq \"/content/drive/MyDrive/Colab Notebooks/birds_dataset_triplets.zip\" -d \"/content/datasets/birds-16\""
      ],
      "metadata": {
        "id": "gAFe3GzEq2KG"
      },
      "id": "gAFe3GzEq2KG",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "############################ REQUIRES MODIFICATION FOR EACH MODEL \n",
        "\n",
        "# scaler = transforms.Resize((224, 224))\n",
        "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "#                                  std=[0.229, 0.224, 0.225])\n",
        "to_tensor = transforms.ToTensor()   # used to convert the PIL image to a PyTorch tensor (multidimensional array)\n",
        "############################\n",
        "\n",
        "\n",
        "############################## HOW TO GET MODEL:\n",
        "# # Load the pretrained model\n",
        "# model = models.resnet18(pretrained=True)\n",
        "# model.cuda()\n",
        "# # Use the model object to select the desired layer\n",
        "# layer = model._modules.get('avgpool')\n",
        "# # Set model to evaluation mode\n",
        "# model.eval()\n",
        "\n",
        "##################################\n",
        "\n",
        "# def get_vector(image_name, model, layer, scaler, normalize, feature_tensor_size):\n",
        "    \n",
        "# #     # Load the pretrained model\n",
        "# #     model = models.resnet18(pretrained=True)\n",
        "# #     # Use the model object to select the desired layer\n",
        "# #     layer = model._modules.get('avgpool')\n",
        "    \n",
        "#     # 1. Load the image with Pillow library\n",
        "#     img = Image.open(image_name).convert('RGB')\n",
        "#     # 2. Create a PyTorch Variable with the transformed image\n",
        "#     t_img = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0)).cuda()\n",
        "\n",
        "    \n",
        "#     feature_extractor = nn.Sequential(*list(model.children())[:-1])\n",
        "#     conv = feature_extractor[0]  \n",
        "#     encoder = feature_extractor[1]\n",
        "\n",
        "#     x_p0 = model._process_input(t_img)\n",
        "#     n = x_p0.shape[0]\n",
        "#     batch_class_token = model.class_token.expand(n, -1, -1)\n",
        "#     x_p0 = torch.cat([batch_class_token, x_p0], dim=1)\n",
        "#     x_p0 = encoder(x_p0)\n",
        "#     x_p0 = torch.flatten(x_p0[:,0])\n",
        "\n",
        "#     return x_p0\n",
        "\n",
        "############################ COSINE SIMILARITY\n",
        "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "\n",
        "\n",
        "########################### GET FEATURE VECTORS\n",
        "def get_image_embeddings(path, image_type, model, layer, scaler, normalize, isHSJOrBirds, feature_tensor_size):  # returns a list of tensors\n",
        "    # path of form: traditional/ref/\n",
        "    feature_tensor_dict = dict()\n",
        "    feature_tensor_dict[\"ref\"] = []\n",
        "    feature_tensor_dict[\"p0\"] = []\n",
        "    feature_tensor_dict[\"p1\"] = []\n",
        "    feature_tensor_dict[\"decision\"] = []\n",
        "    \n",
        "    for image_no in range(1000):\n",
        "        im_no_name =  (6-len(str(image_no)))*\"0\" + str(image_no) + \".\" + image_type\n",
        "        \n",
        "        feature_tensor_dict[\"ref\"].append(get_vector(path+\"/ref/\" + im_no_name))\n",
        "        feature_tensor_dict[\"p0\"].append(get_vector(path+\"/p0/\" + im_no_name))\n",
        "        feature_tensor_dict[\"p1\"].append(get_vector(path+\"/p1/\" + im_no_name))\n",
        "\n",
        "        # now load decision\n",
        "        if isHSJOrBirds:\n",
        "          feature_tensor_dict[\"decision\"].append(0)\n",
        "        else: \n",
        "          decision_no_name =  (6-len(str(image_no)))*\"0\" + str(image_no) + \".npy\"\n",
        "          decision = np.load(path+\"/judge/\"+decision_no_name)\n",
        "          if decision[0] <= 0.5: \n",
        "                feature_tensor_dict[\"decision\"].append(0)\n",
        "          else: \n",
        "                feature_tensor_dict[\"decision\"].append(1)\n",
        "        \n",
        "    return feature_tensor_dict\n",
        "\n",
        "\n",
        "########################## GET MODEL PREDICTIONS\n",
        "def get_predictions(embeddings):\n",
        "  cosine_similarity_dict = dict()\n",
        "  cosine_similarity_dict[\"ref_and_p0\"] = []\n",
        "  cosine_similarity_dict[\"ref_and_p1\"] = []\n",
        "  cosine_similarity_predictions = []\n",
        "\n",
        "  cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "  # cos_sim = cos(query_vector.unsqueeze(0), ref2_vector.unsqueeze(0))\n",
        "\n",
        "  for image_no in range(1000):\n",
        "      cosine_similarity_dict[\"ref_and_p0\"].append(cos(embeddings[\"ref\"][image_no].unsqueeze(0), embeddings[\"p0\"][image_no].unsqueeze(0)))\n",
        "      cosine_similarity_dict[\"ref_and_p1\"].append(cos(embeddings[\"ref\"][image_no].unsqueeze(0), embeddings[\"p1\"][image_no].unsqueeze(0)))\n",
        "      \n",
        "      if cosine_similarity_dict[\"ref_and_p0\"][image_no] >= cosine_similarity_dict[\"ref_and_p1\"][image_no]:\n",
        "          cosine_similarity_predictions.append(0)\n",
        "      else:\n",
        "          cosine_similarity_predictions.append(1)   \n",
        "  return cosine_similarity_predictions\n",
        "\n",
        "########################## GET MODEL ACCURACY\n",
        "def get_accuracy(predictions,embeddings):\n",
        "  decisions = embeddings[\"decision\"]\n",
        "\n",
        "  number_wrong_predictions = 0\n",
        "\n",
        "  for image_no in range(1000):\n",
        "      if predictions[image_no] != decisions[image_no]:\n",
        "          number_wrong_predictions += 1\n",
        "      \n",
        "  accuracy = (1000 - number_wrong_predictions)/(1000)\n",
        "  return accuracy\n",
        "\n",
        "\n",
        "def apply_framework(path, image_type, model, layer, scaler, normalize, isHSJOrBirds, feature_tensor_size):\n",
        "  embeddings = get_image_embeddings(path, \n",
        "                                    image_type,\n",
        "                                    model, layer, scaler, normalize, isHSJOrBirds, feature_tensor_size)\n",
        "  predictions= get_predictions(embeddings)\n",
        "  accuracy = get_accuracy(predictions, embeddings)\n",
        "  print(path + \": \" + str(accuracy))\n",
        "  return accuracy"
      ],
      "metadata": {
        "id": "eq3k76SqeNE2"
      },
      "id": "eq3k76SqeNE2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_framework_model(modelf, layer, feature_tensor_size):\n",
        "  scaler = transforms.Resize((224, 224))\n",
        "  normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                  std=[0.229, 0.224, 0.225])\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"# ----------------------------------------BAPPS 2AFC DIST-----------------------#\")\n",
        "  print(\"\")\n",
        "  ################### TRADITIONAL \n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/traditional_triplets\",\n",
        "                  \"png\",\n",
        "                  modelf, layer, scaler, normalize, False, feature_tensor_size)\n",
        "\n",
        "  ################ CNN\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/cnn_triplets\",\n",
        "                  \"png\",\n",
        "                  modelf, layer, scaler, normalize, False, feature_tensor_size)\n",
        "\n",
        "  ############### COLOR\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/color_triplets\",\n",
        "                  \"png\",\n",
        "                  modelf, layer, scaler, normalize, False, feature_tensor_size)\n",
        "\n",
        "  ################ DEBLUR\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/deblur_triplets\",\n",
        "                  \"png\",\n",
        "                  modelf, layer, scaler, normalize, False, feature_tensor_size)\n",
        "\n",
        "  ############### FRAME INTERP\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/frameinterp_triplets\",\n",
        "                  \"png\",\n",
        "                  modelf, layer, scaler, normalize, False, feature_tensor_size)\n",
        "\n",
        "  ################ SUPER RES\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/superres_triplets\",\n",
        "                  \"png\",\n",
        "                  modelf, layer, scaler, normalize, False, feature_tensor_size)\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"# ----------------------------------------HSJ------------------------#\")\n",
        "  print(\"\")\n",
        "  ################### HSJ Rank 0 + Dissimilar \n",
        "  apply_framework(\"datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar\",\n",
        "                  \"jpg\",\n",
        "                  modelf, layer, scaler, normalize, True, feature_tensor_size)\n",
        "\n",
        "  ################ HSJ Rank 0 + Rank 1\n",
        "  apply_framework(\"datasets/hsj/hsj_triplets/hsj_query_rank0_rank1\",\n",
        "                  \"jpg\",\n",
        "                  modelf, layer, scaler, normalize, True, feature_tensor_size)\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"# ----------------------------------------Birds-16------------------------#\")\n",
        "  print(\"\")\n",
        "  ################### Birds-16 Rank 0 + Dissimilar \n",
        "  apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar\",\n",
        "                  \"jpg\",\n",
        "                  modelf, layer, scaler, normalize, True, feature_tensor_size)\n",
        "\n",
        "  ################### Birds-16 Rank 0 + Rank 1 \n",
        "  apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1\",\n",
        "                  \"jpg\",\n",
        "                  modelf, layer, scaler, normalize, True, feature_tensor_size)\n",
        "\n",
        "  ################### Birds-16 Rank 0 + Dissimilar 2rank1 test\n",
        "  apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1\",\n",
        "                  \"jpg\",\n",
        "                  modelf, layer, scaler, normalize, True, feature_tensor_size)"
      ],
      "metadata": {
        "id": "YnfDJ9S2f8hm"
      },
      "id": "YnfDJ9S2f8hm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Similarity between references for each dataset </h1>"
      ],
      "metadata": {
        "id": "xtadaRexcGrg"
      },
      "id": "xtadaRexcGrg"
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "############################ REQUIRES MODIFICATION FOR EACH MODEL \n",
        "\n",
        "# scaler = transforms.Resize((224, 224))\n",
        "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "#                                  std=[0.229, 0.224, 0.225])\n",
        "to_tensor = transforms.ToTensor()   # used to convert the PIL image to a PyTorch tensor (multidimensional array)\n",
        "############################\n",
        "\n",
        "\n",
        "############################## HOW TO GET MODEL:\n",
        "# # Load the pretrained model\n",
        "# model = models.resnet18(pretrained=True)\n",
        "# model.cuda()\n",
        "# # Use the model object to select the desired layer\n",
        "# layer = model._modules.get('avgpool')\n",
        "# # Set model to evaluation mode\n",
        "# model.eval()\n",
        "\n",
        "##################################\n",
        "\n",
        "def get_vector(image_name, model, layer, scaler, normalize, feature_tensor_size):\n",
        "    \n",
        "#     # Load the pretrained model\n",
        "#     model = models.resnet18(pretrained=True)\n",
        "#     # Use the model object to select the desired layer\n",
        "#     layer = model._modules.get('avgpool')\n",
        "    \n",
        "    # 1. Load the image with Pillow library\n",
        "    img = Image.open(image_name).convert('RGB')\n",
        "    # 2. Create a PyTorch Variable with the transformed image\n",
        "    t_img = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0)).cuda()\n",
        "    # 3. Create a vector of zeros that will hold our feature vector\n",
        "    #    The 'avgpool' layer has an output size of 512\n",
        "    \n",
        "    # M1: my_embedding = torch.zeros(1, 512, 1, 1) and later my_embedding.copy_(o.data)\n",
        "    # M2: my_embedding = torch.zeros(512) and later my_embedding.copy_(o.data.reshape(o.data.size(1)))\n",
        "    my_embedding = torch.zeros(feature_tensor_size).cuda()\n",
        "    \n",
        "    # 4. Define a function that will copy the output of a layer\n",
        "    def copy_data(m, i, o):\n",
        "        my_embedding.copy_(o.data)\n",
        "    # 5. Attach that function to our selected layer\n",
        "    h = layer.register_forward_hook(copy_data)\n",
        "    # 6. Run the model on our transformed image\n",
        "    model(t_img)\n",
        "    # 7. Detach our copy function from the layer\n",
        "    h.remove()\n",
        "    # 8. Return the feature vector\n",
        "    return torch.flatten(my_embedding)\n",
        "\n",
        "############################ COSINE SIMILARITY\n",
        "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "\n",
        "\n",
        "########################### GET FEATURE VECTORS\n",
        "def get_image_embeddings(path, image_type, model, layer, scaler, normalize, isHSJOrBirds, feature_tensor_size):  # returns a list of tensors\n",
        "    # path of form: traditional/ref/\n",
        "    feature_tensor_dict = dict()\n",
        "    feature_tensor_dict[\"ref\"] = []\n",
        "    feature_tensor_dict[\"p0\"] = []\n",
        "    feature_tensor_dict[\"p1\"] = []\n",
        "    feature_tensor_dict[\"decision\"] = []\n",
        "    \n",
        "    for image_no in range(1000):\n",
        "        im_no_name =  (6-len(str(image_no)))*\"0\" + str(image_no) + \".\" + image_type\n",
        "        \n",
        "        feature_tensor_dict[\"ref\"].append(get_vector(path+\"/ref/\" + im_no_name, model, layer, scaler, normalize, feature_tensor_size))\n",
        "        feature_tensor_dict[\"p0\"].append(get_vector(path+\"/p0/\" + im_no_name, model, layer, scaler, normalize, feature_tensor_size))\n",
        "        feature_tensor_dict[\"p1\"].append(get_vector(path+\"/p1/\" + im_no_name, model, layer, scaler, normalize, feature_tensor_size))\n",
        "\n",
        "        # now load decision\n",
        "        if isHSJOrBirds:\n",
        "          feature_tensor_dict[\"decision\"].append(0)\n",
        "        else: \n",
        "          decision_no_name =  (6-len(str(image_no)))*\"0\" + str(image_no) + \".npy\"\n",
        "          decision = np.load(path+\"/judge/\"+decision_no_name)\n",
        "          if decision[0] <= 0.5: \n",
        "                feature_tensor_dict[\"decision\"].append(0)\n",
        "          else: \n",
        "                feature_tensor_dict[\"decision\"].append(1)\n",
        "        \n",
        "    return feature_tensor_dict\n",
        "\n",
        "\n",
        "########################## GET MODEL PREDICTIONS\n",
        "def get_predictions(embeddings):\n",
        "  cosine_similarity_dict = dict()\n",
        "  cosine_similarity_dict[\"ref_and_p0\"] = []\n",
        "  cosine_similarity_dict[\"ref_and_p1\"] = []\n",
        "  cosine_similarity_predictions = []\n",
        "\n",
        "  cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "  # cos_sim = cos(query_vector.unsqueeze(0), ref2_vector.unsqueeze(0))\n",
        "\n",
        "  for image_no in range(1000):\n",
        "      cosine_similarity_dict[\"ref_and_p0\"].append(cos(embeddings[\"ref\"][image_no].unsqueeze(0), embeddings[\"p0\"][image_no].unsqueeze(0)))\n",
        "      cosine_similarity_dict[\"ref_and_p1\"].append(cos(embeddings[\"ref\"][image_no].unsqueeze(0), embeddings[\"p1\"][image_no].unsqueeze(0)))\n",
        "      \n",
        "      if cosine_similarity_dict[\"ref_and_p0\"][image_no] >= cosine_similarity_dict[\"ref_and_p1\"][image_no]:\n",
        "          cosine_similarity_predictions.append(0)\n",
        "      else:\n",
        "          cosine_similarity_predictions.append(1)   \n",
        "  return cosine_similarity_predictions\n",
        "\n",
        "########################## GET MODEL ACCURACY\n",
        "def get_accuracy(predictions,embeddings):\n",
        "  decisions = embeddings[\"decision\"]\n",
        "\n",
        "  number_wrong_predictions = 0\n",
        "\n",
        "  for image_no in range(1000):\n",
        "      if predictions[image_no] != decisions[image_no]:\n",
        "          number_wrong_predictions += 1\n",
        "      \n",
        "  accuracy = (1000 - number_wrong_predictions)/(1000)\n",
        "  return accuracy\n",
        "\n",
        "def get_average_reference_similarty_for_dataset(predictions,embeddings):\n",
        "  similarities_p0_p1 = []\n",
        "  similarities_p0_ref = []\n",
        "  similarities_p1_ref = []\n",
        "  \n",
        "  cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "\n",
        "  for image_no in range(1000):\n",
        "      similarities_p0_p1.append(float(cos(embeddings[\"p0\"][image_no].unsqueeze(0), embeddings[\"p1\"][image_no].unsqueeze(0))))\n",
        "      similarities_p0_ref.append(float(cos(embeddings[\"ref\"][image_no].unsqueeze(0), embeddings[\"p0\"][image_no].unsqueeze(0))))\n",
        "      similarities_p1_ref.append(float(cos(embeddings[\"ref\"][image_no].unsqueeze(0), embeddings[\"p1\"][image_no].unsqueeze(0))))\n",
        "\n",
        "  similarity = np.average(similarities_p0_p1)/(float(np.average(similarities_p0_ref)+np.average(similarities_p1_ref)))\n",
        "\n",
        "  return similarity\n",
        "  \n",
        "\n",
        "def apply_framework(path, image_type, model, layer, scaler, normalize, isHSJOrBirds, feature_tensor_size):\n",
        "  embeddings = get_image_embeddings(path, \n",
        "                                    image_type,\n",
        "                                    model, layer, scaler, normalize, isHSJOrBirds, feature_tensor_size)\n",
        "  predictions= get_predictions(embeddings)\n",
        "  accuracy = get_accuracy(predictions, embeddings)\n",
        "  print(path + \": \" + str(accuracy))\n",
        "  return accuracy\n",
        "\n",
        "def apply_framework_model(modelf, layer, feature_tensor_size):\n",
        "  scaler = transforms.Resize((224, 224))\n",
        "  normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                  std=[0.229, 0.224, 0.225])\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"# ----------------------------------------BAPPS 2AFC DIST-----------------------#\")\n",
        "  print(\"\")\n",
        "  ################### TRADITIONAL \n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/traditional_triplets\",\n",
        "                  \"png\",\n",
        "                  modelf, layer, scaler, normalize, False, feature_tensor_size)\n",
        "\n",
        "  ################ CNN\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/cnn_triplets\",\n",
        "                  \"png\",\n",
        "                  modelf, layer, scaler, normalize, False, feature_tensor_size)\n",
        "\n",
        "  ############### COLOR\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/color_triplets\",\n",
        "                  \"png\",\n",
        "                  modelf, layer, scaler, normalize, False, feature_tensor_size)\n",
        "\n",
        "  ################ DEBLUR\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/deblur_triplets\",\n",
        "                  \"png\",\n",
        "                  modelf, layer, scaler, normalize, False, feature_tensor_size)\n",
        "\n",
        "  ############### FRAME INTERP\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/frameinterp_triplets\",\n",
        "                  \"png\",\n",
        "                  modelf, layer, scaler, normalize, False, feature_tensor_size)\n",
        "\n",
        "  ################ SUPER RES\n",
        "  apply_framework(\"datasets/distortions/distortion_triplets/superres_triplets\",\n",
        "                  \"png\",\n",
        "                  modelf, layer, scaler, normalize, False, feature_tensor_size)\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"# ----------------------------------------HSJ------------------------#\")\n",
        "  print(\"\")\n",
        "  ################### HSJ Rank 0 + Dissimilar \n",
        "  apply_framework(\"datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar\",\n",
        "                  \"jpg\",\n",
        "                  modelf, layer, scaler, normalize, True, feature_tensor_size)\n",
        "\n",
        "  ################ HSJ Rank 0 + Rank 1\n",
        "  apply_framework(\"datasets/hsj/hsj_triplets/hsj_query_rank0_rank1\",\n",
        "                  \"jpg\",\n",
        "                  modelf, layer, scaler, normalize, True, feature_tensor_size)\n",
        "\n",
        "  print(\"\")\n",
        "  print(\"# ----------------------------------------Birds-16------------------------#\")\n",
        "  print(\"\")\n",
        "  ################### Birds-16 Rank 0 + Dissimilar \n",
        "  apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar\",\n",
        "                  \"jpg\",\n",
        "                  modelf, layer, scaler, normalize, True, feature_tensor_size)\n",
        "\n",
        "  ################### Birds-16 Rank 0 + Rank 1 \n",
        "  apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1\",\n",
        "                  \"jpg\",\n",
        "                  modelf, layer, scaler, normalize, True, feature_tensor_size)\n",
        "\n",
        "  ################### Birds-16 Rank 0 + Dissimilar 2rank1 test\n",
        "  apply_framework(\"datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1\",\n",
        "                  \"jpg\",\n",
        "                  modelf, layer, scaler, normalize, True, feature_tensor_size)"
      ],
      "metadata": {
        "id": "8FmPCI28cMZW"
      },
      "id": "8FmPCI28cMZW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"#-------------------------------Resnet-18-------------------------------------#\")\n",
        "model = models.resnet18(pretrained=True)\n",
        "model.cuda()\n",
        "layer = model._modules.get(\"avgpool\")\n",
        "model.eval()\n",
        "apply_framework_model(model,layer,[1, 512, 1, 1])\n",
        "\n",
        "print(\"#-------------------------------AlexNet-------------------------------------#\")\n",
        "print(\"alexnet\")\n",
        "model = models.alexnet(pretrained=True)\n",
        "model.cuda()\n",
        "layer = model._modules.get(\"avgpool\")\n",
        "model.eval()\n",
        "apply_framework_model(model,layer,[1, 256, 6, 6])\n",
        "\n",
        "print(\"#-------------------------------EfficientNet-------------------------------------#\")\n",
        "model = models.efficientnet_b0(pretrained=True)\n",
        "model.cuda()\n",
        "layer = model._modules.get(\"avgpool\")\n",
        "model.eval()\n",
        "apply_framework_model(model,layer,[1, 1280, 1, 1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "70b50fdf983e42098f0435261aec9fa3",
            "5e7907f27f8d4b49a3baeaab7fe5e4e7",
            "5137bb0cc231464f9cfd9ed392242948",
            "c1b2fa2f253245898d9b4e05a58080fa",
            "0dd0bbaf98b145d59b62451b7f086a4a",
            "119d4d6375e44ac0be64515d49e889da",
            "a174d6a993554ebfa2ad306f4dd9a76a",
            "1c1d47cf2d1a4100bb6b94ee967daf4c",
            "3d49b8b4c2f24517bc3d444598143e26",
            "ef9cf3c084684193876d0b3438cba00d",
            "5ec4fbb76c3f4effa82e83be008388e0"
          ]
        },
        "id": "pkEW2FLodYo6",
        "outputId": "cd3cc877-f19c-4cb8-9b78-f387dfa1c54d"
      },
      "id": "pkEW2FLodYo6",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#-------------------------------Resnet-18-------------------------------------#\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n",
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.4641208374760602\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.47506779143223193\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.5205962052334754\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.5227560103399405\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.49837198871172556\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.5032645443982735\n",
            "\n",
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.46999940363671466\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.48269508874571315\n",
            "\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.4763286114740994\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.4901479407311331\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.4713947121570724\n",
            "#-------------------------------AlexNet-------------------------------------#\n",
            "alexnet\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n",
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.4364289060079188\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.45928621575531037\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.542875106223054\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.522324235014437\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.5016308570654885\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.504446025573848\n",
            "\n",
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.3888592227278987\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.4373141247893356\n",
            "\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.4305198639769745\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.4636477607016273\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.41671250148154804\n",
            "#-------------------------------EfficientNet-------------------------------------#\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B0_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B0_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-3dd342df.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-3dd342df.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/20.5M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70b50fdf983e42098f0435261aec9fa3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "# ----------------------------------------BAPPS 2AFC DIST-----------------------#\n",
            "\n",
            "datasets/distortions/distortion_triplets/traditional_triplets: 0.43987050895301505\n",
            "datasets/distortions/distortion_triplets/cnn_triplets: 0.4405119395727711\n",
            "datasets/distortions/distortion_triplets/color_triplets: 0.5492265690689818\n",
            "datasets/distortions/distortion_triplets/deblur_triplets: 0.553268302017516\n",
            "datasets/distortions/distortion_triplets/frameinterp_triplets: 0.49308268301438096\n",
            "datasets/distortions/distortion_triplets/superres_triplets: 0.5104082710720147\n",
            "\n",
            "# ----------------------------------------HSJ------------------------#\n",
            "\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_dissimilar: 0.10308682840902555\n",
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.14060771732463742\n",
            "\n",
            "# ----------------------------------------Birds-16------------------------#\n",
            "\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar: 0.3818553559258767\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_rank1: 0.4717009809021449\n",
            "datasets/birds-16/birds_dataset_triplets/birds_query_rank0_dissimilar_2rank1: 0.37074582527955985\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1> Training our own models </h1>"
      ],
      "metadata": {
        "id": "3o5pmW80vKRQ"
      },
      "id": "3o5pmW80vKRQ"
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from xgboost import XGBClassifier\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "metadata": {
        "id": "3hFwtkvHvN1g"
      },
      "id": "3hFwtkvHvN1g",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(2020)\n",
        "np.random.seed(2020)\n",
        "random.seed(2020)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "if device.type == \"cuda\":\n",
        "    torch.cuda.get_device_name()"
      ],
      "metadata": {
        "id": "ojBh21llyWv5"
      },
      "id": "ojBh21llyWv5",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_dims = 2\n",
        "batch_size = 32\n",
        "epochs = 50"
      ],
      "metadata": {
        "id": "e55s7MKVygaB"
      },
      "id": "e55s7MKVygaB",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class HSJ(Dataset):\n",
        "    def __init__(self, path, train=True, transform=None):\n",
        "        self.is_train = train\n",
        "        self.transform = transform\n",
        "        self.to_pil = transforms.ToPILImage()\n",
        "        self.path=path\n",
        "        \n",
        "        if self.is_train:   \n",
        "            self.image_indices_range = (0,699)\n",
        "            self.length = 700  \n",
        "        else: \n",
        "            self.image_indices_range = (700,999)\n",
        "            self.length = 300  \n",
        "        self.scaler = transforms.Resize((28, 28))\n",
        "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                  std=[0.229, 0.224, 0.225])\n",
        "\n",
        "        #     self.images = df.iloc[:, 1:].values.astype(np.uint8)\n",
        "        #     self.labels = df.iloc[:, 0].values\n",
        "        #     self.index = df.index.values\n",
        "        # else:\n",
        "        #     self.images = df.values.astype(np.uint8)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        # item is just an index --> transform into label\n",
        "        im_no_name =  (6-len(str(item)))*\"0\" + str(item) + \".\" + \"jpg\"\n",
        "        image_name_ref = self.path+\"/ref/\" + im_no_name\n",
        "\n",
        "        anchor_img = self.scaler(Image.open(image_name_ref).convert('L'))\n",
        "        # anchor_img = self.images[item].reshape(28, 28, 1)\n",
        "        \n",
        "        if self.is_train:\n",
        "            image_name_p0 = self.path+\"/p0/\" + im_no_name\n",
        "            positive_img = self.scaler(Image.open(image_name_p0).convert('L'))\n",
        "\n",
        "            image_name_p1 = self.path+\"/p1/\" + im_no_name\n",
        "            negative_img = self.scaler(Image.open(image_name_p1).convert('L'))\n",
        "            \n",
        "            if self.transform:\n",
        "                anchor_img = self.transform(anchor_img)\n",
        "                positive_img = self.transform(positive_img)\n",
        "                negative_img = self.transform(negative_img)\n",
        "            \n",
        "            return anchor_img, positive_img, negative_img   # anchor_label\n",
        "        \n",
        "        else:\n",
        "            if self.transform:\n",
        "                anchor_img = self.transform(anchor_img)\n",
        "            return anchor_img"
      ],
      "metadata": {
        "id": "qaaFI8QC1Diw"
      },
      "id": "qaaFI8QC1Diw",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = HSJ(\"datasets/hsj/hsj_triplets/hsj_query_rank0_rank1\", \n",
        "                 train=True,\n",
        "                 transform=transforms.Compose([\n",
        "                     transforms.ToTensor()\n",
        "                 ]))\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6T3VI_q-wVW",
        "outputId": "c3c34d42-974d-4f14-cd22-ab4b9dae66ce"
      },
      "id": "G6T3VI_q-wVW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_ds = HSJ(\"datasets/hsj/hsj_triplets/hsj_query_rank0_rank1\",\n",
        "                train=False, \n",
        "                transform=transforms.ToTensor())\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=4)"
      ],
      "metadata": {
        "id": "Sf2sADdM_CyX"
      },
      "id": "Sf2sADdM_CyX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TripletLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "        \n",
        "    def calc_euclidean(self, x1, x2):\n",
        "        return (x1 - x2).pow(2).sum(1)\n",
        "    \n",
        "    def forward(self, anchor: torch.Tensor, positive: torch.Tensor, negative: torch.Tensor) -> torch.Tensor:\n",
        "        distance_positive = self.calc_euclidean(anchor, positive)\n",
        "        distance_negative = self.calc_euclidean(anchor, negative)\n",
        "        losses = torch.relu(distance_positive - distance_negative + self.margin)\n",
        "\n",
        "        return losses.mean()"
      ],
      "metadata": {
        "id": "9vLEN6tS_cc_"
      },
      "id": "9vLEN6tS_cc_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dml_42YOFbPD"
      },
      "id": "Dml_42YOFbPD",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Network(nn.Module):\n",
        "    def __init__(self, emb_dim=128):\n",
        "        super(Network, self).__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 32, 5),\n",
        "            nn.PReLU(),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.Dropout(0.3),\n",
        "            nn.Conv2d(32, 64, 5),\n",
        "            nn.PReLU(),\n",
        "            nn.MaxPool2d(2, stride=2),\n",
        "            nn.Dropout(0.3)\n",
        "        )\n",
        "        \n",
        "        self.fc = nn.Sequential(\n",
        "            nn.Linear(64*4*4, 512),\n",
        "            nn.PReLU(),\n",
        "            nn.Linear(512, emb_dim)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(-1, 64*4*4)\n",
        "        x = self.fc(x)\n",
        "        # x = nn.functional.normalize(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "QhTydXLu_mk1"
      },
      "id": "QhTydXLu_mk1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_weights(m):\n",
        "    if isinstance(m, nn.Conv2d):\n",
        "        torch.nn.init.kaiming_normal_(m.weight)"
      ],
      "metadata": {
        "id": "SkmJAITp_0cp"
      },
      "id": "SkmJAITp_0cp",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Network(embedding_dims)\n",
        "model.apply(init_weights)\n",
        "model = torch.jit.script(model).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = torch.jit.script(TripletLoss())"
      ],
      "metadata": {
        "id": "QrLJwKd6_2V9"
      },
      "id": "QrLJwKd6_2V9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.train()\n",
        "for epoch in tqdm(range(epochs), desc=\"Epochs\"):\n",
        "    running_loss = []\n",
        "    for step, (anchor_img, positive_img, negative_img) in enumerate(tqdm(train_loader, desc=\"Training\", leave=False)):\n",
        "        anchor_img = anchor_img.to(device)\n",
        "        positive_img = positive_img.to(device)\n",
        "        negative_img = negative_img.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        anchor_out = model(anchor_img)\n",
        "        positive_out = model(positive_img)\n",
        "        negative_out = model(negative_img)\n",
        "        \n",
        "        loss = criterion(anchor_out, positive_out, negative_out)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss.append(loss.cpu().detach().numpy())\n",
        "    print(\"Epoch: {}/{} - Loss: {:.4f}\".format(epoch+1, epochs, np.mean(running_loss)))"
      ],
      "metadata": {
        "id": "3FSVaiKJ__Tv"
      },
      "id": "3FSVaiKJ__Tv",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.save({\"model_state_dict\": model.state_dict(),\n",
        "            \"optimzier_state_dict\": optimizer.state_dict()\n",
        "           }, \"trained_model.pth\")"
      ],
      "metadata": {
        "id": "xLNZMEYIIIAO"
      },
      "id": "xLNZMEYIIIAO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_results = []\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for img in tqdm(test_loader):\n",
        "        train_results.append(model(img.to(device)).cpu().numpy())\n",
        "        \n",
        "train_results = np.concatenate(train_results)\n",
        "train_results.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121,
          "referenced_widgets": [
            "454d4a72e6d947629edb3e4d4d1d94f7",
            "674d6cbdf514454496b8e40e45e1b511",
            "a02ae67e2c9d4003a2f9c2b0e42585b0",
            "555c13acdcf44b00a9c8c493ef5e6e19",
            "4697c877055847ef96d9623af9283562",
            "4c5a5a7462524faca041881f07315276",
            "bd3c1581e728426fab64db29b85b7d1e",
            "fab99da8597f423cad4263503d5d4d74",
            "93be17e1287b434181e33305f3e3a33d",
            "d8218176d5af4cc093500ab9846984f9",
            "fc122f29b68f4636b4337629915a9081"
          ]
        },
        "id": "92zpfp4yIKsC",
        "outputId": "0b64ff4a-9cd2-49b0-fb84-5a685a1fb700"
      },
      "id": "92zpfp4yIKsC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "454d4a72e6d947629edb3e4d4d1d94f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "    # 1. Load the image with Pillow library\n",
        "item=0\n",
        "path = \"datasets/hsj/hsj_triplets/hsj_query_rank0_rank1\"\n",
        "im_no_name =  (6-len(str(item)))*\"0\" + str(item) + \".\" + \"jpg\"\n",
        "image_name = path+\"/ref/\" + im_no_name\n",
        "\n",
        "img = to_tensor(scaler(Image.open(image_name).convert('L')))\n",
        "print(img.size())\n",
        "x = img.view(-1, 64*4*4)\n",
        "x.size()\n",
        "# t = transforms.ToPILImage()\n",
        "# img_img = t(img)\n",
        "# # t_img = Variable(normalize(to_tensor(scaler(img))).unsqueeze(0)).cuda()\n",
        "# # scaler(img)\n",
        "# img.size() \n",
        "# # feature_tensor_dict[\"ref\"].append(get_vector(path+\"/ref/\" + im_no_name, model, layer, scaler, normalize, feature_tensor_size))\n",
        "# img_img"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ET3gYihB5z3M",
        "outputId": "0541a827-8d0f-458f-8d67-324448074b45"
      },
      "id": "ET3gYihB5z3M",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 224, 224])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([49, 1024])"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New model"
      ],
      "metadata": {
        "id": "q6v9-ptV6p5N"
      },
      "id": "q6v9-ptV6p5N"
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install img2vec-pytorch\n",
        "!unzip -uq \"/content/drive/MyDrive/Colab Notebooks/distortion_triplets.zip\" -d \"/content/datasets/distortions\"\n",
        "!unzip -uq \"/content/drive/MyDrive/Colab Notebooks/hsj_triplets.zip\" -d \"/content/datasets/hsj\"\n",
        "!unzip -uq \"/content/drive/MyDrive/Colab Notebooks/birds_dataset_triplets.zip\" -d \"/content/datasets/birds-16\""
      ],
      "metadata": {
        "id": "Ril7hZc86o5p",
        "outputId": "3120d975-a8e4-4e88-fcea-9a8e903b74f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "Ril7hZc86o5p",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting img2vec-pytorch\n",
            "  Downloading img2vec_pytorch-1.0.1-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from img2vec-pytorch) (1.22.4)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from img2vec-pytorch) (0.14.1+cu116)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from img2vec-pytorch) (1.13.1+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->img2vec-pytorch) (4.5.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.9/dist-packages (from torchvision->img2vec-pytorch) (8.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision->img2vec-pytorch) (2.27.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->img2vec-pytorch) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->img2vec-pytorch) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->img2vec-pytorch) (2.0.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->img2vec-pytorch) (2022.12.7)\n",
            "Installing collected packages: img2vec-pytorch\n",
            "Successfully installed img2vec-pytorch-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from tqdm.notebook import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from xgboost import XGBClassifier\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "metadata": {
        "id": "m2gadCDs9MPa"
      },
      "id": "m2gadCDs9MPa",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "import json\n",
        "from torchvision.transforms import transforms\n",
        "import random\n",
        "\n",
        "class HSJ(Dataset):\n",
        "    def __init__(self, path, train=True, transform=None):\n",
        "        self.is_train = train\n",
        "        self.transform = transform\n",
        "        self.to_pil = transforms.ToPILImage()\n",
        "        self.path=path\n",
        "        \n",
        "        if self.is_train:   \n",
        "            self.image_indices_range = (0,799)\n",
        "            self.length = 700  \n",
        "        else: \n",
        "            self.image_indices_range = (800,899)\n",
        "            self.length = 300  \n",
        "        self.scaler = transforms.Resize((224, 224))\n",
        "        self.normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                                  std=[0.229, 0.224, 0.225])\n",
        "\n",
        "        #     self.images = df.iloc[:, 1:].values.astype(np.uint8)\n",
        "        #     self.labels = df.iloc[:, 0].values\n",
        "        #     self.index = df.index.values\n",
        "        # else:\n",
        "        #     self.images = df.values.astype(np.uint8)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "    \n",
        "    def __getitem__(self, item):\n",
        "        # item is just an index --> transform into label\n",
        "        if self.is_train == False:\n",
        "          item = item + 500\n",
        "        im_no_name =  (6-len(str(item)))*\"0\" + str(item) + \".\" + \"jpg\"\n",
        "        image_name_ref = self.path+\"/ref/\" + im_no_name\n",
        "\n",
        "        anchor_img = Image.open(image_name_ref).convert('RGB')\n",
        "        # anchor_img = self.images[item].reshape(28, 28, 1)\n",
        "        \n",
        "        if True:\n",
        "            image_name_p0 = self.path+\"/p0/\" + im_no_name\n",
        "            positive_img = Image.open(image_name_p0).convert('RGB')\n",
        "\n",
        "            image_name_p1 = self.path+\"/p1/\" + im_no_name\n",
        "            negative_img = Image.open(image_name_p1).convert('RGB')\n",
        "            \n",
        "            if self.transform:\n",
        "                anchor_img = self.transform(anchor_img)\n",
        "                positive_img = self.transform(positive_img)\n",
        "                negative_img = self.transform(negative_img)\n",
        "            \n",
        "            return anchor_img, positive_img, negative_img   # anchor_label"
      ],
      "metadata": {
        "id": "16PZjHajJBRZ"
      },
      "id": "16PZjHajJBRZ",
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_train_dataset(IMAGE_SIZE=96):\n",
        "    train_dataset = HSJ(\"datasets/hsj/hsj_triplets/hsj_query_rank0_rank1\",\n",
        "                        train=True,\n",
        "                        transform=transforms.Compose([transforms.ToTensor(),transforms.Resize((IMAGE_SIZE,IMAGE_SIZE))]))\n",
        "    return train_dataset\n",
        "\n",
        "def get_val_dataset(IMAGE_SIZE=96):\n",
        "    train_dataset = HSJ(\"datasets/hsj/hsj_triplets/hsj_query_rank0_rank1\",\n",
        "                        train=False,\n",
        "                        transform=transforms.Compose([transforms.ToTensor(),transforms.Resize((IMAGE_SIZE,IMAGE_SIZE))]))\n",
        "    return train_dataset"
      ],
      "metadata": {
        "id": "65trlQbEJ6WY"
      },
      "id": "65trlQbEJ6WY",
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TripletLoss(nn.Module):\n",
        "    def __init__(self, margin=1.0):\n",
        "        super(TripletLoss, self).__init__()\n",
        "        self.margin = margin\n",
        "    def calc_euclidean(self, x1, x2):\n",
        "        return (x1 - x2).pow(2).sum(1)\n",
        "    def forward(self, anchor: torch.Tensor, positive: torch.Tensor, negative: torch.Tensor) -> torch.Tensor:\n",
        "        distance_positive = self.calc_euclidean(anchor, positive)\n",
        "        distance_negative = self.calc_euclidean(anchor, negative)\n",
        "        losses = torch.relu(distance_positive - distance_negative + self.margin)\n",
        "        return losses.mean()"
      ],
      "metadata": {
        "id": "EcRYZv1wK4gV"
      },
      "id": "EcRYZv1wK4gV",
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import transforms\n",
        "from torchvision.models import resnet18\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import zipfile\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "XIDGyw2TLMBM"
      },
      "id": "XIDGyw2TLMBM",
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "#””Pick GPU if available, else CPU”””\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "DEVICE = get_default_device()\n",
        "LEARNING_RATE = 0.0005\n",
        "EPOCHS = 5"
      ],
      "metadata": {
        "id": "_STESorILVTe"
      },
      "id": "_STESorILVTe",
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = get_train_dataset(IMAGE_SIZE = IMAGE_SIZE)\n",
        "val_dataset = get_val_dataset(IMAGE_SIZE = IMAGE_SIZE)\n",
        "train_dl = DataLoader(train_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=2,pin_memory=True)\n",
        "val_dl = DataLoader(val_dataset,batch_size=BATCH_SIZE,shuffle=True,num_workers=2,pin_memory=True)"
      ],
      "metadata": {
        "id": "HKQbVCZxLc3r"
      },
      "id": "HKQbVCZxLc3r",
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f = resnet18(pretrained=True).cuda()\n",
        "f._modules\n",
        "f(input)"
      ],
      "metadata": {
        "id": "b8fnYRquFatd",
        "outputId": "0373cb5c-7980-404b-b936-a64e21599110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485,
          "referenced_widgets": [
            "f8b31e6870994f2aae009dcc5e70cbb3",
            "2106e52ab75d457392d2aeda03f99e32",
            "c77579c511a744a9be8fad853d18acc9",
            "b850444fc13645a495ea6a3f620a8a28",
            "ba3996e28cdf48e79a3104dbf4705641",
            "68950badda4f49b4acaef8a605f85dfd",
            "563f6e2e3f214c58abab6a5916e3b29b",
            "e986664dfef84b10bc59b7632ad503a8",
            "f2d655686e6f412e822865d6e1771133",
            "b26a5a582de945669f1a77892463d52a",
            "2d07aebaf873454590cfe7e89fbb745f"
          ]
        }
      },
      "id": "b8fnYRquFatd",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.9/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0.00/44.7M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f8b31e6870994f2aae009dcc5e70cbb3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-46eab0b3ce86>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresnet18\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mcuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    639\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    640\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 641\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    642\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    662\u001b[0m             \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 664\u001b[0;31m                 \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m             \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    747\u001b[0m             \u001b[0mModule\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    748\u001b[0m         \"\"\"\n\u001b[0;32m--> 749\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    750\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mipu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mT\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet_Triplet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.Feature_Extractor = resnet18(pretrained=True)\n",
        "        num_filters = self.Feature_Extractor.fc.in_features\n",
        "        self.Feature_Extractor.fc = nn.Sequential(\n",
        "                  nn.Linear(num_filters,512),\n",
        "                  nn.LeakyReLU(),\n",
        "                  nn.Linear(512,100))\n",
        "        self.Triplet_Loss = nn.Sequential(\n",
        "                  nn.Linear(100,100))\n",
        "    def forward(self,x):\n",
        "        features = self.Feature_Extractor(x)\n",
        "        triplets = self.Triplet_Loss(features)\n",
        "        return triplets"
      ],
      "metadata": {
        "id": "-Ky0D5S7Lu7_"
      },
      "id": "-Ky0D5S7Lu7_",
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet = ResNet_Triplet()\n",
        "ResNet = ResNet.to(DEVICE)\n",
        "Optimizer = torch.optim.Adam(ResNet.parameters(),lr = LEARNING_RATE)\n",
        "criterion = TripletLoss()"
      ],
      "metadata": {
        "id": "VKd3wV-7MF4V"
      },
      "id": "VKd3wV-7MF4V",
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = transforms.Resize((224, 224))\n",
        "to_tensor = transforms.ToTensor()\n",
        "input = to_tensor(scaler(Image.open(\"000467.jpg\").convert('RGB'))).cuda().reshape(1,3,224,224)\n",
        "input.size()\n",
        "layer = ResNet.Feature_Extractor\n",
        "output = layer(input)\n",
        "output.size()"
      ],
      "metadata": {
        "id": "GVfPwhXI9h4e",
        "outputId": "ca86f974-b51c-40f4-ab2c-f535782e3b4e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        }
      },
      "id": "GVfPwhXI9h4e",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-2f1568c6f98e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mto_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mToTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"000467.jpg\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFeature_Extractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   2973\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2974\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2975\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2976\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '000467.jpg'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm(range(EPOCHS), desc=\"Epochs\"):\n",
        "    ResNet.train()\n",
        "    running_loss = []\n",
        "    for step, (anchor_img, positive_img, negative_img) in enumerate(tqdm(train_dl, desc=\"Training\", leave=False)):        \n",
        "        anchor_img = anchor_img.to(DEVICE)\n",
        "        positive_img = positive_img.to(DEVICE)\n",
        "        negative_img = negative_img.to(DEVICE)\n",
        "\n",
        "        Optimizer.zero_grad()\n",
        "\n",
        "        anchor_out = ResNet(anchor_img)\n",
        "        positive_out = ResNet(positive_img)\n",
        "        negative_out = ResNet(negative_img)\n",
        "\n",
        "        loss = criterion(anchor_out, positive_out, negative_out)\n",
        "        loss.backward()\n",
        "        Optimizer.step()\n",
        "        running_loss.append(loss.cpu().detach().numpy())\n",
        "        print(\"Epoch: {}/{} — Loss: {:.4f}\".format(epoch+1, EPOCHS, np.mean(running_loss)))\n",
        "\n",
        "    ResNet.eval()\n",
        "    running_loss_val = []\n",
        "    for step, (anchor_img, positive_img, negative_img) in enumerate(tqdm(val_dl, desc=\"Training\", leave=False)):        \n",
        "        anchor_img = anchor_img.to(DEVICE)\n",
        "        positive_img = positive_img.to(DEVICE)\n",
        "        negative_img = negative_img.to(DEVICE)\n",
        "\n",
        "        anchor_out = ResNet(anchor_img)\n",
        "        positive_out = ResNet(positive_img)\n",
        "        negative_out = ResNet(negative_img)\n",
        "        \n",
        "        loss = criterion(anchor_out, positive_out, negative_out)\n",
        "        running_loss_val.append(loss.cpu().detach().numpy())\n",
        "        print(\"Epoch: {}/{} — Loss: {:.4f}\".format(epoch+1, EPOCHS, np.mean(running_loss_val)))"
      ],
      "metadata": {
        "id": "bvqN6a2jMHWV",
        "outputId": "f210d095-ae39-4f15-e173-862ae543d24f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "5801bc485ebe417c9e46b27287b48502",
            "90f8ba2b3801401999e57d839761d7dd",
            "a28c250b2ced49e28812fea2d487994a",
            "4de266145a52432ca2d9f949332b3f6f",
            "db329ce8b18f4ea98fc64af2133505d6",
            "a307bfbc81304b0e87f56a4f8c648141",
            "be22d1d424724fcd872f1a1c99561d24",
            "d32bdecce1d64bfa9047b559460308b2",
            "72a8918eaaa040a9b2276cf515fce888",
            "acc2e74e03414318905b88693d308574",
            "d94c20da1e89435480b86f7562e570b9",
            "9b6c5336f1334841bdf895f859d5095b",
            "6d9e6b380abb4551bdaa32d6ff469119",
            "260990e219ac469ab6262f4347289ce1",
            "e8798bd1ed9e43ae937d58df2854de16",
            "988a9329975540acba5b86c716af16fd",
            "01a6688aeeae4fd18e9e4f9c758dad4c",
            "d309e072f2ef4b0eb4776439f4f4784e",
            "2362863875f34de2b3dd796f1554b1ad",
            "4ba124f7cbf44805a78b935191e8b0af",
            "dfa17269873446099e6fb9b8a7a56e70",
            "e70a9abdc6bd4b8591d84807d71b48d2",
            "7ef7155f3e2e43dd8cafef3f9f89314b",
            "37c2bf3f4d0844c593270f5addd8c6bb",
            "9d75eb4911e6467facb8135e14db4c9d",
            "fa9b1490c49340ff9cb39612ade4614e",
            "6629367e3bed46aea39d5a34c74ec938",
            "edf2dc3686224cb7b69faf3544597514",
            "d57725ba54e04d89adfb74702a0820d2",
            "c0c0eccc768044ffa83fde642d211530",
            "6bb9135db4f94d44b7c0f7735b09b57f",
            "819bca99e9cf480da4482a082db07cbf",
            "ed4a358fe0ef4da591378d37ee9d41a7",
            "5ad8b67b330345ae8cc73b4fe028a686",
            "0187a3cf33374ac6a38f44f1c18137c6",
            "f2de16efa2304fd28889399b28deab82",
            "c475ad77f595463fa996917d74dcac8e",
            "b940087024e2473d8a95008c45477145",
            "fcd927d2fda94ba5b245acabab89397b",
            "ae13bb30e1384525ba11bc8d0d7c85ed",
            "19f299bfc8e9478ba3dc4ac956d57cc6",
            "6ce7de85ee784dc9b3bb86835bc57e3f",
            "3ac7186360314a79b0cc4165634ef2a0",
            "0bc01146ca334786a9ddd492c0ad0eab",
            "f3dc3fdc35704c54a156633160bc108e",
            "6732eaffc69d45cab24b4176e343fbf3",
            "b78f763148da4110a1cf7a8941d3254a",
            "0244faa4064446deaaac1e20e7ce37c6",
            "9ac024bb5b2e47ce83c84d6107835cb1",
            "1c3cf3dded6a4e0088d7d72df4b270e9",
            "b2555885009b4b8293f573376b30217c",
            "bf2e660da1b54ba090f30d660c797ec4",
            "67877ce9a7ac47f3964ba7b9519c0da9",
            "2880fe30c97a46149cef71e289a20eb3",
            "5abdc1b4cf58459586ff2dc8b9ae5456",
            "5aafcb9ed5dd4b2f8465d483230df25f",
            "1b4143d7c9294d59bf0d952a9319beeb",
            "ac16adf042934fa4974256cf9ee525c5",
            "42446d4d6f8146dba6a9b0d2c8df39de",
            "f6cafc0083b54dcc8c7addbfc1504a75",
            "d96a951da80a40df9c57a9f4de4ded18",
            "bca760804754475abc0472a119f83244",
            "60b2ce3ae0c04c1aab6de621b21d9ab7",
            "f148183d2ef645e98e3e6d59f42ec14b",
            "617b84e30ee74458a29ebc6fe8f0ade1",
            "1db0108ee9b647598b7a0efb3b84599c",
            "23d5ecdf1694415aab48318ff60df7ac",
            "b31fbcae66e94cb1820e97fb1c25c297",
            "242bc551b0e6496abc6883c61ec932b3",
            "6803a8e2ae67451da232d1dd778f5dbb",
            "06553c1e88c24322867660665cabc73a",
            "6ab6ad8993a1435aa1b2b1211c1b454b",
            "1c190cc8f85d41b595005d094d7f05a5",
            "667ca9632f4742b595a4536f01fce6a3",
            "0c015da411e146e4ade2be8ab4b5b819",
            "3e27e0247b2d4d44aff87276c911039c",
            "21605b7f7a544a18afc9e36b2391d01d",
            "78edcbd16c934095bbac2adbe141b4e3",
            "58637e951da446188e0ff40822bb822b",
            "144ba332b80a44ffa983d33cc2e2bcfd",
            "0464d4c141e848278baaf3d3caea491b",
            "873616ea18cb43bd96397f6e5309e459",
            "f3914d0037114ba2bc597a8a1958d9c7",
            "7731c1e9adb34320b2d2beb6985e83bc",
            "353ed4b12d1a4f5bb16e589e124b39d5",
            "db695a42ca6548f1848adec453e33863",
            "81c38ccffc93469cb97d3cac19cb9725",
            "3f1209a945364dc8a4a9eaba804fc24a",
            "ba188b2a994a4f69aa8fcf277bd00643",
            "4de69b31438349a98c20a4c740d07935",
            "ea40150135d94ca689f519f10657df7b",
            "886cf77621c74d9c8d82846a514ff4f0",
            "deb12f7cedb5459f9da7d3edb024cd41",
            "35c52ec26a934a65a8b4e1da0b0b4ffb",
            "daad900575794a77b977a1a376074dfd",
            "6bec39527cb84f70b523e45ed71275f0",
            "34dc3d24c1e84a8b8f27c50677baefc1",
            "57c5b76fdcd64f19a434c4dfd8590326",
            "2f493fe657594a51ac1ee295b5df0e1e",
            "f3594297a90a41a88c5a1f7a8af67724",
            "a6ad1cf2b50e41a6acb6db98d375a78f",
            "6dfa624f683b45079fe0e317e8ac4b70",
            "812ed4bccc9b4355ac2af8e486a67a3f",
            "14686dd9459849d398a5bb90d13d29ca",
            "c0020bbb73be44e09e0d10e50e279612",
            "6de5aae052ff48258767fbbe0b7e0dbd",
            "1e14c257a58640cc844f1e6611a3c140",
            "e02cf81073af47e686a79cb114703d8d",
            "14384e109bde496c823015fda02411ab",
            "e8b3cfa026684b7e99b7c89c0c7c9e0a",
            "d0e1c044ee7e48e7bf7ef9da6da1c8cd",
            "865d6a14079345868b6df0a924feade2",
            "58401f0d928d43ad856e8e5395009c46",
            "963b7501e70e47379575e6fee6d03b34",
            "31e2f60669404148a09e7fab3c1f5775",
            "1c7ebc9e6d514e56afbd22a899deb197",
            "88a3736c47474abcb5e9e7c9813e7876",
            "cf8520cc31fb47cba7bf9a5a41845e4a",
            "2dbfa31841034ddf9a6081aac1a9102a",
            "adcadc0c79e04bba9c60518c294795a4",
            "099095df2dd94d59a3807629e4914db7"
          ]
        }
      },
      "id": "bvqN6a2jMHWV",
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5801bc485ebe417c9e46b27287b48502"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9b6c5336f1334841bdf895f859d5095b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/5 — Loss: 0.8667\n",
            "Epoch: 1/5 — Loss: 0.9646\n",
            "Epoch: 1/5 — Loss: 0.9410\n",
            "Epoch: 1/5 — Loss: 1.0606\n",
            "Epoch: 1/5 — Loss: 1.0912\n",
            "Epoch: 1/5 — Loss: 1.1213\n",
            "Epoch: 1/5 — Loss: 1.0902\n",
            "Epoch: 1/5 — Loss: 1.1308\n",
            "Epoch: 1/5 — Loss: 1.1830\n",
            "Epoch: 1/5 — Loss: 1.1902\n",
            "Epoch: 1/5 — Loss: 1.2278\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ef7155f3e2e43dd8cafef3f9f89314b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/5 — Loss: 0.9545\n",
            "Epoch: 1/5 — Loss: 0.8689\n",
            "Epoch: 1/5 — Loss: 0.9044\n",
            "Epoch: 1/5 — Loss: 0.9441\n",
            "Epoch: 1/5 — Loss: 0.9974\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5ad8b67b330345ae8cc73b4fe028a686"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2/5 — Loss: 0.4643\n",
            "Epoch: 2/5 — Loss: 0.4736\n",
            "Epoch: 2/5 — Loss: 0.4368\n",
            "Epoch: 2/5 — Loss: 0.4798\n",
            "Epoch: 2/5 — Loss: 0.5108\n",
            "Epoch: 2/5 — Loss: 0.5363\n",
            "Epoch: 2/5 — Loss: 0.5596\n",
            "Epoch: 2/5 — Loss: 0.5748\n",
            "Epoch: 2/5 — Loss: 0.5836\n",
            "Epoch: 2/5 — Loss: 0.5803\n",
            "Epoch: 2/5 — Loss: 0.5799\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3dc3fdc35704c54a156633160bc108e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 2/5 — Loss: 0.6788\n",
            "Epoch: 2/5 — Loss: 0.6337\n",
            "Epoch: 2/5 — Loss: 0.6054\n",
            "Epoch: 2/5 — Loss: 0.5513\n",
            "Epoch: 2/5 — Loss: 0.5605\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5aafcb9ed5dd4b2f8465d483230df25f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3/5 — Loss: 0.3085\n",
            "Epoch: 3/5 — Loss: 0.3502\n",
            "Epoch: 3/5 — Loss: 0.3635\n",
            "Epoch: 3/5 — Loss: 0.3522\n",
            "Epoch: 3/5 — Loss: 0.3429\n",
            "Epoch: 3/5 — Loss: 0.3352\n",
            "Epoch: 3/5 — Loss: 0.3175\n",
            "Epoch: 3/5 — Loss: 0.3086\n",
            "Epoch: 3/5 — Loss: 0.2949\n",
            "Epoch: 3/5 — Loss: 0.2846\n",
            "Epoch: 3/5 — Loss: 0.2829\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "23d5ecdf1694415aab48318ff60df7ac"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 3/5 — Loss: 0.4914\n",
            "Epoch: 3/5 — Loss: 0.4989\n",
            "Epoch: 3/5 — Loss: 0.4912\n",
            "Epoch: 3/5 — Loss: 0.4869\n",
            "Epoch: 3/5 — Loss: 0.4554\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "78edcbd16c934095bbac2adbe141b4e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4/5 — Loss: 0.0898\n",
            "Epoch: 4/5 — Loss: 0.0648\n",
            "Epoch: 4/5 — Loss: 0.1006\n",
            "Epoch: 4/5 — Loss: 0.1337\n",
            "Epoch: 4/5 — Loss: 0.1532\n",
            "Epoch: 4/5 — Loss: 0.1511\n",
            "Epoch: 4/5 — Loss: 0.1750\n",
            "Epoch: 4/5 — Loss: 0.1893\n",
            "Epoch: 4/5 — Loss: 0.1963\n",
            "Epoch: 4/5 — Loss: 0.2128\n",
            "Epoch: 4/5 — Loss: 0.2271\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ba188b2a994a4f69aa8fcf277bd00643"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 4/5 — Loss: 0.3137\n",
            "Epoch: 4/5 — Loss: 0.3657\n",
            "Epoch: 4/5 — Loss: 0.4144\n",
            "Epoch: 4/5 — Loss: 0.5010\n",
            "Epoch: 4/5 — Loss: 0.4630\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f3594297a90a41a88c5a1f7a8af67724"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5/5 — Loss: 0.0749\n",
            "Epoch: 5/5 — Loss: 0.1271\n",
            "Epoch: 5/5 — Loss: 0.1170\n",
            "Epoch: 5/5 — Loss: 0.1527\n",
            "Epoch: 5/5 — Loss: 0.1435\n",
            "Epoch: 5/5 — Loss: 0.1521\n",
            "Epoch: 5/5 — Loss: 0.1502\n",
            "Epoch: 5/5 — Loss: 0.1800\n",
            "Epoch: 5/5 — Loss: 0.2148\n",
            "Epoch: 5/5 — Loss: 0.2148\n",
            "Epoch: 5/5 — Loss: 0.2177\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d0e1c044ee7e48e7bf7ef9da6da1c8cd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 5/5 — Loss: 0.5634\n",
            "Epoch: 5/5 — Loss: 0.5685\n",
            "Epoch: 5/5 — Loss: 0.6251\n",
            "Epoch: 5/5 — Loss: 0.7307\n",
            "Epoch: 5/5 — Loss: 0.7182\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm(range(EPOCHS), desc=\"Epochs\"):\n",
        "    running_loss = []\n",
        "    for step, (anchor_img, positive_img, negative_img) in enumerate(tqdm(train_dl, desc=\"Training\", leave=False)):        \n",
        "        anchor_img = anchor_img.to(DEVICE)\n",
        "        positive_img = positive_img.to(DEVICE)\n",
        "        negative_img = negative_img.to(DEVICE)\n",
        "\n",
        "        Optimizer.zero_grad()\n",
        "\n",
        "        anchor_out = ResNet(anchor_img)\n",
        "        positive_out = ResNet(positive_img)\n",
        "        negative_out = ResNet(negative_img)\n",
        "        \n",
        "        loss = criterion(anchor_out, positive_out, negative_out)\n",
        "        loss.backward()\n",
        "        Optimizer.step()\n",
        "        running_loss.append(loss.cpu().detach().numpy())\n",
        "        print(\"Epoch: {}/{} — Loss: {:.4f}\".format(epoch+1, EPOCHS, np.mean(running_loss)))"
      ],
      "metadata": {
        "id": "PaFXotOheE_7",
        "outputId": "fe14a5cb-8208-43d1-f49f-98c47ac016c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 445,
          "referenced_widgets": [
            "7818ba934b494c7280f6b96a78e97eff",
            "d4ba0b80c7dd4dadb982d0ce630f770b",
            "427b0de0b9f141e1aeac5aa163bca809",
            "5058e6fef0154415bc63fa3d4237199a",
            "aeb28be41bb7487aa24590fc9fc1dbaa",
            "8cee92312966446184519c48a48ceeff",
            "cc004a10c1f0438997c8d521a7f3f696",
            "848711a27db1461bac96b9b8eab3a3cb",
            "518ba1c2a59a47ba816fec3da796e80e",
            "2cd4e62e4f82469eb4bfd68660d98464",
            "469893fecb92412b86ac3cec36006fcc",
            "8f3201dae8c94a34b69dde6b4cffa281",
            "3517a03907ff436e9e4956bbaafecde4",
            "c0aeb427c20e49e39c8cbfafd65761fe",
            "81f8e8d092094c319dc1ecfb749686e1",
            "add84e71c1d849018f126a6c987694a2",
            "5ba1ae8fc37148dba669fb77bc1b44f7",
            "39a8c429b57548edb5f2353f7faf87cb",
            "331fbea9d93d41e3aaac77f997ab95da",
            "9e9e8086d978417b808671c67deab6fb",
            "b80fadc156cb4f56a61bda34ec9c2527",
            "8e14f53a489742d18fd1a8b307990f62"
          ]
        }
      },
      "id": "PaFXotOheE_7",
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7818ba934b494c7280f6b96a78e97eff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f3201dae8c94a34b69dde6b4cffa281"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-4a142788378b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Epochs\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0manchor_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpositive_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnegative_img\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0manchor_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0manchor_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mpositive_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpositive_img\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1315\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1316\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1317\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1272\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1273\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1118\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1119\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1120\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1121\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    178\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.9/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    314\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in tqdm(range(EPOCHS), desc=\"Epochs\"):\n",
        "    running_loss = []\n",
        "    for step, (anchor_img, positive_img, negative_img) in enumerate(tqdm(train_dl, desc=\"Training\", leave=False)):        \n",
        "        anchor_img = anchor_img.to(DEVICE)\n",
        "        positive_img = positive_img.to(DEVICE)\n",
        "        negative_img = negative_img.to(DEVICE)\n",
        "\n",
        "        Optimizer.zero_grad()\n",
        "\n",
        "        anchor_out = ResNet(anchor_img)\n",
        "        positive_out = ResNet(positive_img)\n",
        "        negative_out = ResNet(negative_img)\n",
        "        \n",
        "        loss = criterion(anchor_out, positive_out, negative_out)\n",
        "        loss.backward()\n",
        "        Optimizer.step()\n",
        "        running_loss.append(loss.cpu().detach().numpy())\n",
        "        print(\"Epoch: {}/{} — Loss: {:.4f}\".format(epoch+1, EPOCHS, np.mean(running_loss)))"
      ],
      "metadata": {
        "id": "j51yFor7d3q8",
        "outputId": "37add420-1a04-43e7-9cf3-0c46aa3ba1ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133,
          "referenced_widgets": [
            "09bc1c42b81246e1a7782dab46fd1318",
            "5ebdc4d4ba05461391dc88fc9a42ac79",
            "ac1398c18781423084bbfa0d07a84d99",
            "ac0dcf46a9a4485fadc8710b354c2940",
            "f20ef71f8501423f9111a762e38e0e5e",
            "9c9cad24e27b4cd5a2e02346acd20f2d",
            "8354768b9b70482d8e8919293b2f6860",
            "c2aaa52dfdff4fe7b5e7a8d96d933558",
            "ec1cf61747694d1c930a61ed65a4863a",
            "c5be0c86a0264ea9bf3dc8a31363f995",
            "eeb4df42f6e94cc18e048be86a93819b",
            "17aadcf8afed48458a939d04d6b62e7d",
            "49ffc3f8aa244766b437c723e7a3931d",
            "81e450099ef54436ba492213c39765ba",
            "555e6c4b6a5d43859c8dfc7cc217ec32",
            "0b1604aab61445ed89bac9b035d37728",
            "472d559e62014da0b6c8a6171b94d761",
            "c9ed48c18c324380b67e40146e254a32",
            "d6f252f10c4e40da9426e2f0f368998d",
            "8fe9f7fdc37946f280faa684c510d188",
            "04dd15f3dc154901b96401e9fc4b728b",
            "a031f0d26be7498e876b8fd30b668fd0"
          ]
        }
      },
      "id": "j51yFor7d3q8",
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epochs:   0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09bc1c42b81246e1a7782dab46fd1318"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/11 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "17aadcf8afed48458a939d04d6b62e7d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "KeyboardInterrupt\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# returns (positive distance, negative distance)\n",
        "ResNet.eval()\n",
        "# testing idea --> SIMPLY TRAIN IT AND THEN TO TEST U TEST LIKE U DID BEFORE USING LAYERS\n",
        "test_examples = HSJ(\"datasets/hsj/hsj_triplets/hsj_query_rank0_rank1\",\n",
        "                        train=True,\n",
        "                        transform=transforms.Compose([transforms.ToTensor(),transforms.Resize((96,96))]))\n",
        "test_examples"
      ],
      "metadata": {
        "id": "8F7VF7A6NXWG",
        "outputId": "31b8c1d3-a7e8-4309-fd14-b71d27d19e82",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "8F7VF7A6NXWG",
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.HSJ at 0x7f5dac2acf40>"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "\n",
        "############################ REQUIRES MODIFICATION FOR EACH MODEL \n",
        "\n",
        "# scaler = transforms.Resize((224, 224))\n",
        "# normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "#                                  std=[0.229, 0.224, 0.225])\n",
        "to_tensor = transforms.ToTensor()   # used to convert the PIL image to a PyTorch tensor (multidimensional array)\n",
        "############################\n",
        "\n",
        "\n",
        "############################## HOW TO GET MODEL:\n",
        "# # Load the pretrained model\n",
        "# model = models.resnet18(pretrained=True)\n",
        "# model.cuda()\n",
        "# # Use the model object to select the desired layer\n",
        "# layer = model._modules.get('avgpool')\n",
        "# # Set model to evaluation mode\n",
        "# model.eval()\n",
        "\n",
        "##################################\n",
        "\n",
        "def get_vector1(image_name, model):\n",
        "  with torch.no_grad():\n",
        "      scaler = transforms.Resize((224,224))\n",
        "      \n",
        "  #     # Load the pretrained model\n",
        "  #     model = models.resnet18(pretrained=True)\n",
        "  #     # Use the model object to select the desired layer\n",
        "  #     layer = model._modules.get('avgpool')\n",
        "      \n",
        "      # 1. Load the image with Pillow library\n",
        "      img = Image.open(image_name).convert('RGB')\n",
        "      # 2. Create a PyTorch Variable with the transformed image\n",
        "      t_img = to_tensor(scaler(img)).reshape(1,3,224,224).cuda()\n",
        "      output = model(t_img)\n",
        "\n",
        "  return torch.flatten(output)\n",
        "\n",
        "############################ COSINE SIMILARITY\n",
        "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "\n",
        "\n",
        "########################### GET FEATURE VECTORS\n",
        "def get_image_embeddings(path, image_type, model, isHSJOrBirds):  # returns a list of tensors\n",
        "    # path of form: traditional/ref/\n",
        "    feature_tensor_dict = dict()\n",
        "    feature_tensor_dict[\"ref\"] = []\n",
        "    feature_tensor_dict[\"p0\"] = []\n",
        "    feature_tensor_dict[\"p1\"] = []\n",
        "    feature_tensor_dict[\"decision\"] = []\n",
        "    \n",
        "    for image_no in range(700,1000):\n",
        "        im_no_name =  (6-len(str(image_no)))*\"0\" + str(image_no) + \".\" + image_type\n",
        "        \n",
        "        feature_tensor_dict[\"ref\"].append(get_vector1(path+\"/ref/\" + im_no_name, model))\n",
        "        feature_tensor_dict[\"p0\"].append(get_vector1(path+\"/p0/\" + im_no_name, model))\n",
        "        feature_tensor_dict[\"p1\"].append(get_vector1(path+\"/p1/\" + im_no_name, model))\n",
        "\n",
        "        # now load decision\n",
        "        if isHSJOrBirds:\n",
        "          feature_tensor_dict[\"decision\"].append(0)\n",
        "        else: \n",
        "          decision_no_name =  (6-len(str(image_no)))*\"0\" + str(image_no) + \".npy\"\n",
        "          decision = np.load(path+\"/judge/\"+decision_no_name)\n",
        "          if decision[0] <= 0.5: \n",
        "                feature_tensor_dict[\"decision\"].append(0)\n",
        "          else: \n",
        "                feature_tensor_dict[\"decision\"].append(1)\n",
        "        \n",
        "    return feature_tensor_dict\n",
        "\n",
        "\n",
        "########################## GET MODEL PREDICTIONS\n",
        "def get_predictions(embeddings):\n",
        "  cosine_similarity_dict = dict()\n",
        "  cosine_similarity_dict[\"ref_and_p0\"] = []\n",
        "  cosine_similarity_dict[\"ref_and_p1\"] = []\n",
        "  cosine_similarity_predictions = []\n",
        "\n",
        "  cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "  # cos_sim = cos(query_vector.unsqueeze(0), ref2_vector.unsqueeze(0))\n",
        "\n",
        "  for image_no in range(300):\n",
        "      cosine_similarity_dict[\"ref_and_p0\"].append(cos(embeddings[\"ref\"][image_no].unsqueeze(0), embeddings[\"p0\"][image_no].unsqueeze(0)))\n",
        "      cosine_similarity_dict[\"ref_and_p1\"].append(cos(embeddings[\"ref\"][image_no].unsqueeze(0), embeddings[\"p1\"][image_no].unsqueeze(0)))\n",
        "      \n",
        "      if cosine_similarity_dict[\"ref_and_p0\"][image_no] >= cosine_similarity_dict[\"ref_and_p1\"][image_no]:\n",
        "          cosine_similarity_predictions.append(0)\n",
        "      else:\n",
        "          cosine_similarity_predictions.append(1)   \n",
        "  return cosine_similarity_predictions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "  ########################## GET MODEL PREDICTIONS\n",
        "def get_predictions_distance(embeddings):\n",
        "  cosine_similarity_dict = dict()\n",
        "  cosine_similarity_dict[\"ref_and_p0\"] = []\n",
        "  cosine_similarity_dict[\"ref_and_p1\"] = []\n",
        "  cosine_similarity_predictions = []\n",
        "  \n",
        "  # dist = (tensor1 - tensor2).pow(2).sum(3).sqrt()\n",
        "  for image_no in range(300):\n",
        "      cosine_similarity_dict[\"ref_and_p0\"].append(torch.cdist(embeddings[\"ref\"][image_no].unsqueeze(0),embeddings[\"p0\"][image_no].unsqueeze(0))**2)\n",
        "      cosine_similarity_dict[\"ref_and_p1\"].append(torch.cdist(embeddings[\"ref\"][image_no].unsqueeze(0),embeddings[\"p1\"][image_no].unsqueeze(0))**2)\n",
        "      \n",
        "      if cosine_similarity_dict[\"ref_and_p0\"][image_no] >= cosine_similarity_dict[\"ref_and_p1\"][image_no]:\n",
        "          cosine_similarity_predictions.append(0)\n",
        "      else:\n",
        "          cosine_similarity_predictions.append(1)   \n",
        "  return cosine_similarity_predictions\n",
        "\n",
        "########################## GET MODEL ACCURACY\n",
        "def get_accuracy(predictions,embeddings):\n",
        "  decisions = embeddings[\"decision\"]\n",
        "\n",
        "  number_wrong_predictions = 0\n",
        "\n",
        "  for image_no in range(300):\n",
        "      if predictions[image_no] != decisions[image_no]:\n",
        "          number_wrong_predictions += 1\n",
        "      \n",
        "  accuracy = (300 - number_wrong_predictions)/(300)\n",
        "  return accuracy\n",
        "\n",
        "def get_average_reference_similarty_for_dataset(predictions,embeddings):\n",
        "  similarities_p0_p1 = []\n",
        "  similarities_p0_ref = []\n",
        "  similarities_p1_ref = []\n",
        "  \n",
        "  cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
        "\n",
        "  for image_no in range(300):\n",
        "      similarities_p0_p1.append(float(cos(embeddings[\"p0\"][image_no].unsqueeze(0), embeddings[\"p1\"][image_no].unsqueeze(0))))\n",
        "      similarities_p0_ref.append(float(cos(embeddings[\"ref\"][image_no].unsqueeze(0), embeddings[\"p0\"][image_no].unsqueeze(0))))\n",
        "      similarities_p1_ref.append(float(cos(embeddings[\"ref\"][image_no].unsqueeze(0), embeddings[\"p1\"][image_no].unsqueeze(0))))\n",
        "\n",
        "  similarity = np.average(similarities_p0_p1)/(float(np.average(similarities_p0_ref)+np.average(similarities_p1_ref)))\n",
        "\n",
        "  return similarity\n",
        "  \n",
        "\n",
        "def apply_framework(path, image_type, model, isHSJOrBirds):\n",
        "  embeddings = get_image_embeddings(path, \n",
        "                                    image_type,\n",
        "                                    model,isHSJOrBirds)\n",
        "  predictions= get_predictions(embeddings)\n",
        "  accuracy = get_accuracy(predictions, embeddings)\n",
        "  print(path + \": \" + str(accuracy))\n",
        "  return accuracy\n",
        "\n",
        "# def apply_framework_model(modelf, layer):\n",
        "#   scaler = transforms.Resize((224, 224))\n",
        "#   normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "#                                   std=[0.229, 0.224, 0.225])\n",
        "\n",
        "#   ################ HSJ Rank 0 + Rank 1\n",
        "#   apply_framework(\"datasets/hsj/hsj_triplets/hsj_query_rank0_rank1\",\n",
        "#                   \"jpg\",\n",
        "#                   modelf, layer, scaler, normalize, True, feature_tensor_size)"
      ],
      "metadata": {
        "id": "gf0ATYd9QvKy"
      },
      "id": "gf0ATYd9QvKy",
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.rand(100).unsqueeze(0)\n",
        "t2 = torch.rand(100).unsqueeze(0)\n",
        "torch.cdist(t,t2)**2\n",
        "for i in range(700, 1000):\n",
        "  print(i)"
      ],
      "metadata": {
        "id": "fLM3dxlWTMWu"
      },
      "id": "fLM3dxlWTMWu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "apply_framework(\"datasets/hsj/hsj_triplets/hsj_query_rank0_rank1\", \"jpg\", ResNet, True)"
      ],
      "metadata": {
        "id": "tdLnnENfQ9uz",
        "outputId": "20d91825-de2e-4c86-926b-43c65cac238f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "tdLnnENfQ9uz",
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 100])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-115-80baa4adf413>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mapply_framework\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datasets/hsj/hsj_triplets/hsj_query_rank0_rank1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-114-f246d0bef581>\u001b[0m in \u001b[0;36mapply_framework\u001b[0;34m(path, image_type, model, isHSJOrBirds)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply_framework\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misHSJOrBirds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m   embeddings = get_image_embeddings(path, \n\u001b[0m\u001b[1;32m    154\u001b[0m                                     \u001b[0mimage_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                                     model,isHSJOrBirds)\n",
            "\u001b[0;32m<ipython-input-114-f246d0bef581>\u001b[0m in \u001b[0;36mget_image_embeddings\u001b[0;34m(path, image_type, model, isHSJOrBirds)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mim_no_name\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m\"0\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_no\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0mfeature_tensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ref\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_vector1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/ref/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim_no_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0mfeature_tensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"p0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_vector1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/p0/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim_no_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mfeature_tensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"p1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_vector1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/p1/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim_no_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-114-f246d0bef581>\u001b[0m in \u001b[0;36mget_vector1\u001b[0;34m(image_name, model)\u001b[0m\n\u001b[1;32m     41\u001b[0m       \u001b[0;31m# 2. Create a PyTorch Variable with the transformed image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m       \u001b[0mt_img\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-88-b83080b08197>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m                   nn.Linear(100,100))\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFeature_Extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtriplets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTriplet_Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtriplets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m                 \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-98-556058de429b>\u001b[0m in \u001b[0;36mcopy_data\u001b[0;34m(m, i, o)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcopy_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mmy_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;31m# 5. Attach that function to our selected layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (100) at non-singleton dimension 3"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "apply_framework(\"datasets/hsj/hsj_triplets/hsj_query_rank0_rank1\", \"jpg\",ResNet,True)"
      ],
      "metadata": {
        "id": "DJdvWsN8UV5M",
        "outputId": "e2db6462-c23b-4953-9c8c-b9ee2f9a933d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "id": "DJdvWsN8UV5M",
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "datasets/hsj/hsj_triplets/hsj_query_rank0_rank1: 0.724\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.724"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"#-------------------------------Resnet-18-------------------------------------#\")\n",
        "ResNet.cuda()\n",
        "layer = ResNet._modules.get(\"Feature_Extractor\")\n",
        "ResNet.eval()\n",
        "t = torch.rand(1,3,224,224)\n",
        "ResNet()\n",
        "apply_framework_model(ResNet,layer,[1, 512, 1, 1])"
      ],
      "metadata": {
        "id": "u9ZsX_rfRFQ8",
        "outputId": "77c0acd4-70ae-437a-fe4c-ca963cdbd168",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "id": "u9ZsX_rfRFQ8",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "#-------------------------------Resnet-18-------------------------------------#\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-2a36018ec5e8>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"#-------------------------------Resnet-18-------------------------------------#\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mResNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Feature_Extractor\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ResNet' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NKs_DfmpYJtH"
      },
      "id": "NKs_DfmpYJtH",
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ResNet.eval()\n",
        "layer = ResNet.Feature_Extractor\n",
        "apply_framework(\"datasets/hsj/hsj_triplets/hsj_query_rank0_rank1\", \"jpg\", ResNet, layer, True, [1,100])"
      ],
      "metadata": {
        "id": "f5JIiRaqjCgG",
        "outputId": "c3e9e1dc-8ff1-4efc-82a6-332d98c7d841",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "id": "f5JIiRaqjCgG",
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 100])\n",
            "torch.Size([1, 100])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-102-4480d2a7c1fb>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFeature_Extractor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mapply_framework\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"datasets/hsj/hsj_triplets/hsj_query_rank0_rank1\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"jpg\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-101-99e3e45cbf7b>\u001b[0m in \u001b[0;36mapply_framework\u001b[0;34m(path, image_type, model, layer, isHSJOrBirds, feature_tensor_size)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mapply_framework\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimage_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0misHSJOrBirds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_tensor_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m   embeddings = get_image_embeddings(path, \n\u001b[0m\u001b[1;32m    136\u001b[0m                                     \u001b[0mimage_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                                     model, layer, isHSJOrBirds, feature_tensor_size)\n",
            "\u001b[0;32m<ipython-input-101-99e3e45cbf7b>\u001b[0m in \u001b[0;36mget_image_embeddings\u001b[0;34m(path, image_type, model, layer, isHSJOrBirds, feature_tensor_size)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mim_no_name\u001b[0m \u001b[0;34m=\u001b[0m  \u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m\"0\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_no\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mimage_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m         \u001b[0mfeature_tensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ref\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/ref/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim_no_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_tensor_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mfeature_tensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"p0\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/p0/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim_no_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_tensor_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0mfeature_tensor_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"p1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"/p1/\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mim_no_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_tensor_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-101-99e3e45cbf7b>\u001b[0m in \u001b[0;36mget_vector\u001b[0;34m(image_name, model, layer, feature_tensor_size)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# 6. Run the model on our transformed image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;31m# 7. Detach our copy function from the layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0mh\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-88-b83080b08197>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     11\u001b[0m                   nn.Linear(100,100))\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFeature_Extractor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mtriplets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTriplet_Loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtriplets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.9/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1213\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_global_forward_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1215\u001b[0;31m                 \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1216\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mhook_result\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-98-556058de429b>\u001b[0m in \u001b[0;36mcopy_data\u001b[0;34m(m, i, o)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcopy_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mmy_embedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;31m# 5. Attach that function to our selected layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_forward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcopy_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (4) must match the size of tensor b (100) at non-singleton dimension 3"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f78RRBARj5H3"
      },
      "id": "f78RRBARj5H3",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bca6d128c81c4b1596e23411c8939c43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3e1a8617cb748a39f282c11b9491e0a",
              "IPY_MODEL_d3e31a9020364e64be5c1ee8950e48b3",
              "IPY_MODEL_7548b65877f94225ae7889578eab5db2"
            ],
            "layout": "IPY_MODEL_75708c28b4694cee90680050814f3aa4"
          }
        },
        "f3e1a8617cb748a39f282c11b9491e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_893c1dca55e44bcaa5e35d8c22fa8636",
            "placeholder": "​",
            "style": "IPY_MODEL_5372c90c9580459ab96dc596ac1361d5",
            "value": "100%"
          }
        },
        "d3e31a9020364e64be5c1ee8950e48b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0f7d3090a62545049b4ebc69e7fd5f21",
            "max": 87319819,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_fdd5022ec0ab422db94c6392eb0202f1",
            "value": 87319819
          }
        },
        "7548b65877f94225ae7889578eab5db2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_009229f9541b4e25b6aa5b8a9724865c",
            "placeholder": "​",
            "style": "IPY_MODEL_71eaa211a3a9407083de38c547cc3305",
            "value": " 83.3M/83.3M [00:01&lt;00:00, 63.4MB/s]"
          }
        },
        "75708c28b4694cee90680050814f3aa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "893c1dca55e44bcaa5e35d8c22fa8636": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5372c90c9580459ab96dc596ac1361d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0f7d3090a62545049b4ebc69e7fd5f21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fdd5022ec0ab422db94c6392eb0202f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "009229f9541b4e25b6aa5b8a9724865c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71eaa211a3a9407083de38c547cc3305": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6678c3284bba4788bbe9d4e45414ffc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0bb4ca5b79eb47cba9040c4866621628",
              "IPY_MODEL_0dca7d41c2c6492d94e48aa4ddac2b39",
              "IPY_MODEL_cffc167a23f346938726878ea7968396"
            ],
            "layout": "IPY_MODEL_ce4cd73fae2c4ca6ac365353239ad9fe"
          }
        },
        "0bb4ca5b79eb47cba9040c4866621628": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ff89d302c7b447b7865767d11316ab95",
            "placeholder": "​",
            "style": "IPY_MODEL_dec2a15e52af45b8aef578feec6d82c6",
            "value": "100%"
          }
        },
        "0dca7d41c2c6492d94e48aa4ddac2b39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0c88bfb26f94466f8ce31588b5e6faff",
            "max": 178793939,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e2e0448838f24045bb09baa6a82f7d60",
            "value": 178793939
          }
        },
        "cffc167a23f346938726878ea7968396": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c786b0d9c3a4f908b4bef29511cdf54",
            "placeholder": "​",
            "style": "IPY_MODEL_229cdc96df7c40029253c5e17f6edf74",
            "value": " 171M/171M [00:03&lt;00:00, 59.1MB/s]"
          }
        },
        "ce4cd73fae2c4ca6ac365353239ad9fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff89d302c7b447b7865767d11316ab95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dec2a15e52af45b8aef578feec6d82c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c88bfb26f94466f8ce31588b5e6faff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e2e0448838f24045bb09baa6a82f7d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c786b0d9c3a4f908b4bef29511cdf54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "229cdc96df7c40029253c5e17f6edf74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "29ec99b1c78842238a5f1e9a1f7bd471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1a3ed3a66f5412b908e14b58b920c67",
              "IPY_MODEL_053f280125b1431aba72492658913b36",
              "IPY_MODEL_4561cbe2c1214254a8d670b9f31caed1"
            ],
            "layout": "IPY_MODEL_1dac5859a10945a1adadb28dfc93ea0e"
          }
        },
        "d1a3ed3a66f5412b908e14b58b920c67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_18f2ceb4c94c4ea091afc17ab882936f",
            "placeholder": "​",
            "style": "IPY_MODEL_48d0319c81204308a655424e9d974f41",
            "value": "100%"
          }
        },
        "053f280125b1431aba72492658913b36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_917e6cbf826c4da399841399330f9dd9",
            "max": 241627721,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92a20835c1ab41af8eee379d345dc6e0",
            "value": 241627721
          }
        },
        "4561cbe2c1214254a8d670b9f31caed1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d97d9fc3cfe04e60aebd1723a4cdf263",
            "placeholder": "​",
            "style": "IPY_MODEL_516db9148baa45f485cbcca81248a1f1",
            "value": " 230M/230M [00:02&lt;00:00, 96.4MB/s]"
          }
        },
        "1dac5859a10945a1adadb28dfc93ea0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18f2ceb4c94c4ea091afc17ab882936f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48d0319c81204308a655424e9d974f41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "917e6cbf826c4da399841399330f9dd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92a20835c1ab41af8eee379d345dc6e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d97d9fc3cfe04e60aebd1723a4cdf263": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "516db9148baa45f485cbcca81248a1f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "70b50fdf983e42098f0435261aec9fa3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e7907f27f8d4b49a3baeaab7fe5e4e7",
              "IPY_MODEL_5137bb0cc231464f9cfd9ed392242948",
              "IPY_MODEL_c1b2fa2f253245898d9b4e05a58080fa"
            ],
            "layout": "IPY_MODEL_0dd0bbaf98b145d59b62451b7f086a4a"
          }
        },
        "5e7907f27f8d4b49a3baeaab7fe5e4e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_119d4d6375e44ac0be64515d49e889da",
            "placeholder": "​",
            "style": "IPY_MODEL_a174d6a993554ebfa2ad306f4dd9a76a",
            "value": "100%"
          }
        },
        "5137bb0cc231464f9cfd9ed392242948": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c1d47cf2d1a4100bb6b94ee967daf4c",
            "max": 21444401,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d49b8b4c2f24517bc3d444598143e26",
            "value": 21444401
          }
        },
        "c1b2fa2f253245898d9b4e05a58080fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef9cf3c084684193876d0b3438cba00d",
            "placeholder": "​",
            "style": "IPY_MODEL_5ec4fbb76c3f4effa82e83be008388e0",
            "value": " 20.5M/20.5M [00:00&lt;00:00, 62.4MB/s]"
          }
        },
        "0dd0bbaf98b145d59b62451b7f086a4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "119d4d6375e44ac0be64515d49e889da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a174d6a993554ebfa2ad306f4dd9a76a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c1d47cf2d1a4100bb6b94ee967daf4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d49b8b4c2f24517bc3d444598143e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef9cf3c084684193876d0b3438cba00d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ec4fbb76c3f4effa82e83be008388e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "454d4a72e6d947629edb3e4d4d1d94f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_674d6cbdf514454496b8e40e45e1b511",
              "IPY_MODEL_a02ae67e2c9d4003a2f9c2b0e42585b0",
              "IPY_MODEL_555c13acdcf44b00a9c8c493ef5e6e19"
            ],
            "layout": "IPY_MODEL_4697c877055847ef96d9623af9283562"
          }
        },
        "674d6cbdf514454496b8e40e45e1b511": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c5a5a7462524faca041881f07315276",
            "placeholder": "​",
            "style": "IPY_MODEL_bd3c1581e728426fab64db29b85b7d1e",
            "value": "100%"
          }
        },
        "a02ae67e2c9d4003a2f9c2b0e42585b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fab99da8597f423cad4263503d5d4d74",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_93be17e1287b434181e33305f3e3a33d",
            "value": 10
          }
        },
        "555c13acdcf44b00a9c8c493ef5e6e19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8218176d5af4cc093500ab9846984f9",
            "placeholder": "​",
            "style": "IPY_MODEL_fc122f29b68f4636b4337629915a9081",
            "value": " 10/10 [00:03&lt;00:00,  5.11it/s]"
          }
        },
        "4697c877055847ef96d9623af9283562": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c5a5a7462524faca041881f07315276": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd3c1581e728426fab64db29b85b7d1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fab99da8597f423cad4263503d5d4d74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "93be17e1287b434181e33305f3e3a33d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d8218176d5af4cc093500ab9846984f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fc122f29b68f4636b4337629915a9081": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8b31e6870994f2aae009dcc5e70cbb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2106e52ab75d457392d2aeda03f99e32",
              "IPY_MODEL_c77579c511a744a9be8fad853d18acc9",
              "IPY_MODEL_b850444fc13645a495ea6a3f620a8a28"
            ],
            "layout": "IPY_MODEL_ba3996e28cdf48e79a3104dbf4705641"
          }
        },
        "2106e52ab75d457392d2aeda03f99e32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68950badda4f49b4acaef8a605f85dfd",
            "placeholder": "​",
            "style": "IPY_MODEL_563f6e2e3f214c58abab6a5916e3b29b",
            "value": "100%"
          }
        },
        "c77579c511a744a9be8fad853d18acc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e986664dfef84b10bc59b7632ad503a8",
            "max": 46830571,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f2d655686e6f412e822865d6e1771133",
            "value": 46830571
          }
        },
        "b850444fc13645a495ea6a3f620a8a28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b26a5a582de945669f1a77892463d52a",
            "placeholder": "​",
            "style": "IPY_MODEL_2d07aebaf873454590cfe7e89fbb745f",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 73.8MB/s]"
          }
        },
        "ba3996e28cdf48e79a3104dbf4705641": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68950badda4f49b4acaef8a605f85dfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "563f6e2e3f214c58abab6a5916e3b29b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e986664dfef84b10bc59b7632ad503a8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2d655686e6f412e822865d6e1771133": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b26a5a582de945669f1a77892463d52a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d07aebaf873454590cfe7e89fbb745f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5801bc485ebe417c9e46b27287b48502": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_90f8ba2b3801401999e57d839761d7dd",
              "IPY_MODEL_a28c250b2ced49e28812fea2d487994a",
              "IPY_MODEL_4de266145a52432ca2d9f949332b3f6f"
            ],
            "layout": "IPY_MODEL_db329ce8b18f4ea98fc64af2133505d6"
          }
        },
        "90f8ba2b3801401999e57d839761d7dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a307bfbc81304b0e87f56a4f8c648141",
            "placeholder": "​",
            "style": "IPY_MODEL_be22d1d424724fcd872f1a1c99561d24",
            "value": "Epochs: 100%"
          }
        },
        "a28c250b2ced49e28812fea2d487994a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d32bdecce1d64bfa9047b559460308b2",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_72a8918eaaa040a9b2276cf515fce888",
            "value": 5
          }
        },
        "4de266145a52432ca2d9f949332b3f6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acc2e74e03414318905b88693d308574",
            "placeholder": "​",
            "style": "IPY_MODEL_d94c20da1e89435480b86f7562e570b9",
            "value": " 5/5 [03:18&lt;00:00, 40.48s/it]"
          }
        },
        "db329ce8b18f4ea98fc64af2133505d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a307bfbc81304b0e87f56a4f8c648141": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be22d1d424724fcd872f1a1c99561d24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d32bdecce1d64bfa9047b559460308b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72a8918eaaa040a9b2276cf515fce888": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "acc2e74e03414318905b88693d308574": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d94c20da1e89435480b86f7562e570b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9b6c5336f1334841bdf895f859d5095b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6d9e6b380abb4551bdaa32d6ff469119",
              "IPY_MODEL_260990e219ac469ab6262f4347289ce1",
              "IPY_MODEL_e8798bd1ed9e43ae937d58df2854de16"
            ],
            "layout": "IPY_MODEL_988a9329975540acba5b86c716af16fd"
          }
        },
        "6d9e6b380abb4551bdaa32d6ff469119": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_01a6688aeeae4fd18e9e4f9c758dad4c",
            "placeholder": "​",
            "style": "IPY_MODEL_d309e072f2ef4b0eb4776439f4f4784e",
            "value": "Training: 100%"
          }
        },
        "260990e219ac469ab6262f4347289ce1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2362863875f34de2b3dd796f1554b1ad",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4ba124f7cbf44805a78b935191e8b0af",
            "value": 11
          }
        },
        "e8798bd1ed9e43ae937d58df2854de16": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfa17269873446099e6fb9b8a7a56e70",
            "placeholder": "​",
            "style": "IPY_MODEL_e70a9abdc6bd4b8591d84807d71b48d2",
            "value": " 11/11 [00:21&lt;00:00,  1.74s/it]"
          }
        },
        "988a9329975540acba5b86c716af16fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "01a6688aeeae4fd18e9e4f9c758dad4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d309e072f2ef4b0eb4776439f4f4784e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2362863875f34de2b3dd796f1554b1ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ba124f7cbf44805a78b935191e8b0af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dfa17269873446099e6fb9b8a7a56e70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e70a9abdc6bd4b8591d84807d71b48d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ef7155f3e2e43dd8cafef3f9f89314b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_37c2bf3f4d0844c593270f5addd8c6bb",
              "IPY_MODEL_9d75eb4911e6467facb8135e14db4c9d",
              "IPY_MODEL_fa9b1490c49340ff9cb39612ade4614e"
            ],
            "layout": "IPY_MODEL_6629367e3bed46aea39d5a34c74ec938"
          }
        },
        "37c2bf3f4d0844c593270f5addd8c6bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_edf2dc3686224cb7b69faf3544597514",
            "placeholder": "​",
            "style": "IPY_MODEL_d57725ba54e04d89adfb74702a0820d2",
            "value": "Training: 100%"
          }
        },
        "9d75eb4911e6467facb8135e14db4c9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0c0eccc768044ffa83fde642d211530",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6bb9135db4f94d44b7c0f7735b09b57f",
            "value": 5
          }
        },
        "fa9b1490c49340ff9cb39612ade4614e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_819bca99e9cf480da4482a082db07cbf",
            "placeholder": "​",
            "style": "IPY_MODEL_ed4a358fe0ef4da591378d37ee9d41a7",
            "value": " 5/5 [00:10&lt;00:00,  1.71s/it]"
          }
        },
        "6629367e3bed46aea39d5a34c74ec938": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "edf2dc3686224cb7b69faf3544597514": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d57725ba54e04d89adfb74702a0820d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0c0eccc768044ffa83fde642d211530": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6bb9135db4f94d44b7c0f7735b09b57f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "819bca99e9cf480da4482a082db07cbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed4a358fe0ef4da591378d37ee9d41a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5ad8b67b330345ae8cc73b4fe028a686": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0187a3cf33374ac6a38f44f1c18137c6",
              "IPY_MODEL_f2de16efa2304fd28889399b28deab82",
              "IPY_MODEL_c475ad77f595463fa996917d74dcac8e"
            ],
            "layout": "IPY_MODEL_b940087024e2473d8a95008c45477145"
          }
        },
        "0187a3cf33374ac6a38f44f1c18137c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fcd927d2fda94ba5b245acabab89397b",
            "placeholder": "​",
            "style": "IPY_MODEL_ae13bb30e1384525ba11bc8d0d7c85ed",
            "value": "Training: 100%"
          }
        },
        "f2de16efa2304fd28889399b28deab82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19f299bfc8e9478ba3dc4ac956d57cc6",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ce7de85ee784dc9b3bb86835bc57e3f",
            "value": 11
          }
        },
        "c475ad77f595463fa996917d74dcac8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ac7186360314a79b0cc4165634ef2a0",
            "placeholder": "​",
            "style": "IPY_MODEL_0bc01146ca334786a9ddd492c0ad0eab",
            "value": " 11/11 [00:32&lt;00:00,  3.09s/it]"
          }
        },
        "b940087024e2473d8a95008c45477145": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "fcd927d2fda94ba5b245acabab89397b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ae13bb30e1384525ba11bc8d0d7c85ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19f299bfc8e9478ba3dc4ac956d57cc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ce7de85ee784dc9b3bb86835bc57e3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3ac7186360314a79b0cc4165634ef2a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0bc01146ca334786a9ddd492c0ad0eab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3dc3fdc35704c54a156633160bc108e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6732eaffc69d45cab24b4176e343fbf3",
              "IPY_MODEL_b78f763148da4110a1cf7a8941d3254a",
              "IPY_MODEL_0244faa4064446deaaac1e20e7ce37c6"
            ],
            "layout": "IPY_MODEL_9ac024bb5b2e47ce83c84d6107835cb1"
          }
        },
        "6732eaffc69d45cab24b4176e343fbf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c3cf3dded6a4e0088d7d72df4b270e9",
            "placeholder": "​",
            "style": "IPY_MODEL_b2555885009b4b8293f573376b30217c",
            "value": "Training: 100%"
          }
        },
        "b78f763148da4110a1cf7a8941d3254a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf2e660da1b54ba090f30d660c797ec4",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67877ce9a7ac47f3964ba7b9519c0da9",
            "value": 5
          }
        },
        "0244faa4064446deaaac1e20e7ce37c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2880fe30c97a46149cef71e289a20eb3",
            "placeholder": "​",
            "style": "IPY_MODEL_5abdc1b4cf58459586ff2dc8b9ae5456",
            "value": " 5/5 [00:12&lt;00:00,  2.08s/it]"
          }
        },
        "9ac024bb5b2e47ce83c84d6107835cb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "1c3cf3dded6a4e0088d7d72df4b270e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2555885009b4b8293f573376b30217c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bf2e660da1b54ba090f30d660c797ec4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67877ce9a7ac47f3964ba7b9519c0da9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2880fe30c97a46149cef71e289a20eb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5abdc1b4cf58459586ff2dc8b9ae5456": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5aafcb9ed5dd4b2f8465d483230df25f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b4143d7c9294d59bf0d952a9319beeb",
              "IPY_MODEL_ac16adf042934fa4974256cf9ee525c5",
              "IPY_MODEL_42446d4d6f8146dba6a9b0d2c8df39de"
            ],
            "layout": "IPY_MODEL_f6cafc0083b54dcc8c7addbfc1504a75"
          }
        },
        "1b4143d7c9294d59bf0d952a9319beeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d96a951da80a40df9c57a9f4de4ded18",
            "placeholder": "​",
            "style": "IPY_MODEL_bca760804754475abc0472a119f83244",
            "value": "Training: 100%"
          }
        },
        "ac16adf042934fa4974256cf9ee525c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_60b2ce3ae0c04c1aab6de621b21d9ab7",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f148183d2ef645e98e3e6d59f42ec14b",
            "value": 11
          }
        },
        "42446d4d6f8146dba6a9b0d2c8df39de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_617b84e30ee74458a29ebc6fe8f0ade1",
            "placeholder": "​",
            "style": "IPY_MODEL_1db0108ee9b647598b7a0efb3b84599c",
            "value": " 11/11 [00:27&lt;00:00,  2.26s/it]"
          }
        },
        "f6cafc0083b54dcc8c7addbfc1504a75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "d96a951da80a40df9c57a9f4de4ded18": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bca760804754475abc0472a119f83244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "60b2ce3ae0c04c1aab6de621b21d9ab7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f148183d2ef645e98e3e6d59f42ec14b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "617b84e30ee74458a29ebc6fe8f0ade1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1db0108ee9b647598b7a0efb3b84599c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "23d5ecdf1694415aab48318ff60df7ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b31fbcae66e94cb1820e97fb1c25c297",
              "IPY_MODEL_242bc551b0e6496abc6883c61ec932b3",
              "IPY_MODEL_6803a8e2ae67451da232d1dd778f5dbb"
            ],
            "layout": "IPY_MODEL_06553c1e88c24322867660665cabc73a"
          }
        },
        "b31fbcae66e94cb1820e97fb1c25c297": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ab6ad8993a1435aa1b2b1211c1b454b",
            "placeholder": "​",
            "style": "IPY_MODEL_1c190cc8f85d41b595005d094d7f05a5",
            "value": "Training: 100%"
          }
        },
        "242bc551b0e6496abc6883c61ec932b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_667ca9632f4742b595a4536f01fce6a3",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0c015da411e146e4ade2be8ab4b5b819",
            "value": 5
          }
        },
        "6803a8e2ae67451da232d1dd778f5dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e27e0247b2d4d44aff87276c911039c",
            "placeholder": "​",
            "style": "IPY_MODEL_21605b7f7a544a18afc9e36b2391d01d",
            "value": " 5/5 [00:08&lt;00:00,  1.32s/it]"
          }
        },
        "06553c1e88c24322867660665cabc73a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "6ab6ad8993a1435aa1b2b1211c1b454b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1c190cc8f85d41b595005d094d7f05a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "667ca9632f4742b595a4536f01fce6a3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0c015da411e146e4ade2be8ab4b5b819": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e27e0247b2d4d44aff87276c911039c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "21605b7f7a544a18afc9e36b2391d01d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "78edcbd16c934095bbac2adbe141b4e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_58637e951da446188e0ff40822bb822b",
              "IPY_MODEL_144ba332b80a44ffa983d33cc2e2bcfd",
              "IPY_MODEL_0464d4c141e848278baaf3d3caea491b"
            ],
            "layout": "IPY_MODEL_873616ea18cb43bd96397f6e5309e459"
          }
        },
        "58637e951da446188e0ff40822bb822b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3914d0037114ba2bc597a8a1958d9c7",
            "placeholder": "​",
            "style": "IPY_MODEL_7731c1e9adb34320b2d2beb6985e83bc",
            "value": "Training: 100%"
          }
        },
        "144ba332b80a44ffa983d33cc2e2bcfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_353ed4b12d1a4f5bb16e589e124b39d5",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db695a42ca6548f1848adec453e33863",
            "value": 11
          }
        },
        "0464d4c141e848278baaf3d3caea491b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_81c38ccffc93469cb97d3cac19cb9725",
            "placeholder": "​",
            "style": "IPY_MODEL_3f1209a945364dc8a4a9eaba804fc24a",
            "value": " 11/11 [00:32&lt;00:00,  2.88s/it]"
          }
        },
        "873616ea18cb43bd96397f6e5309e459": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "f3914d0037114ba2bc597a8a1958d9c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7731c1e9adb34320b2d2beb6985e83bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "353ed4b12d1a4f5bb16e589e124b39d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db695a42ca6548f1848adec453e33863": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "81c38ccffc93469cb97d3cac19cb9725": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f1209a945364dc8a4a9eaba804fc24a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ba188b2a994a4f69aa8fcf277bd00643": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4de69b31438349a98c20a4c740d07935",
              "IPY_MODEL_ea40150135d94ca689f519f10657df7b",
              "IPY_MODEL_886cf77621c74d9c8d82846a514ff4f0"
            ],
            "layout": "IPY_MODEL_deb12f7cedb5459f9da7d3edb024cd41"
          }
        },
        "4de69b31438349a98c20a4c740d07935": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35c52ec26a934a65a8b4e1da0b0b4ffb",
            "placeholder": "​",
            "style": "IPY_MODEL_daad900575794a77b977a1a376074dfd",
            "value": "Training: 100%"
          }
        },
        "ea40150135d94ca689f519f10657df7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6bec39527cb84f70b523e45ed71275f0",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_34dc3d24c1e84a8b8f27c50677baefc1",
            "value": 5
          }
        },
        "886cf77621c74d9c8d82846a514ff4f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57c5b76fdcd64f19a434c4dfd8590326",
            "placeholder": "​",
            "style": "IPY_MODEL_2f493fe657594a51ac1ee295b5df0e1e",
            "value": " 5/5 [00:15&lt;00:00,  3.09s/it]"
          }
        },
        "deb12f7cedb5459f9da7d3edb024cd41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "35c52ec26a934a65a8b4e1da0b0b4ffb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daad900575794a77b977a1a376074dfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6bec39527cb84f70b523e45ed71275f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34dc3d24c1e84a8b8f27c50677baefc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "57c5b76fdcd64f19a434c4dfd8590326": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f493fe657594a51ac1ee295b5df0e1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3594297a90a41a88c5a1f7a8af67724": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a6ad1cf2b50e41a6acb6db98d375a78f",
              "IPY_MODEL_6dfa624f683b45079fe0e317e8ac4b70",
              "IPY_MODEL_812ed4bccc9b4355ac2af8e486a67a3f"
            ],
            "layout": "IPY_MODEL_14686dd9459849d398a5bb90d13d29ca"
          }
        },
        "a6ad1cf2b50e41a6acb6db98d375a78f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c0020bbb73be44e09e0d10e50e279612",
            "placeholder": "​",
            "style": "IPY_MODEL_6de5aae052ff48258767fbbe0b7e0dbd",
            "value": "Training: 100%"
          }
        },
        "6dfa624f683b45079fe0e317e8ac4b70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1e14c257a58640cc844f1e6611a3c140",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e02cf81073af47e686a79cb114703d8d",
            "value": 11
          }
        },
        "812ed4bccc9b4355ac2af8e486a67a3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_14384e109bde496c823015fda02411ab",
            "placeholder": "​",
            "style": "IPY_MODEL_e8b3cfa026684b7e99b7c89c0c7c9e0a",
            "value": " 11/11 [00:23&lt;00:00,  1.74s/it]"
          }
        },
        "14686dd9459849d398a5bb90d13d29ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "c0020bbb73be44e09e0d10e50e279612": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6de5aae052ff48258767fbbe0b7e0dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1e14c257a58640cc844f1e6611a3c140": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e02cf81073af47e686a79cb114703d8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "14384e109bde496c823015fda02411ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8b3cfa026684b7e99b7c89c0c7c9e0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0e1c044ee7e48e7bf7ef9da6da1c8cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_865d6a14079345868b6df0a924feade2",
              "IPY_MODEL_58401f0d928d43ad856e8e5395009c46",
              "IPY_MODEL_963b7501e70e47379575e6fee6d03b34"
            ],
            "layout": "IPY_MODEL_31e2f60669404148a09e7fab3c1f5775"
          }
        },
        "865d6a14079345868b6df0a924feade2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c7ebc9e6d514e56afbd22a899deb197",
            "placeholder": "​",
            "style": "IPY_MODEL_88a3736c47474abcb5e9e7c9813e7876",
            "value": "Training: 100%"
          }
        },
        "58401f0d928d43ad856e8e5395009c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf8520cc31fb47cba7bf9a5a41845e4a",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2dbfa31841034ddf9a6081aac1a9102a",
            "value": 5
          }
        },
        "963b7501e70e47379575e6fee6d03b34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_adcadc0c79e04bba9c60518c294795a4",
            "placeholder": "​",
            "style": "IPY_MODEL_099095df2dd94d59a3807629e4914db7",
            "value": " 5/5 [00:14&lt;00:00,  2.38s/it]"
          }
        },
        "31e2f60669404148a09e7fab3c1f5775": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": "hidden",
            "width": null
          }
        },
        "1c7ebc9e6d514e56afbd22a899deb197": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88a3736c47474abcb5e9e7c9813e7876": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf8520cc31fb47cba7bf9a5a41845e4a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2dbfa31841034ddf9a6081aac1a9102a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "adcadc0c79e04bba9c60518c294795a4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "099095df2dd94d59a3807629e4914db7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7818ba934b494c7280f6b96a78e97eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d4ba0b80c7dd4dadb982d0ce630f770b",
              "IPY_MODEL_427b0de0b9f141e1aeac5aa163bca809",
              "IPY_MODEL_5058e6fef0154415bc63fa3d4237199a"
            ],
            "layout": "IPY_MODEL_aeb28be41bb7487aa24590fc9fc1dbaa"
          }
        },
        "d4ba0b80c7dd4dadb982d0ce630f770b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8cee92312966446184519c48a48ceeff",
            "placeholder": "​",
            "style": "IPY_MODEL_cc004a10c1f0438997c8d521a7f3f696",
            "value": "Epochs:   0%"
          }
        },
        "427b0de0b9f141e1aeac5aa163bca809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_848711a27db1461bac96b9b8eab3a3cb",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_518ba1c2a59a47ba816fec3da796e80e",
            "value": 0
          }
        },
        "5058e6fef0154415bc63fa3d4237199a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cd4e62e4f82469eb4bfd68660d98464",
            "placeholder": "​",
            "style": "IPY_MODEL_469893fecb92412b86ac3cec36006fcc",
            "value": " 0/5 [00:01&lt;?, ?it/s]"
          }
        },
        "aeb28be41bb7487aa24590fc9fc1dbaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cee92312966446184519c48a48ceeff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc004a10c1f0438997c8d521a7f3f696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "848711a27db1461bac96b9b8eab3a3cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "518ba1c2a59a47ba816fec3da796e80e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2cd4e62e4f82469eb4bfd68660d98464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "469893fecb92412b86ac3cec36006fcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f3201dae8c94a34b69dde6b4cffa281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3517a03907ff436e9e4956bbaafecde4",
              "IPY_MODEL_c0aeb427c20e49e39c8cbfafd65761fe",
              "IPY_MODEL_81f8e8d092094c319dc1ecfb749686e1"
            ],
            "layout": "IPY_MODEL_add84e71c1d849018f126a6c987694a2"
          }
        },
        "3517a03907ff436e9e4956bbaafecde4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ba1ae8fc37148dba669fb77bc1b44f7",
            "placeholder": "​",
            "style": "IPY_MODEL_39a8c429b57548edb5f2353f7faf87cb",
            "value": "Training:   0%"
          }
        },
        "c0aeb427c20e49e39c8cbfafd65761fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_331fbea9d93d41e3aaac77f997ab95da",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9e9e8086d978417b808671c67deab6fb",
            "value": 0
          }
        },
        "81f8e8d092094c319dc1ecfb749686e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b80fadc156cb4f56a61bda34ec9c2527",
            "placeholder": "​",
            "style": "IPY_MODEL_8e14f53a489742d18fd1a8b307990f62",
            "value": " 0/11 [00:01&lt;?, ?it/s]"
          }
        },
        "add84e71c1d849018f126a6c987694a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5ba1ae8fc37148dba669fb77bc1b44f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "39a8c429b57548edb5f2353f7faf87cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "331fbea9d93d41e3aaac77f997ab95da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e9e8086d978417b808671c67deab6fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b80fadc156cb4f56a61bda34ec9c2527": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e14f53a489742d18fd1a8b307990f62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "09bc1c42b81246e1a7782dab46fd1318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5ebdc4d4ba05461391dc88fc9a42ac79",
              "IPY_MODEL_ac1398c18781423084bbfa0d07a84d99",
              "IPY_MODEL_ac0dcf46a9a4485fadc8710b354c2940"
            ],
            "layout": "IPY_MODEL_f20ef71f8501423f9111a762e38e0e5e"
          }
        },
        "5ebdc4d4ba05461391dc88fc9a42ac79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c9cad24e27b4cd5a2e02346acd20f2d",
            "placeholder": "​",
            "style": "IPY_MODEL_8354768b9b70482d8e8919293b2f6860",
            "value": "Epochs:   0%"
          }
        },
        "ac1398c18781423084bbfa0d07a84d99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2aaa52dfdff4fe7b5e7a8d96d933558",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec1cf61747694d1c930a61ed65a4863a",
            "value": 0
          }
        },
        "ac0dcf46a9a4485fadc8710b354c2940": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5be0c86a0264ea9bf3dc8a31363f995",
            "placeholder": "​",
            "style": "IPY_MODEL_eeb4df42f6e94cc18e048be86a93819b",
            "value": " 0/5 [00:03&lt;?, ?it/s]"
          }
        },
        "f20ef71f8501423f9111a762e38e0e5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9c9cad24e27b4cd5a2e02346acd20f2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8354768b9b70482d8e8919293b2f6860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2aaa52dfdff4fe7b5e7a8d96d933558": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec1cf61747694d1c930a61ed65a4863a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5be0c86a0264ea9bf3dc8a31363f995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eeb4df42f6e94cc18e048be86a93819b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17aadcf8afed48458a939d04d6b62e7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_49ffc3f8aa244766b437c723e7a3931d",
              "IPY_MODEL_81e450099ef54436ba492213c39765ba",
              "IPY_MODEL_555e6c4b6a5d43859c8dfc7cc217ec32"
            ],
            "layout": "IPY_MODEL_0b1604aab61445ed89bac9b035d37728"
          }
        },
        "49ffc3f8aa244766b437c723e7a3931d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_472d559e62014da0b6c8a6171b94d761",
            "placeholder": "​",
            "style": "IPY_MODEL_c9ed48c18c324380b67e40146e254a32",
            "value": "Training:   0%"
          }
        },
        "81e450099ef54436ba492213c39765ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6f252f10c4e40da9426e2f0f368998d",
            "max": 11,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8fe9f7fdc37946f280faa684c510d188",
            "value": 0
          }
        },
        "555e6c4b6a5d43859c8dfc7cc217ec32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_04dd15f3dc154901b96401e9fc4b728b",
            "placeholder": "​",
            "style": "IPY_MODEL_a031f0d26be7498e876b8fd30b668fd0",
            "value": " 0/11 [00:03&lt;?, ?it/s]"
          }
        },
        "0b1604aab61445ed89bac9b035d37728": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "472d559e62014da0b6c8a6171b94d761": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9ed48c18c324380b67e40146e254a32": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6f252f10c4e40da9426e2f0f368998d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fe9f7fdc37946f280faa684c510d188": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "04dd15f3dc154901b96401e9fc4b728b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a031f0d26be7498e876b8fd30b668fd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}