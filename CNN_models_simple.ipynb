{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9065aff9",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5158285a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "from img2vec_pytorch import Img2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc372be2",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "fd5b2f0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 4096])\n",
      "torch.Size([1, 512, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Initialize Img2Vec with GPU\n",
    "img2vec_alexnet = Img2Vec(cuda=False, model=\"alexnet\")  # default model resnet\n",
    "\n",
    "# Read in an image (rgb format)\n",
    "img = Image.open('test.png').convert('RGB')\n",
    "# Get a vector from img2vec, returned as a torch FloatTensor\n",
    "vec = img2vec_alexnet.get_vec(img, tensor=True)\n",
    "\n",
    "print(vec.size())\n",
    "\n",
    "# Initialize Img2Vec with GPU\n",
    "img2vec_18 = Img2Vec(cuda=False, model=\"resnet-18\")  # default model resnet\n",
    "\n",
    "# Read in an image (rgb format)\n",
    "img = Image.open('test.png').convert('RGB')\n",
    "# Get a vector from img2vec, returned as a torch FloatTensor\n",
    "vec = img2vec_18.get_vec(img, tensor=True)\n",
    "\n",
    "print(vec.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a6a4db4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ref = Image.open('ref.png').convert('RGB')\n",
    "ref_vec = img2vec.get_vec(ref, tensor=True)\n",
    "\n",
    "p0 = Image.open('p0.png').convert('RGB')\n",
    "p0_vec = img2vec.get_vec(p0, tensor=True)\n",
    "\n",
    "p1 = Image.open('p1.png').convert('RGB')\n",
    "p1_vec = img2vec.get_vec(p1, tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93cf0baa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine similarity: tensor([0.4113])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using PyTorch Cosine Similarity\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "cos_sim = cos(ref_vec,\n",
    "              p0_vec)\n",
    "print('\\nCosine similarity: {0}\\n'.format(cos_sim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "314ba326",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cosine similarity: tensor([0.3291])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Using PyTorch Cosine Similarity\n",
    "cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "cos_sim = cos(ref_vec,\n",
    "              p1_vec)\n",
    "print('\\nCosine similarity: {0}\\n'.format(cos_sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1e953e",
   "metadata": {},
   "source": [
    "### Common functions for loading dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aade6f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_image_number(number):\n",
    "    img_no_str = str(number)\n",
    "    \n",
    "    if len(img_no_str) == 1:\n",
    "        im_no_name = \"00000\"\n",
    "    elif len(img_no_str) == 2:\n",
    "        im_no_name = \"0000\"\n",
    "    elif len(img_no_str) == 3:\n",
    "        im_no_name = \"000\"\n",
    "    elif len(img_no_str) == 4:\n",
    "        im_no_name = \"00\"\n",
    "    elif len(img_no_str) == 5:\n",
    "        im_no_name = \"0\"\n",
    "    elif len(img_no_str) == 6:\n",
    "        im_no_name = \"\"\n",
    "        \n",
    "    return im_no_name + img_no_str\n",
    "    \n",
    "\n",
    "def get_images_vector(path, number_of_images):  # returns a list of tensors\n",
    "    # path of form: traditional/ref/\n",
    "    feature_tensor_list = []\n",
    "    \n",
    "    for image_no in range(number_of_images):\n",
    "        image_no_str = str(image_no)\n",
    "        \n",
    "        im_no_name = format_image_number(image_no_str) + \".png\"\n",
    "        \n",
    "        path_to_image = path + im_no_name\n",
    "\n",
    "        feature_vector_image = Image.open(path_to_image).convert('RGB')\n",
    "        feature_vec = img2vec.get_vec(feature_vector_image, tensor=True)\n",
    "        feature_tensor_list.append(feature_vec)\n",
    "        \n",
    "    return feature_tensor_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2d7d1a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_cosine_similarity_model_predictions(number_of_images, refs_vec_list, p0s_rec_list, p1s_rec_list):\n",
    "    cosine_similarity_ref_and_p0 = []\n",
    "    cosine_similarity_ref_and_p1 = []\n",
    "\n",
    "    # list of predictions\n",
    "    cosine_similarity_predictions = []\n",
    "    \n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    # cos_sim = cos(query_vector.unsqueeze(0), ref2_vector.unsqueeze(0))\n",
    "\n",
    "    for image_no in range(number_of_images): \n",
    "        reshaped_ref = torch.reshape(refs_vec_list[image_no], (1,512))\n",
    "        reshaped_p0 = torch.reshape(p0s_rec_list[image_no], (1,512))\n",
    "        reshaped_p1 = torch.reshape(p1s_rec_list[image_no], (1,512))\n",
    "        \n",
    "        cosine_similarity_ref_and_p0.append(cos(reshaped_ref, reshaped_p0))\n",
    "        cosine_similarity_ref_and_p1.append(cos(reshaped_ref, reshaped_p1))\n",
    "\n",
    "        if cosine_similarity_ref_and_p0[image_no] >= cosine_similarity_ref_and_p1[image_no]:\n",
    "            cosine_similarity_predictions.append(0)\n",
    "        else:\n",
    "            cosine_similarity_predictions.append(1)   \n",
    "            \n",
    "    return cosine_similarity_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "66ee8ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_prediction_accuracy(number_of_images, path_to_decision, actual_predictions):\n",
    "    expected_decision_outputs = []\n",
    "\n",
    "    for image_no in range(number_of_images):\n",
    "            image_no_str = str(image_no)\n",
    "\n",
    "            im_no_name = format_image_number(image_no_str) + \".npy\"\n",
    "            path_to_image = path_to_decision + im_no_name\n",
    "\n",
    "            decision = np.load(path_to_image)\n",
    "\n",
    "            if decision[0] <= 0.5: \n",
    "                expected_decision_outputs.append(0)\n",
    "            else: \n",
    "                expected_decision_outputs.append(1)\n",
    "                \n",
    "    number_wrong_predictions = 0\n",
    "\n",
    "    for image_no in range(number_of_images):\n",
    "        if actual_predictions[image_no] != expected_decision_outputs[image_no]:\n",
    "            number_wrong_predictions += 1\n",
    "\n",
    "    accuracy = (number_of_images - number_wrong_predictions)/(number_of_images)\n",
    "    \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "68c2d02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_tensor_list(dim, tensor_list):\n",
    "    reshaped_list = []\n",
    "    for t in tensor_list:\n",
    "        reshaped_t = torch.reshape(t, (1,dim))\n",
    "        reshaped_list.append(t)\n",
    "    return reshaped_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49678780",
   "metadata": {},
   "source": [
    "### 1. Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73f39e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2vec_res = Img2Vec(cuda=False, model=\"resnet-18\")  # default model resnet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22520bf3",
   "metadata": {},
   "source": [
    "#### 1.1 Traditional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "27073e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "traditional_refs = get_images_vector(\"val/traditional/ref/\", 4720)\n",
    "traditional_p0s = get_images_vector(\"val/traditional/p0/\", 4720)\n",
    "traditional_p1s = get_images_vector(\"val/traditional/p1/\", 4720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0a2a3043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4720\n",
      "4720\n",
      "4720\n"
     ]
    }
   ],
   "source": [
    "print(len(traditional_refs))\n",
    "print(len(traditional_p0s))\n",
    "print(len(traditional_p1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "46a90a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_model_predictions = obtain_cosine_similarity_model_predictions(4720, traditional_refs, traditional_p0s, traditional_p1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "09b82c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_accuracy = obtain_prediction_accuracy(4720, \"val/traditional/judge/\", actual_model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d8ca7cef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8048728813559322"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e07c6190",
   "metadata": {},
   "source": [
    "Prediction accuracy for Resnet-18 for traditional distortions: 0.8048728813559322"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a16c9",
   "metadata": {},
   "source": [
    "#### 1.2 CNN-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d95c1374",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_refs = get_images_vector(\"val/cnn/ref/\", 4720)\n",
    "cnn_p0s = get_images_vector(\"val/cnn/p0/\", 4720)\n",
    "cnn_p1s = get_images_vector(\"val/cnn/p1/\", 4720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7d2e7f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4720\n",
      "4720\n",
      "4720\n"
     ]
    }
   ],
   "source": [
    "print(len(cnn_refs))\n",
    "print(len(cnn_p0s))\n",
    "print(len(cnn_p1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "131aa574",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_model_predictions_cnn_distortion = obtain_cosine_similarity_model_predictions(4720, cnn_refs, cnn_p0s, cnn_p1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d427a1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_accuracy_cnn_distortion = obtain_prediction_accuracy(4720, \"val/cnn/judge/\", actual_model_predictions_cnn_distortion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7534f0a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8442796610169492"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_accuracy_cnn_distortion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93478b18",
   "metadata": {},
   "source": [
    "Prediction accuracy for Resnet-18 for CNN-based distortions: 0.8442796610169492"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b8f83f",
   "metadata": {},
   "source": [
    "#### 1.3 Colorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "eca880a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_refs = get_images_vector(\"val/color/ref/\", 4720)\n",
    "color_p0s = get_images_vector(\"val/color/p0/\", 4720)\n",
    "color_p1s = get_images_vector(\"val/color/p1/\", 4720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1e90d57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4720\n",
      "4720\n",
      "4720\n"
     ]
    }
   ],
   "source": [
    "print(len(color_refs))\n",
    "print(len(color_p0s))\n",
    "print(len(color_p1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d3829085",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_model_predictions_color_distortion = obtain_cosine_similarity_model_predictions(4720, color_refs, color_p0s, color_p1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "8dcd0778",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_accuracy_color_distortion = obtain_prediction_accuracy(4720, \"val/color/judge/\", actual_model_predictions_color_distortion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2fe4ff36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6533898305084745"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_accuracy_color_distortion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c68ea4",
   "metadata": {},
   "source": [
    "Prediction accuracy for Resnet-18 for colorizaton distortions: 0.6533898305084745"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7687f12b",
   "metadata": {},
   "source": [
    "#### 1.4 Deblurring --- IGNORE FOR NOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "190dcbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "deb_refs = get_images_vector(\"val/deblur/ref/\", 9440)\n",
    "deb_p0s = get_images_vector(\"val/deblur/p0/\", 9440)\n",
    "deb_p1s = get_images_vector(\"val/deblur/p1/\", 9440)\n",
    "\n",
    "fi_refs = get_images_vector(\"val/frameinterp/ref/\", 1888)\n",
    "fi_p0s = get_images_vector(\"val/frameinterp/p0/\", 1888)\n",
    "fi_p1s = get_images_vector(\"val/frameinterp/p1/\", 1888)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e570fb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4720\n",
      "4720\n",
      "4720\n"
     ]
    }
   ],
   "source": [
    "print(len(deb_refs))\n",
    "print(len(deb_p0s))\n",
    "print(len(deb_p1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "25912505",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_model_predictions_deb_distortion = obtain_cosine_similarity_model_predictions(4720, deb_refs, deb_p0s, deb_p1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "b696dd69",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_accuracy_deb_distortion = obtain_prediction_accuracy(4720, \"val/deblur/judge/\", actual_model_predictions_deb_distortion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "24fe912d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6016949152542372"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_accuracy_deb_distortion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dd7e700",
   "metadata": {},
   "source": [
    "Prediction accuracy for Resnet-18 for deblurring distortions: 0.6016949152542372"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f340a2",
   "metadata": {},
   "source": [
    "#### 1.4, 1.5 and 1.6 Deblurring, frame interpolation and super resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "40b99584",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deblurring is complete\n",
      "FI is complete\n",
      "Spr is complete\n"
     ]
    }
   ],
   "source": [
    "deblur_refs = get_images_vector(\"val/deblur/ref/\", 9440)\n",
    "deblur_p0s = get_images_vector(\"val/deblur/p0/\", 9440)\n",
    "deblur_p1s = get_images_vector(\"val/deblur/p1/\", 9440)\n",
    "print(\"Deblurring is complete\")\n",
    "\n",
    "fi_refs = get_images_vector(\"val/frameinterp/ref/\", 1888)\n",
    "fi_p0s = get_images_vector(\"val/frameinterp/p0/\", 1888)\n",
    "fi_p1s = get_images_vector(\"val/frameinterp/p1/\", 1888)\n",
    "print(\"FI is complete\")\n",
    "\n",
    "spr_refs = get_images_vector(\"val/superres/ref/\", 10856)\n",
    "spr_p0s = get_images_vector(\"val/superres/p0/\", 10856)\n",
    "spr_p1s = get_images_vector(\"val/superres/p1/\", 10856)\n",
    "print(\"Spr is complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "10596319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deblur: \n",
      "0.6113347457627119\n",
      "----------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actual_model_predictions_blur_distortion = obtain_cosine_similarity_model_predictions(9440, deblur_refs, deblur_p0s, deblur_p1s)\n",
    "prediction_accuracy_blur_distortion = obtain_prediction_accuracy(9440, \"val/deblur/judge/\", actual_model_predictions_blur_distortion)\n",
    "print(\"Deblur: \")\n",
    "print(prediction_accuracy_blur_distortion)\n",
    "print(\"----------------\")\n",
    "print(\"\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "5e767016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fi: \n",
      "0.6604872881355932\n",
      "----------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actual_model_predictions_frame = obtain_cosine_similarity_model_predictions(1888, fi_refs, fi_p0s, fi_p1s)\n",
    "prediction_accuracy_frame = obtain_prediction_accuracy(1888, \"val/frameinterp/judge/\", actual_model_predictions_frame)\n",
    "print(\"Fi: \")\n",
    "print(prediction_accuracy_frame)\n",
    "print(\"----------------\")\n",
    "print(\"\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b85a9750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spr: \n",
      "0.7198784082535004\n",
      "----------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "actual_model_predictions_cnn_distortion_super = obtain_cosine_similarity_model_predictions(10856, spr_refs, spr_p0s, spr_p1s)\n",
    "prediction_accuracy_cnn_distortion_super = obtain_prediction_accuracy(10856, \"val/superres/judge/\", actual_model_predictions_cnn_distortion_super)\n",
    "print(\"Spr: \")\n",
    "print(prediction_accuracy_cnn_distortion_super)\n",
    "print(\"----------------\")\n",
    "print(\"\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45c4672a",
   "metadata": {},
   "source": [
    "Prediction accuracy for Resnet-18 for deblurring distortions: 0.6113347457627119\n",
    "\n",
    "Prediction accuracy for Resnet-18 for frame interpolation distortions: 0.6604872881355932\n",
    "\n",
    "Prediction accuracy for Resnet-18 for super resolution distortions: 0.7198784082535004"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb9f1bc",
   "metadata": {},
   "source": [
    "### 2. AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "3cad9bf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alexnet results:\n",
      "Deblurring is complete\n",
      "FI is complete\n",
      "Spr is complete\n",
      "Traditional: \n",
      "0.8108050847457627\n",
      "----------------\n",
      "\n",
      "\n",
      "CNN: \n",
      "0.8544491525423729\n",
      "----------------\n",
      "\n",
      "\n",
      "Colorization: \n",
      "0.6720338983050848\n",
      "----------------\n",
      "\n",
      "\n",
      "Deblur: \n",
      "0.639406779661017\n",
      "----------------\n",
      "\n",
      "\n",
      "Fi: \n",
      "0.666843220338983\n",
      "----------------\n",
      "\n",
      "\n",
      "Spr: \n",
      "0.7424465733235077\n",
      "----------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "from img2vec_pytorch import Img2Vec\n",
    "\n",
    "def format_image_number(number):\n",
    "    img_no_str = str(number)\n",
    "    \n",
    "    if len(img_no_str) == 1:\n",
    "        im_no_name = \"00000\"\n",
    "    elif len(img_no_str) == 2:\n",
    "        im_no_name = \"0000\"\n",
    "    elif len(img_no_str) == 3:\n",
    "        im_no_name = \"000\"\n",
    "    elif len(img_no_str) == 4:\n",
    "        im_no_name = \"00\"\n",
    "    elif len(img_no_str) == 5:\n",
    "        im_no_name = \"0\"\n",
    "    elif len(img_no_str) == 6:\n",
    "        im_no_name = \"\"\n",
    "        \n",
    "    return im_no_name + img_no_str\n",
    "    \n",
    "img2vec = Img2Vec(cuda=False, model=\"alexnet\")  # default model resnet\n",
    "\n",
    "def get_images_vector(path, number_of_images):  # returns a list of tensors\n",
    "    # path of form: traditional/ref/\n",
    "    feature_tensor_list = []\n",
    "    \n",
    "    for image_no in range(number_of_images):\n",
    "        image_no_str = str(image_no)\n",
    "        \n",
    "        im_no_name = format_image_number(image_no_str) + \".png\"\n",
    "        \n",
    "        path_to_image = path + im_no_name\n",
    "\n",
    "        feature_vector_image = Image.open(path_to_image).convert('RGB')\n",
    "        feature_vec = img2vec.get_vec(feature_vector_image, tensor=True)\n",
    "        feature_tensor_list.append(feature_vec)\n",
    "        \n",
    "    return feature_tensor_list\n",
    "\n",
    "def obtain_cosine_similarity_model_predictions(number_of_images, refs_vec_list, p0s_rec_list, p1s_rec_list):\n",
    "    cosine_similarity_ref_and_p0 = []\n",
    "    cosine_similarity_ref_and_p1 = []\n",
    "\n",
    "    # list of predictions\n",
    "    cosine_similarity_predictions = []\n",
    "    \n",
    "    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n",
    "    # cos_sim = cos(query_vector.unsqueeze(0), ref2_vector.unsqueeze(0))\n",
    "\n",
    "    for image_no in range(number_of_images): \n",
    "        reshaped_ref = refs_vec_list[image_no]\n",
    "        reshaped_p0 = p0s_rec_list[image_no]\n",
    "        reshaped_p1 = p1s_rec_list[image_no]\n",
    "        \n",
    "        cosine_similarity_ref_and_p0.append(cos(reshaped_ref, reshaped_p0))\n",
    "        cosine_similarity_ref_and_p1.append(cos(reshaped_ref, reshaped_p1))\n",
    "\n",
    "        if cosine_similarity_ref_and_p0[image_no] >= cosine_similarity_ref_and_p1[image_no]:\n",
    "            cosine_similarity_predictions.append(0)\n",
    "        else:\n",
    "            cosine_similarity_predictions.append(1)   \n",
    "            \n",
    "    return cosine_similarity_predictions\n",
    "\n",
    "def obtain_prediction_accuracy(number_of_images, path_to_decision, actual_predictions):\n",
    "    expected_decision_outputs = []\n",
    "\n",
    "    for image_no in range(number_of_images):\n",
    "            image_no_str = str(image_no)\n",
    "\n",
    "            im_no_name = format_image_number(image_no_str) + \".npy\"\n",
    "            path_to_image = path_to_decision + im_no_name\n",
    "\n",
    "            decision = np.load(path_to_image)\n",
    "\n",
    "            if decision[0] <= 0.5: \n",
    "                expected_decision_outputs.append(0)\n",
    "            else: \n",
    "                expected_decision_outputs.append(1)\n",
    "                \n",
    "    number_wrong_predictions = 0\n",
    "\n",
    "    for image_no in range(number_of_images):\n",
    "        if actual_predictions[image_no] != expected_decision_outputs[image_no]:\n",
    "            number_wrong_predictions += 1\n",
    "\n",
    "    accuracy = (number_of_images - number_wrong_predictions)/(number_of_images)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "def reshape_tensor_list(dim, tensor_list):\n",
    "    reshaped_list = []\n",
    "    for t in tensor_list:\n",
    "        reshaped_t = torch.reshape(t, (1,dim))\n",
    "        reshaped_list.append(t)\n",
    "    return reshaped_list\n",
    "\n",
    "\n",
    "\n",
    "print(\"Alexnet results:\")\n",
    "\n",
    "img2vec_res = Img2Vec(cuda=False, model=\"alexnet\")  # default model resnet\n",
    "\n",
    "traditional_refs = get_images_vector(\"val/traditional/ref/\", 4720)\n",
    "traditional_p0s = get_images_vector(\"val/traditional/p0/\", 4720)\n",
    "traditional_p1s = get_images_vector(\"val/traditional/p1/\", 4720)\n",
    "\n",
    "cnn_refs = get_images_vector(\"val/cnn/ref/\", 4720)\n",
    "cnn_p0s = get_images_vector(\"val/cnn/p0/\", 4720)\n",
    "cnn_p1s = get_images_vector(\"val/cnn/p1/\", 4720)\n",
    "\n",
    "color_refs = get_images_vector(\"val/color/ref/\", 4720)\n",
    "color_p0s = get_images_vector(\"val/color/p0/\", 4720)\n",
    "color_p1s = get_images_vector(\"val/color/p1/\", 4720)\n",
    "\n",
    "deblur_refs = get_images_vector(\"val/deblur/ref/\", 9440)\n",
    "deblur_p0s = get_images_vector(\"val/deblur/p0/\", 9440)\n",
    "deblur_p1s = get_images_vector(\"val/deblur/p1/\", 9440)\n",
    "print(\"Deblurring is complete\")\n",
    "\n",
    "fi_refs = get_images_vector(\"val/frameinterp/ref/\", 1888)\n",
    "fi_p0s = get_images_vector(\"val/frameinterp/p0/\", 1888)\n",
    "fi_p1s = get_images_vector(\"val/frameinterp/p1/\", 1888)\n",
    "print(\"FI is complete\")\n",
    "\n",
    "spr_refs = get_images_vector(\"val/superres/ref/\", 10856)\n",
    "spr_p0s = get_images_vector(\"val/superres/p0/\", 10856)\n",
    "spr_p1s = get_images_vector(\"val/superres/p1/\", 10856)\n",
    "print(\"Spr is complete\")\n",
    "\n",
    "\n",
    "actual_model_predictions = obtain_cosine_similarity_model_predictions(4720, traditional_refs, traditional_p0s, traditional_p1s)\n",
    "prediction_accuracy = obtain_prediction_accuracy(4720, \"val/traditional/judge/\", actual_model_predictions)\n",
    "print(\"Traditional: \")\n",
    "print(prediction_accuracy)\n",
    "print(\"----------------\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "actual_model_predictions_cnn_distortion = obtain_cosine_similarity_model_predictions(4720, cnn_refs, cnn_p0s, cnn_p1s)\n",
    "prediction_accuracy_cnn_distortion = obtain_prediction_accuracy(4720, \"val/cnn/judge/\", actual_model_predictions_cnn_distortion)\n",
    "print(\"CNN: \")\n",
    "print(prediction_accuracy_cnn_distortion)\n",
    "print(\"----------------\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "actual_model_predictions_color_distortion = obtain_cosine_similarity_model_predictions(4720, color_refs, color_p0s, color_p1s)\n",
    "prediction_accuracy_color_distortion = obtain_prediction_accuracy(4720, \"val/color/judge/\", actual_model_predictions_color_distortion)\n",
    "print(\"Colorization: \")\n",
    "print(prediction_accuracy_color_distortion)\n",
    "print(\"----------------\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "actual_model_predictions_blur_distortion = obtain_cosine_similarity_model_predictions(9440, deblur_refs, deblur_p0s, deblur_p1s)\n",
    "prediction_accuracy_blur_distortion = obtain_prediction_accuracy(9440, \"val/deblur/judge/\", actual_model_predictions_blur_distortion)\n",
    "print(\"Deblur: \")\n",
    "print(prediction_accuracy_blur_distortion)\n",
    "print(\"----------------\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "\n",
    "actual_model_predictions_frame = obtain_cosine_similarity_model_predictions(1888, fi_refs, fi_p0s, fi_p1s)\n",
    "prediction_accuracy_frame = obtain_prediction_accuracy(1888, \"val/frameinterp/judge/\", actual_model_predictions_frame)\n",
    "print(\"Fi: \")\n",
    "print(prediction_accuracy_frame)\n",
    "print(\"----------------\")\n",
    "print(\"\")\n",
    "print(\"\")\n",
    "\n",
    "actual_model_predictions_cnn_distortion_super = obtain_cosine_similarity_model_predictions(10856, spr_refs, spr_p0s, spr_p1s)\n",
    "prediction_accuracy_cnn_distortion_super = obtain_prediction_accuracy(10856, \"val/superres/judge/\", actual_model_predictions_cnn_distortion_super)\n",
    "print(\"Spr: \")\n",
    "print(prediction_accuracy_cnn_distortion_super)\n",
    "print(\"----------------\")\n",
    "print(\"\")\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1abe4f",
   "metadata": {},
   "source": [
    "AlexNet: \n",
    "    \n",
    "Traditional: \n",
    "0.8108050847457627\n",
    "\n",
    "\n",
    "CNN: \n",
    "0.8544491525423729\n",
    "\n",
    "\n",
    "\n",
    "Colorization: \n",
    "0.6720338983050848\n",
    "\n",
    "\n",
    "\n",
    "Deblur: \n",
    "0.639406779661017\n",
    "\n",
    "\n",
    "\n",
    "Fi: \n",
    "0.666843220338983\n",
    "\n",
    "\n",
    "\n",
    "Spr: \n",
    "0.7424465733235077"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
